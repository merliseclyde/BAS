<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in
Linear Models — bas.lm • BAS</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>


<!-- docsearch -->
<script src="../docsearch.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous" />
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>



<meta property="og:title" content="Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in
Linear Models — bas.lm" />
<meta property="og:description" content="Sample without replacement from a posterior distribution on models" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">BAS</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.6.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://twitter.com/merliseclyde">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/merliseclyde/BAS">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
      
      <form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
        </div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in
Linear Models</h1>
    <small class="dont-index">Source: <a href='https://github.com/merliseclyde/BAS/blob/master/R/bas_lm.R'><code>R/bas_lm.R</code></a></small>
    <div class="hidden name"><code>bas.lm.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Sample without replacement from a posterior distribution on models</p>
    </div>

    <pre class="usage"><span class='fu'>bas.lm</span><span class='op'>(</span>
  <span class='va'>formula</span>,
  <span class='va'>data</span>,
  <span class='va'>subset</span>,
  <span class='va'>weights</span>,
  contrasts <span class='op'>=</span> <span class='cn'>NULL</span>,
  na.action <span class='op'>=</span> <span class='st'>"na.omit"</span>,
  n.models <span class='op'>=</span> <span class='cn'>NULL</span>,
  prior <span class='op'>=</span> <span class='st'>"ZS-null"</span>,
  alpha <span class='op'>=</span> <span class='cn'>NULL</span>,
  modelprior <span class='op'>=</span> <span class='fu'><a href='beta.binomial.html'>beta.binomial</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>,
  initprobs <span class='op'>=</span> <span class='st'>"Uniform"</span>,
  include.always <span class='op'>=</span> <span class='op'>~</span><span class='fl'>1</span>,
  method <span class='op'>=</span> <span class='st'>"BAS"</span>,
  update <span class='op'>=</span> <span class='cn'>NULL</span>,
  bestmodel <span class='op'>=</span> <span class='cn'>NULL</span>,
  prob.local <span class='op'>=</span> <span class='fl'>0</span>,
  prob.rw <span class='op'>=</span> <span class='fl'>0.5</span>,
  MCMC.iterations <span class='op'>=</span> <span class='cn'>NULL</span>,
  lambda <span class='op'>=</span> <span class='cn'>NULL</span>,
  delta <span class='op'>=</span> <span class='fl'>0.025</span>,
  thin <span class='op'>=</span> <span class='fl'>1</span>,
  renormalize <span class='op'>=</span> <span class='cn'>FALSE</span>,
  force.heredity <span class='op'>=</span> <span class='cn'>FALSE</span>,
  pivot <span class='op'>=</span> <span class='cn'>TRUE</span>,
  tol <span class='op'>=</span> <span class='fl'>1e-07</span>,
  bigmem <span class='op'>=</span> <span class='cn'>FALSE</span>
<span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>formula</th>
      <td><p>linear model formula for the full model with all predictors,
Y ~ X.  All code assumes that an intercept will be included in each model
and that the X's will be centered.</p></td>
    </tr>
    <tr>
      <th>data</th>
      <td><p>a data frame.  Factors will be converted to numerical vectors based on
the using `model.matrix`.</p></td>
    </tr>
    <tr>
      <th>subset</th>
      <td><p>an optional vector specifying a subset of observations to be
used in the fitting process.</p></td>
    </tr>
    <tr>
      <th>weights</th>
      <td><p>an optional vector of weights to be used in the fitting
process. Should be NULL or a numeric vector. If non-NULL, Bayes estimates
are obtained assuming that Y ~ N(Xb, sigma^2 diag(1/weights)).</p></td>
    </tr>
    <tr>
      <th>contrasts</th>
      <td><p>an optional list. See the contrasts.arg of `model.matrix.default()`.</p></td>
    </tr>
    <tr>
      <th>na.action</th>
      <td><p>a function which indicates what should happen when the data
contain NAs. The default is "na.omit".</p></td>
    </tr>
    <tr>
      <th>n.models</th>
      <td><p>number of models to sample either without replacement
(method="BAS" or "MCMC+BAS") or with replacement (method="MCMC"). If NULL,
BAS with method="BAS" will try to enumerate all 2^p models. If enumeration
is not possible (memory or time) then a value should be supplied which
controls the number of sampled models using 'n.models'.  With method="MCMC",
sampling will stop once the min(n.models, MCMC.iterations) occurs so
MCMC.iterations be significantly larger than n.models in order to explore the model space.
On exit for method= "MCMC" this is the number of unique models that have
been sampled with counts stored in the output as "freq".</p></td>
    </tr>
    <tr>
      <th>prior</th>
      <td><p>prior distribution for regression coefficients.  Choices
include</p><ul>
<li><p>"AIC"</p></li>
<li><p>"BIC"</p></li>
<li><p>"g-prior", Zellner's g prior where `g` is specified using the argument `alpha`</p></li>
<li><p>"JZS"  Jeffreys-Zellner-Siow prior which uses the Jeffreys
prior on sigma and the Zellner-Siow Cauchy prior on the coefficients.
The optional parameter `alpha` can be used to control
the squared scale of the prior, where the default is alpha=1. Setting
`alpha` is equal to rscale^2 in the BayesFactor package of Morey.
This uses QUADMATH for numerical integration of g.</p></li>
<li><p>"ZS-null", a Laplace approximation to the 'JZS' prior
for integration of g.  alpha = 1 only. We recommend
using 'JZS' for accuracy and compatibility
with the BayesFactor package, although it is
slower.</p></li>
<li><p>"ZS-full" (to be deprecated)</p></li>
<li><p>"hyper-g", a mixture of g-priors where the prior on
g/(1+g) is a Beta(1, alpha/2) as in Liang et al (2008).  This
uses the Cephes library for evaluation of the marginal
likelihoods and may be numerically unstable for
large n or R2 close to 1.  Default choice of alpha is 3.</p></li>
<li><p>"hyper-g-laplace", Same as above but using a Laplace
approximation to integrate over the prior on g.</p></li>
<li><p>"hyper-g-n", a mixture of g-priors that where
u = g/n and u ~ Beta(1, alpha/2)  to provide consistency
when the null model is true.</p></li>
<li><p>"EB-local", use the MLE of g from the marginal likelihood
within each model</p></li>
<li><p>"EB-global" uses an EM algorithm to find a common or
global estimate of g, averaged over all models.  When it is not possible to
enumerate all models, the EM algorithm uses only the
models sampled under EB-local.</p></li>
</ul></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>optional hyperparameter in g-prior or hyper g-prior.  For
Zellner's g-prior, alpha = g, for the Liang et al hyper-g or hyper-g-n
method, recommended choice is alpha are between (2 &lt; alpha &lt; 4), with alpha
= 3 the default.  For the Zellner-Siow prior alpha = 1 by default, but can be used
to modify the rate parameter in the gamma prior on g,  1/g ~ G(1/2, n*alpha/2) so that
beta ~ C(0, sigma^2 alpha (X'X/n)^-1).</p></td>
    </tr>
    <tr>
      <th>modelprior</th>
      <td><p>Family of prior distribution on the models.  Choices
include <code><a href='uniform.html'>uniform</a></code> <code><a href='Bernoulli.html'>Bernoulli</a></code> or
<code><a href='beta.binomial.html'>beta.binomial</a></code>, <code><a href='tr.beta.binomial.html'>tr.beta.binomial</a></code>,
(with truncation) <code><a href='tr.poisson.html'>tr.poisson</a></code> (a truncated Poisson), and
<code><a href='tr.power.prior.html'>tr.power.prior</a></code> (a truncated power family),
 with the default being a
<code><a href='beta.binomial.html'>beta.binomial(1,1)</a></code>.  Truncated versions are useful for p &gt; n.</p></td>
    </tr>
    <tr>
      <th>initprobs</th>
      <td><p>Vector of length p or a character string specifying which
method is used to create the vector. This is used to order variables for
sampling all methods for potentially more efficient storage while sampling
and provides the initial inclusion probabilities used for sampling without
replacement with method="BAS".  Options for the character string giving the
method are: "Uniform" or "uniform" where each predictor variable is equally
likely to be sampled (equivalent to random sampling without replacement);
"eplogp" uses the <code><a href='eplogprob.html'>eplogprob</a></code> function to approximate the Bayes
factor from p-values from the full model to find initial marginal inclusion
probabilities; "marg-eplogp" uses<code><a href='eplogprob.marg.html'>eplogprob.marg</a></code> function to
approximate the Bayes factor from p-values from the full model each simple
linear regression.  To run a Markov Chain to provide initial estimates of
marginal inclusion probabilities for "BAS", use method="MCMC+BAS" below.
While the initprobs are not used in sampling for method="MCMC", this
determines the order of the variables in the lookup table and affects memory
allocation in large problems where enumeration is not feasible.  For
variables that should always be included set the corresponding initprobs to
1, to override the `modelprior` or use `include.always` to force these variables
to always be included in the model.</p></td>
    </tr>
    <tr>
      <th>include.always</th>
      <td><p>A formula with terms that should always be included
in the model with probability one.  By default this is `~ 1` meaning that the
intercept is always included.  This will also override any of the values in `initprobs`
above by setting them to 1.</p></td>
    </tr>
    <tr>
      <th>method</th>
      <td><p>A character variable indicating which sampling method to use:</p><ul>
<li><p>"deterministic" uses the "top k" algorithm described in Ghosh and Clyde (2011)
to sample models in order of approximate probability under conditional independence
using the "initprobs".  This is the most efficient algorithm for enumeration.</p></li>
<li><p>"BAS" uses Bayesian Adaptive Sampling (without replacement) using the
sampling probabilities given in initprobs under a model of conditional independence.
These can be updated based on estimates of the marginal inclusion probabilities.</p></li>
<li><p>"MCMC" samples with
replacement via a MCMC algorithm that combines the birth/death random walk
in Hoeting et al (1997) of MC3 with a random swap move to interchange a
variable in the model with one currently excluded as described in Clyde,
Ghosh and Littman (2010).</p></li>
<li><p>"MCMC+BAS" runs an initial MCMC to
calculate marginal inclusion probabilities and then samples without
replacement as in BAS.  For BAS, the sampling probabilities can be updated
as more models are sampled. (see update below).</p></li>
</ul></td>
    </tr>
    <tr>
      <th>update</th>
      <td><p>number of iterations between potential updates of the sampling
probabilities for method "BAS" or "MCMC+BAS". If NULL do not update, otherwise the
algorithm will update using the marginal inclusion probabilities as they
change while sampling takes place.  For large model spaces, updating is
recommended. If the model space will be enumerated, leave at the default.</p></td>
    </tr>
    <tr>
      <th>bestmodel</th>
      <td><p>optional binary vector representing a model to initialize
the sampling. If NULL sampling starts with the null model</p></td>
    </tr>
    <tr>
      <th>prob.local</th>
      <td><p>A future option to allow sampling of models "near" the
median probability model.  Not used at this time.</p></td>
    </tr>
    <tr>
      <th>prob.rw</th>
      <td><p>For any of the MCMC methods, probability of using the
random-walk Metropolis proposal; otherwise use a random "flip" move
to propose swap a variable that is excluded with a variable in the model.</p></td>
    </tr>
    <tr>
      <th>MCMC.iterations</th>
      <td><p>Number of iterations for the MCMC sampler; the
default is n.models*10 if not set by the user.</p></td>
    </tr>
    <tr>
      <th>lambda</th>
      <td><p>Parameter in the AMCMC algorithm (deprecated).</p></td>
    </tr>
    <tr>
      <th>delta</th>
      <td><p>truncation parameter to prevent sampling probabilities to
degenerate to 0 or 1 prior to enumeration for sampling without replacement.</p></td>
    </tr>
    <tr>
      <th>thin</th>
      <td><p>For "MCMC", thin the MCMC chain every "thin" iterations; default is no
thinning.  For large p, thinning can be used to significantly reduce memory
requirements as models and associated summaries are saved only every thin iterations.  For thin = p, the  model and associated output are recorded every p iterations,
similar to the Gibbs sampler in SSVS.</p></td>
    </tr>
    <tr>
      <th>renormalize</th>
      <td><p>For MCMC sampling, should posterior probabilities be
based on renormalizing the marginal likelihoods times prior probabilities
(TRUE) or frequencies from MCMC.  The latter are unbiased in long runs,
while the former may have less variability.  May be compared via the
diagnostic plot function <code><a href='diagnostics.html'>diagnostics</a></code>.
See details in Clyde and Ghosh (2012).</p></td>
    </tr>
    <tr>
      <th>force.heredity</th>
      <td><p>Logical variable to force all levels of a factor to be
included together and to include higher order interactions only if lower
order terms are included.  Currently supported with `method='MCMC'`
and experimentally with `method='BAS'` on non-Solaris platforms.
Default is FALSE.</p></td>
    </tr>
    <tr>
      <th>pivot</th>
      <td><p>Logical variable to allow pivoting of columns when obtaining the
OLS estimates of a model so that models that are not full rank can be fit.
Defaults to TRUE.
Currently coefficients that are not estimable are set to zero.  Use caution with
interpreting BMA estimates of parameters.</p></td>
    </tr>
    <tr>
      <th>tol</th>
      <td><p>1e-7 as</p></td>
    </tr>
    <tr>
      <th>bigmem</th>
      <td><p>Logical variable to indicate that there is access to
large amounts of memory (physical or virtual) for enumeration
with large model spaces, e.g. &gt; 2^25. default; used in determining rank of X^TX in cholesky
decomposition
with pivoting.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p><code>bas</code> returns an object of class <code>bas</code></p>
<p>An object of class <code>BAS</code> is a list containing at least the following
components:</p>
<dt>postprob</dt><dd><p>the posterior probabilities of the models selected</p></dd>
<dt>priorprobs</dt><dd><p>the prior probabilities of the models selected</p></dd>
<dt>namesx</dt><dd><p>the names of the variables</p></dd>
<dt>R2</dt><dd><p>R2 values for the
models</p></dd>
<dt>logmarg</dt><dd><p>values of the log of the marginal likelihood for the
models.  This is equivalent to the log Bayes Factor for comparing
each model to a base model with intercept only.</p></dd>
<dt>n.vars</dt><dd><p>total number of independent variables in the full
model, including the intercept</p></dd>
<dt>size</dt><dd><p>the number of independent
variables in each of the models, includes the intercept</p></dd>
 <dt>rank</dt><dd><p>the rank of the design matrix; if `pivot = FALSE`, this is the same as size
 as no checking of rank is conducted.</p></dd>
<dt>which</dt><dd><p>a list
of lists with one list per model with variables that are included in the
model</p></dd>
<dt>probne0</dt><dd><p>the posterior probability that each variable is
non-zero computed using the renormalized marginal likelihoods of sampled
models.  This may be biased if the number of sampled models is much smaller
than the total number of models. Unbiased estimates may be obtained using
method "MCMC".</p></dd>
<dt>mle</dt><dd><p>list of lists with one list per model giving the
MLE (OLS) estimate of each (nonzero) coefficient for each model. NOTE: The
intercept is the mean of Y as each column of X has been centered by
subtracting its mean.</p></dd>
<dt>mle.se</dt><dd><p>list of lists with one list per model
giving the MLE (OLS) standard error of each coefficient for each model</p></dd>
<dt>prior</dt><dd><p>the name of the prior that created the BMA object</p></dd>
<dt>alpha</dt><dd><p>value of hyperparameter in coefficient prior used to create the BMA
object.</p></dd>
<dt>modelprior</dt><dd><p>the prior distribution on models that created the
BMA object</p></dd>
<dt>Y</dt><dd><p>response</p></dd>
<dt>X</dt><dd><p>matrix of predictors</p></dd>
<dt>mean.x</dt><dd><p>vector of means for each column of X (used in
<code><a href='predict.bas.html'>predict.bas</a></code>)</p></dd>
weights used in model fitting
<dt>include.always</dt><dd><p>indices of variables that are forced into the model</p></dd>

The function <a href='summary.bas.html'>summary.bas</a>, is used to print a summary of the
results. The function <a href='plot.bas.html'>plot.bas</a> is used to plot posterior
distributions for the coefficients and <a href='image.bas.html'>image.bas</a> provides an
image of the distribution over models.  Posterior summaries of coefficients
can be extracted using <a href='coef.bas.html'>coefficients.bas</a>.  Fitted values and
predictions can be obtained using the S3 functions <a href='fitted.bas.html'>fitted.bas</a>
and <a href='predict.bas.html'>predict.bas</a>.  BAS objects may be updated to use a
different prior (without rerunning the sampler) using the function
<a href='update.bas.html'>update.bas</a>. For MCMC sampling <a href='diagnostics.html'>diagnostics</a> can be used
to assess whether the MCMC has run long enough so that the posterior probabilities
are stable. For more details see the associated demos and vignette.

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>BAS provides several algorithms to sample from posterior distributions
of models for
use in Bayesian Model Averaging or Bayesian variable selection. For p less than
20-25, BAS can enumerate all models depending on memory availability.  As BAS saves all
models, MLEs, standard errors, log marginal likelihoods, prior and posterior and  probabilities
memory requirements grow linearly with M*p where M is the number of models
and p is the number of predictors.  For example, enumeration with p=21 with 2,097,152 takes just under
2 Gigabytes on a 64 bit machine to store all summaries that would be needed for model averaging.
(A future version will likely include an option to not store all summaries if
users do not plan on using  model averaging or model selection on Best Predictive models.)
For larger p, BAS samples without replacement using random or deterministic
sampling. The Bayesian Adaptive Sampling algorithm of Clyde, Ghosh, Littman
(2010) samples models without replacement using the initial sampling
probabilities, and will optionally update the sampling probabilities every
"update" models using the estimated marginal inclusion probabilities. BAS
uses different methods to obtain the <code>initprobs</code>, which may impact the
results in high-dimensional problems. The deterministic sampler provides a
list of the top models in order of an approximation of independence using
the provided <code>initprobs</code>.  This may be effective after running the
other algorithms to identify high probability models and works well if the
correlations of variables are small to modest.
We recommend "MCMC" for
problems where enumeration is not feasible (memory or time constrained)
or even modest p if the number of
models sampled is not close to the number of possible models and/or there are significant
correlations among the predictors as the bias in estimates of inclusion
probabilities from "BAS" or "MCMC+BAS" may be large relative to the reduced
variability from using the normalized model probabilities as shown in Clyde and Ghosh, 2012.
Diagnostic plots with MCMC can be used to assess convergence.
For large problems we recommend thinning with MCMC to reduce memory requirements.
The priors on coefficients
include Zellner's g-prior, the Hyper-g prior (Liang et al 2008, the
Zellner-Siow Cauchy prior, Empirical Bayes (local and global) g-priors.  AIC
and BIC are also included, while a range of priors on the model space are available.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Clyde, M. Ghosh, J. and Littman, M. (2010) Bayesian Adaptive
Sampling for Variable Selection and Model Averaging. Journal of
Computational Graphics and Statistics.  20:80-101 <br />
<a href='https://dx.doi.org/10.1198/jcgs.2010.09049'>https://dx.doi.org/10.1198/jcgs.2010.09049</a></p>
<p>Clyde, M. and Ghosh. J. (2012) Finite population estimators in stochastic search variable selection.
Biometrika, 99 (4), 981-988. <a href='https://dx.doi.org/10.1093/biomet/ass040'>https://dx.doi.org/10.1093/biomet/ass040</a></p>
<p>Clyde, M. and George, E. I. (2004) Model Uncertainty. Statist. Sci., 19,
81-94. <br /> <a href='https://dx.doi.org/10.1214/088342304000000035'>https://dx.doi.org/10.1214/088342304000000035</a></p>
<p>Clyde, M. (1999) Bayesian Model Averaging and Model Search Strategies (with
discussion). In Bayesian Statistics 6. J.M. Bernardo, A.P. Dawid, J.O.
Berger, and A.F.M. Smith eds. Oxford University Press, pages 157-185.</p>
<p>Hoeting, J. A., Madigan, D., Raftery, A. E. and Volinsky, C. T. (1999)
Bayesian model averaging: a tutorial (with discussion). Statist. Sci., 14,
382-401. <br />
<a href='https://dx.doi.org/10.1214/ss/1009212519'>https://dx.doi.org/10.1214/ss/1009212519</a></p>
<p>Liang, F., Paulo, R., Molina, G., Clyde, M. and Berger, J.O. (2008) Mixtures
of g-priors for Bayesian Variable Selection. Journal of the American
Statistical Association.  103:410-423.  <br />
<a href='https://dx.doi.org/10.1198/016214507000001337'>https://dx.doi.org/10.1198/016214507000001337</a></p>
<p>Zellner, A. (1986) On assessing prior distributions and Bayesian regression
analysis with g-prior distributions. In Bayesian Inference and Decision
Techniques: Essays in Honor of Bruno de Finetti, pp. 233-243.
North-Holland/Elsevier.</p>
<p>Zellner, A. and Siow, A. (1980) Posterior odds ratios for selected
regression hypotheses. In Bayesian Statistics: Proceedings of the First
International Meeting held in Valencia (Spain), pp. 585-603.</p>
<p>Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., \&amp; Iverson, G.
(2009). Bayesian t-tests for accepting and rejecting the null hypothesis.
Psychonomic Bulletin &amp; Review, 16, 225-237</p>
<p>Rouder, J. N., Morey, R. D., Speckman, P. L., Province, J. M., (2012)
Default Bayes Factors for ANOVA Designs. Journal of Mathematical Psychology.
56.  p. 356-374.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='summary.bas.html'>summary.bas</a></code>, <code><a href='coef.bas.html'>coefficients.bas</a></code>,
<code><a href='print.bas.html'>print.bas</a></code>, <code><a href='predict.bas.html'>predict.bas</a></code>, <code><a href='fitted.bas.html'>fitted.bas</a></code>
<code><a href='plot.bas.html'>plot.bas</a></code>, <code><a href='image.bas.html'>image.bas</a></code>, <code><a href='eplogprob.html'>eplogprob</a></code>,
<code><a href='update.bas.html'>update.bas</a></code></p>
<p>Other bas methods: 
<code><a href='BAS.html'>BAS</a></code>,
<code><a href='coef.bas.html'>coef.bas</a>()</code>,
<code><a href='confint.coef.bas.html'>confint.coef.bas</a>()</code>,
<code><a href='confint.pred.bas.html'>confint.pred.bas</a>()</code>,
<code><a href='diagnostics.html'>diagnostics</a>()</code>,
<code><a href='extract_MPM.html'>extract_MPM</a>()</code>,
<code><a href='fitted.bas.html'>fitted.bas</a>()</code>,
<code><a href='force.heredity.bas.html'>force.heredity.bas</a>()</code>,
<code><a href='image.bas.html'>image.bas</a>()</code>,
<code><a href='plot.confint.bas.html'>plot.confint.bas</a>()</code>,
<code><a href='predict.basglm.html'>predict.basglm</a>()</code>,
<code><a href='predict.bas.html'>predict.bas</a>()</code>,
<code><a href='summary.bas.html'>summary.bas</a>()</code>,
<code><a href='update.bas.html'>update.bas</a>()</code>,
<code><a href='variable.names.pred.bas.html'>variable.names.pred.bas</a>()</code></p></div>
    <h2 class="hasAnchor" id="author"><a class="anchor" href="#author"></a>Author</h2>

    <p>Merlise Clyde (<a href='mailto:clyde@duke.edu'>clyde@duke.edu</a>) and Michael Littman</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://www.stats.ox.ac.uk/pub/MASS4/'>MASS</a></span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>UScrime</span><span class='op'>)</span>
<span class='va'>crime.bic</span> <span class='op'>&lt;-</span> <span class='fu'>bas.lm</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span> <span class='op'>~</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>M</span><span class='op'>)</span> <span class='op'>+</span> <span class='va'>So</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Ed</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Po1</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Po2</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>LF</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>M.F</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Pop</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>NW</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>U1</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>U2</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>GDP</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Ineq</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Prob</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Time</span><span class='op'>)</span>,
data <span class='op'>=</span> <span class='va'>UScrime</span>, n.models <span class='op'>=</span> <span class='fl'>2</span><span class='op'>^</span><span class='fl'>15</span>, prior <span class='op'>=</span> <span class='st'>"BIC"</span>,
modelprior <span class='op'>=</span> <span class='fu'><a href='beta.binomial.html'>beta.binomial</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>,
initprobs <span class='op'>=</span> <span class='st'>"eplogp"</span>, pivot <span class='op'>=</span> <span class='cn'>FALSE</span>
<span class='op'>)</span>


<span class='co'># use MCMC rather than enumeration</span>
<span class='va'>crime.mcmc</span> <span class='op'>&lt;-</span> <span class='fu'>bas.lm</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span> <span class='op'>~</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>M</span><span class='op'>)</span> <span class='op'>+</span> <span class='va'>So</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Ed</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Po1</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Po2</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>LF</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>M.F</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Pop</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>NW</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>U1</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>U2</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>GDP</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Ineq</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Prob</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>Time</span><span class='op'>)</span>,
data <span class='op'>=</span> <span class='va'>UScrime</span>,
method <span class='op'>=</span> <span class='st'>"MCMC"</span>,
MCMC.iterations <span class='op'>=</span> <span class='fl'>20000</span>, prior <span class='op'>=</span> <span class='st'>"BIC"</span>,
modelprior <span class='op'>=</span> <span class='fu'><a href='beta.binomial.html'>beta.binomial</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span>,
initprobs <span class='op'>=</span> <span class='st'>"eplogp"</span>, pivot <span class='op'>=</span> <span class='cn'>FALSE</span>
<span class='op'>)</span>

<span class='fu'><a href='summary.bas.html'>summary</a></span><span class='op'>(</span><span class='va'>crime.bic</span><span class='op'>)</span>
</div><div class='output co'>#&gt;           P(B != 0 | Y)   model 1       model 2     model 3     model 4
#&gt; Intercept     1.0000000   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(M)        0.9335117   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; So            0.3276563   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(Ed)       0.9910219   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(Po1)      0.7246635   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(Po2)      0.4602481   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(LF)       0.2935326   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(M.F)      0.3298168   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(Pop)      0.4962869   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(NW)       0.8346412   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(U1)       0.3481266   0.00000  1.000000e+00   0.0000000   0.0000000
#&gt; log(U2)       0.7752102   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(GDP)      0.5253694   0.00000  1.000000e+00   0.0000000   1.0000000
#&gt; log(Ineq)     0.9992058   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(Prob)     0.9541470   1.00000  1.000000e+00   1.0000000   1.0000000
#&gt; log(Time)     0.5432686   1.00000  1.000000e+00   0.0000000   1.0000000
#&gt; BF                   NA   1.00000  1.267935e-04   0.7609295   0.5431578
#&gt; PostProbs            NA   0.01910  1.560000e-02   0.0145000   0.0133000
#&gt; R2                   NA   0.84200  8.695000e-01   0.8265000   0.8506000
#&gt; dim                  NA   9.00000  1.600000e+01   8.0000000  10.0000000
#&gt; logmarg              NA -22.15855 -3.113150e+01 -22.4317627 -22.7689035
#&gt;               model 5
#&gt; Intercept   1.0000000
#&gt; log(M)      1.0000000
#&gt; So          0.0000000
#&gt; log(Ed)     1.0000000
#&gt; log(Po1)    1.0000000
#&gt; log(Po2)    0.0000000
#&gt; log(LF)     0.0000000
#&gt; log(M.F)    0.0000000
#&gt; log(Pop)    1.0000000
#&gt; log(NW)     1.0000000
#&gt; log(U1)     0.0000000
#&gt; log(U2)     1.0000000
#&gt; log(GDP)    0.0000000
#&gt; log(Ineq)   1.0000000
#&gt; log(Prob)   1.0000000
#&gt; log(Time)   0.0000000
#&gt; BF          0.5203179
#&gt; PostProbs   0.0099000
#&gt; R2          0.8375000
#&gt; dim         9.0000000
#&gt; logmarg   -22.8118635</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>crime.bic</span><span class='op'>)</span>
</div><div class='img'><img src='bas.lm-1.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-2.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-3.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-4.png' alt='' width='700' height='433' /></div><div class='input'><span class='fu'><a href='image.bas.html'>image</a></span><span class='op'>(</span><span class='va'>crime.bic</span>, subset <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1</span><span class='op'>)</span>
</div><div class='img'><img src='bas.lm-5.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'># example with two-way interactions and hierarchical constraints</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>ToothGrowth</span><span class='op'>)</span>
<span class='va'>ToothGrowth</span><span class='op'>$</span><span class='va'>dose</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>factor</a></span><span class='op'>(</span><span class='va'>ToothGrowth</span><span class='op'>$</span><span class='va'>dose</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/base/levels.html'>levels</a></span><span class='op'>(</span><span class='va'>ToothGrowth</span><span class='op'>$</span><span class='va'>dose</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"Low"</span>, <span class='st'>"Medium"</span>, <span class='st'>"High"</span><span class='op'>)</span>
<span class='va'>TG.bas</span> <span class='op'>&lt;-</span> <span class='fu'>bas.lm</span><span class='op'>(</span><span class='va'>len</span> <span class='op'>~</span> <span class='va'>supp</span> <span class='op'>*</span> <span class='va'>dose</span>,
  data <span class='op'>=</span> <span class='va'>ToothGrowth</span>,
  modelprior <span class='op'>=</span> <span class='fu'><a href='uniform.html'>uniform</a></span><span class='op'>(</span><span class='op'>)</span>, method <span class='op'>=</span> <span class='st'>"BAS"</span>,
  force.heredity <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>
<span class='fu'><a href='summary.bas.html'>summary</a></span><span class='op'>(</span><span class='va'>TG.bas</span><span class='op'>)</span>
</div><div class='output co'>#&gt;                   P(B != 0 | Y)  model 1    model 2     model 3      model 4
#&gt; Intercept             1.0000000  1.00000  1.0000000  1.00000000 1.000000e+00
#&gt; suppVC                0.9910702  1.00000  1.0000000  0.00000000 0.000000e+00
#&gt; doseMedium            1.0000000  1.00000  1.0000000  1.00000000 0.000000e+00
#&gt; doseHigh              1.0000000  1.00000  1.0000000  1.00000000 0.000000e+00
#&gt; suppVC:doseMedium     0.4500943  0.00000  1.0000000  0.00000000 0.000000e+00
#&gt; suppVC:doseHigh       0.4500943  0.00000  1.0000000  0.00000000 0.000000e+00
#&gt; BF                           NA  1.00000  0.8320043  0.01650685 2.812754e-15
#&gt; PostProbs                    NA  0.54100  0.4501000  0.00890000 0.000000e+00
#&gt; R2                           NA  0.76230  0.7937000  0.70290000 0.000000e+00
#&gt; dim                          NA  4.00000  6.0000000  3.00000000 1.000000e+00
#&gt; logmarg                      NA 33.50461 33.3206946 29.40063248 0.000000e+00
#&gt;                         model 5
#&gt; Intercept          1.000000e+00
#&gt; suppVC             1.000000e+00
#&gt; doseMedium         0.000000e+00
#&gt; doseHigh           0.000000e+00
#&gt; suppVC:doseMedium  0.000000e+00
#&gt; suppVC:doseHigh    0.000000e+00
#&gt; BF                 7.895214e-16
#&gt; PostProbs          0.000000e+00
#&gt; R2                 5.950000e-02
#&gt; dim                2.000000e+00
#&gt; logmarg           -1.270492e+00</div><div class='input'><span class='fu'><a href='image.bas.html'>image</a></span><span class='op'>(</span><span class='va'>TG.bas</span><span class='op'>)</span>
</div><div class='img'><img src='bas.lm-6.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'># exmple with non-full rank case</span>

 <span class='va'>loc</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/system.file.html'>system.file</a></span><span class='op'>(</span><span class='st'>"testdata"</span>, package <span class='op'>=</span> <span class='st'>"BAS"</span><span class='op'>)</span>
 <span class='va'>d</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/read.table.html'>read.csv</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste</a></span><span class='op'>(</span><span class='va'>loc</span>, <span class='st'>"JASP-testdata.csv"</span>, sep <span class='op'>=</span> <span class='st'>"/"</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>fullModelFormula</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/formula.html'>as.formula</a></span><span class='op'>(</span><span class='st'>"contNormal ~  contGamma * contExpon +
                                contGamma * contcor1 + contExpon * contcor1"</span><span class='op'>)</span>

<span class='co'># should give warning; use pivot = T to fit non-full rank case (fails on i386)</span>
 <span class='va'>out</span> <span class='op'>=</span> <span class='fu'>bas.lm</span><span class='op'>(</span><span class='va'>fullModelFormula</span>,
              data <span class='op'>=</span> <span class='va'>d</span>,
              alpha <span class='op'>=</span> <span class='fl'>0.125316</span>,
              prior <span class='op'>=</span> <span class='st'>"JZS"</span>,
              weights <span class='op'>=</span> <span class='va'>facFifty</span>, force.heredity <span class='op'>=</span> <span class='cn'>FALSE</span>, pivot <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='warning'>Warning: log marginals and posterior probabilities contain NA's.  Consider re-running with the option `pivot=TRUE` if there are models that are not full rank</span></div><div class='input'>

<span class='co'># use pivot = TRUE to fit non-full rank case  (default)</span>
<span class='co'># This is slower but safer</span>

<span class='va'>out</span> <span class='op'>=</span>  <span class='fu'>bas.lm</span><span class='op'>(</span><span class='va'>fullModelFormula</span>,
              data <span class='op'>=</span> <span class='va'>d</span>,
              alpha <span class='op'>=</span> <span class='fl'>0.125316</span>,
              prior <span class='op'>=</span> <span class='st'>"JZS"</span>,
              weights <span class='op'>=</span> <span class='va'>facFifty</span>, force.heredity <span class='op'>=</span> <span class='cn'>FALSE</span>, pivot <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>

<span class='co'># more complete demo's</span>
<span class='fu'><a href='https://rdrr.io/r/utils/demo.html'>demo</a></span><span class='op'>(</span><span class='va'>BAS.hald</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 
#&gt; 
#&gt; 	demo(BAS.hald)
#&gt; 	---- ~~~~~~~~
#&gt; 
#&gt; &gt; data(Hald)
#&gt; 
#&gt; &gt; hald.gprior =  bas.lm(Y~ ., data=Hald, prior="g-prior", alpha=13,
#&gt; +                       modelprior=beta.binomial(1,1),
#&gt; +                       initprobs="eplogp")
#&gt; 
#&gt; &gt; hald.gprior
#&gt; 
#&gt; Call:
#&gt; bas.lm(formula = Y ~ ., data = Hald, prior = "g-prior", alpha = 13, 
#&gt;     modelprior = beta.binomial(1, 1), initprobs = "eplogp")
#&gt; 
#&gt; 
#&gt;  Marginal Posterior Inclusion Probabilities: 
#&gt; Intercept         X1         X2         X3         X4  
#&gt;    1.0000     0.9019     0.6896     0.4653     0.6329  
#&gt; 
#&gt; &gt; plot(hald.gprior)</div><div class='img'><img src='bas.lm-7.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-8.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-9.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-10.png' alt='' width='700' height='433' /></div><div class='output co'>#&gt; 
#&gt; &gt; summary(hald.gprior)
#&gt;           P(B != 0 | Y)  model 1    model 2    model 3    model 4    model 5
#&gt; Intercept     1.0000000  1.00000  1.0000000 1.00000000  1.0000000  1.0000000
#&gt; X1            0.9019245  1.00000  1.0000000 1.00000000  1.0000000  1.0000000
#&gt; X2            0.6895830  1.00000  0.0000000 1.00000000  1.0000000  1.0000000
#&gt; X3            0.4652762  0.00000  0.0000000 1.00000000  0.0000000  1.0000000
#&gt; X4            0.6329266  0.00000  1.0000000 1.00000000  1.0000000  0.0000000
#&gt; BF                   NA  1.00000  0.6923944 0.08991408  0.3355714  0.3344926
#&gt; PostProbs            NA  0.24320  0.1684000 0.13120000  0.1224000  0.1220000
#&gt; R2                   NA  0.97870  0.9725000 0.98240000  0.9823000  0.9823000
#&gt; dim                  NA  3.00000  3.0000000 5.00000000  4.0000000  4.0000000
#&gt; logmarg              NA 11.72735 11.3597547 9.31845348 10.6354335 10.6322138
#&gt; 
#&gt; &gt; image(hald.gprior, subset=-1, vlas=0)</div><div class='img'><img src='bas.lm-11.png' alt='' width='700' height='433' /></div><div class='output co'>#&gt; 
#&gt; &gt; hald.coef = coefficients(hald.gprior)
#&gt; 
#&gt; &gt; hald.coef
#&gt; 
#&gt;  Marginal Posterior Summaries of Coefficients: 
#&gt; 
#&gt;  Using  BMA 
#&gt; 
#&gt;  Based on the top  16 models 
#&gt;            post mean  post SD  post p(B != 0)
#&gt; Intercept  95.4231     0.7107   1.0000       
#&gt; X1          1.2150     0.5190   0.9019       
#&gt; X2          0.2756     0.4832   0.6896       
#&gt; X3         -0.1271     0.4976   0.4653       
#&gt; X4         -0.3269     0.4717   0.6329       
#&gt; 
#&gt; &gt; plot(hald.coef)</div><div class='img'><img src='bas.lm-12.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-13.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-14.png' alt='' width='700' height='433' /></div><div class='img'><img src='bas.lm-15.png' alt='' width='700' height='433' /></div><div class='output co'>#&gt; 
#&gt; &gt; predict(hald.gprior, top=5, se.fit=TRUE)  
#&gt; $fit
#&gt;  [1]  79.74246  74.50010 105.29268  89.88693  95.57177 104.56409 103.40145
#&gt;  [8]  77.13668  91.99731 114.21325  82.78446 111.00723 110.40160
#&gt; 
#&gt; $Ybma
#&gt;            [,1]
#&gt;  [1,]  79.74246
#&gt;  [2,]  74.50010
#&gt;  [3,] 105.29268
#&gt;  [4,]  89.88693
#&gt;  [5,]  95.57177
#&gt;  [6,] 104.56409
#&gt;  [7,] 103.40145
#&gt;  [8,]  77.13668
#&gt;  [9,]  91.99731
#&gt; [10,] 114.21325
#&gt; [11,]  82.78446
#&gt; [12,] 111.00723
#&gt; [13,] 110.40160
#&gt; 
#&gt; $Ypred
#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 81.17036 74.83464 105.0725 89.69881 97.15898 104.4575 103.3893 76.06454
#&gt; [2,] 77.70296 74.24113 105.8554 90.46267 93.09565 104.7152 103.1399 78.80193
#&gt; [3,] 79.70437 74.40553 105.2175 89.76253 95.63309 104.5709 103.5254 77.08557
#&gt; [4,] 79.65151 74.47846 105.4218 89.83174 95.62799 104.5962 103.5068 77.00839
#&gt; [5,] 79.84321 74.31409 104.9063 89.65651 95.70301 104.5285 103.5476 77.15919
#&gt;          [,9]    [,10]    [,11]    [,12]    [,13]
#&gt; [1,] 91.57174 113.1722 81.59906 111.2219 111.0884
#&gt; [2,] 92.68123 115.8058 84.50293 110.4162 109.0791
#&gt; [3,] 91.98604 114.1759 82.78145 111.1196 110.5321
#&gt; [4,] 92.07571 114.1088 82.68233 111.0429 110.4674
#&gt; [5,] 91.83513 114.2353 82.88128 111.2384 110.6515
#&gt; 
#&gt; $postprobs
#&gt; [1] 0.3089304 0.2139017 0.1666632 0.1555023 0.1550024
#&gt; 
#&gt; $se.fit
#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 2.220164 2.265862 1.546911 2.181188 1.310135 1.523300 2.655096 2.176560
#&gt; [2,] 2.716798 2.389723 1.633637 2.179215 1.321062 1.581232 2.721957 2.078129
#&gt; [3,] 3.203405 2.501485 3.279273 2.357164 2.589756 1.549136 2.623290 2.765255
#&gt; [4,] 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817
#&gt; [5,] 2.932580 2.353352 1.538009 2.141694 2.507848 1.498758 2.616407 2.680289
#&gt;          [,9]    [,10]    [,11]    [,12]    [,13]
#&gt; [1,] 1.883610 3.264656 1.908238 1.970691 2.054234
#&gt; [2,] 2.013244 3.298134 1.933819 1.964374 1.924460
#&gt; [3,] 2.353516 3.609909 2.821295 2.227363 2.390135
#&gt; [4,] 1.990817 3.485929 2.456636 1.951456 2.212238
#&gt; [5,] 1.889302 3.569065 2.665166 1.934336 2.117189
#&gt; 
#&gt; $se.pred
#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 5.057182 5.077410 4.799885 5.040193 4.728892 4.792328 5.262651 5.038191
#&gt; [2,] 5.415848 5.259391 4.961773 5.167146 4.867815 4.944766 5.418438 5.125333
#&gt; [3,] 5.489152 5.111401 5.533771 5.042342 5.155175 4.718984 5.172102 5.245534
#&gt; [4,] 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065
#&gt; [5,] 5.337427 5.042456 4.717369 4.947217 5.116386 4.704719 5.170463 5.203081
#&gt;          [,9]    [,10]    [,11]    [,12]    [,13]
#&gt; [1,] 4.918734 5.594992 4.928218 4.952735 4.986566
#&gt; [2,] 5.099370 5.729582 5.068538 5.080274 5.064974
#&gt; [3,] 5.040638 5.735890 5.275291 4.982985 5.057839
#&gt; [4,] 4.882702 5.659428 5.090431 4.866787 4.977090
#&gt; [5,] 4.843301 5.711946 5.195307 4.861045 4.936658
#&gt; 
#&gt; $se.bma.fit
#&gt;  [1] 2.688224 2.095245 1.769625 1.970919 2.197285 1.363804 2.356457 2.302631
#&gt;  [9] 1.822084 3.141443 2.237663 1.801849 1.991374
#&gt; 
#&gt; $se.bma.pred
#&gt;  [1] 4.838655 4.536087 4.395180 4.480017 4.584113 4.248058 4.662502 4.635531
#&gt;  [9] 4.416563 5.104380 4.603604 4.408253 4.489054
#&gt; 
#&gt; $df
#&gt; [1] 12 12 12 12 12
#&gt; 
#&gt; $best
#&gt; [1]  7  3 12 14  8
#&gt; 
#&gt; $bestmodel
#&gt; $bestmodel[[1]]
#&gt; [1] 0 1 2
#&gt; 
#&gt; $bestmodel[[2]]
#&gt; [1] 0 1 4
#&gt; 
#&gt; $bestmodel[[3]]
#&gt; [1] 0 1 2 3 4
#&gt; 
#&gt; $bestmodel[[4]]
#&gt; [1] 0 1 2 4
#&gt; 
#&gt; $bestmodel[[5]]
#&gt; [1] 0 1 2 3
#&gt; 
#&gt; 
#&gt; $best.vars
#&gt; [1] "Intercept" "X1"        "X2"        "X3"        "X4"       
#&gt; 
#&gt; $estimator
#&gt; [1] "BMA"
#&gt; 
#&gt; attr(,"class")
#&gt; [1] "pred.bas"
#&gt; 
#&gt; &gt; confint(predict(hald.gprior, Hald, estimator="BMA", se.fit=TRUE, top=5), parm="mean")
#&gt;            2.5%     97.5%      mean
#&gt;  [1,]  73.14344  85.98936  79.74246
#&gt;  [2,]  69.17879  79.54704  74.50010
#&gt;  [3,] 100.84534 109.49004 105.29268
#&gt;  [4,]  85.24164  94.79407  89.88693
#&gt;  [5,]  90.59779 100.36471  95.57177
#&gt;  [6,] 101.02479 107.78653 104.56409
#&gt;  [7,]  97.47160 109.01169 103.40145
#&gt;  [8,]  71.67868  82.61563  77.13668
#&gt;  [9,]  87.57661  96.30489  91.99731
#&gt; [10,] 106.59779 121.77646 114.21325
#&gt; [11,]  77.65505  88.21687  82.78446
#&gt; [12,] 106.70258 115.53730 111.00723
#&gt; [13,] 105.64711 115.13696 110.40160
#&gt; attr(,"Probability")
#&gt; [1] 0.95
#&gt; attr(,"class")
#&gt; [1] "confint.bas"
#&gt; 
#&gt; &gt; predict(hald.gprior, estimator="MPM", se.fit=TRUE)  
#&gt; $fit
#&gt;  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684
#&gt;  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741
#&gt; 
#&gt; $Ybma
#&gt;            [,1]
#&gt;  [1,]  79.65151
#&gt;  [2,]  74.47846
#&gt;  [3,] 105.42183
#&gt;  [4,]  89.83174
#&gt;  [5,]  95.62799
#&gt;  [6,] 104.59616
#&gt;  [7,] 103.50684
#&gt;  [8,]  77.00839
#&gt;  [9,]  92.07571
#&gt; [10,] 114.10876
#&gt; [11,]  82.68233
#&gt; [12,] 111.04286
#&gt; [13,] 110.46741
#&gt; 
#&gt; $Ypred
#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 79.65151 74.47846 105.4218 89.83174 95.62799 104.5962 103.5068 77.00839
#&gt;          [,9]    [,10]    [,11]    [,12]    [,13]
#&gt; [1,] 92.07571 114.1088 82.68233 111.0429 110.4674
#&gt; 
#&gt; $postprobs
#&gt; [1] 1
#&gt; 
#&gt; $se.fit
#&gt; numeric(0)
#&gt; 
#&gt; $se.pred
#&gt; numeric(0)
#&gt; 
#&gt; $se.bma.fit
#&gt; NULL
#&gt; 
#&gt; $se.bma.pred
#&gt; NULL
#&gt; 
#&gt; $df
#&gt; [1] 12
#&gt; 
#&gt; $best
#&gt; [1] 1
#&gt; 
#&gt; $bestmodel
#&gt; $bestmodel[[1]]
#&gt; [1] 0 1 2 4
#&gt; 
#&gt; 
#&gt; $best.vars
#&gt; [1] "Intercept" "X1"        "X2"        "X3"        "X4"       
#&gt; 
#&gt; $estimator
#&gt; [1] "MPM"
#&gt; 
#&gt; attr(,"class")
#&gt; [1] "pred.bas"
#&gt; 
#&gt; &gt; confint(predict(hald.gprior, Hald, estimator="MPM", se.fit=TRUE), parm="mean")</div><div class='output co'>#&gt; <span class='warning'>Warning: number of rows of result is not a multiple of vector length (arg 2)</span></div><div class='img'><img src='bas.lm-16.png' alt='' width='700' height='433' /></div><div class='output co'>#&gt;      2.5% 97.5% mean
#&gt; attr(,"Probability")
#&gt; [1] 0.95
#&gt; attr(,"class")
#&gt; [1] "confint.bas"
#&gt; 
#&gt; &gt; fitted(hald.gprior, estimator="HPM")
#&gt;  [1]  81.17036  74.83464 105.07248  89.69881  97.15898 104.45753 103.38927
#&gt;  [8]  76.06454  91.57174 113.17222  81.59906 111.22195 111.08841
#&gt; 
#&gt; &gt; hald.gprior =  bas.lm(Y~ ., data=Hald, n.models=2^4,
#&gt; +                       prior="g-prior", alpha=13, modelprior=uniform(),
#&gt; +                       initprobs="eplogp")
#&gt; 
#&gt; &gt; hald.EB = update(hald.gprior, newprior="EB-global")
#&gt; 
#&gt; &gt; hald.bic = update(hald.gprior,newprior="BIC")
#&gt; 
#&gt; &gt; hald.zs = update(hald.bic, newprior="ZS-null")</div><div class='input'><span class='kw'>if</span> <span class='op'>(</span><span class='cn'>FALSE</span><span class='op'>)</span> <span class='op'>{</span>
<span class='fu'><a href='https://rdrr.io/r/utils/demo.html'>demo</a></span><span class='op'>(</span><span class='va'>BAS.USCrime</span><span class='op'>)</span>
<span class='op'>}</span>

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by <a href='http://stat.duke.edu/~clyde'>Merlise Clyde</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script>
<script>
  docsearch({
    
    
    apiKey: '94a8229a313e5475acdeffd26558ce98',
    indexName: 'bas',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>



  </body>
</html>



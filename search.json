[{"path":[]},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team clyde@duke.edu. project team review investigate complaints, respond way deems appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"http://merliseclyde.github.io/BAS/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to BAS development","title":"Contributing to BAS development","text":"goal guide help contribute BAS. guide divided three main pieces: Filing bug report feature request issue Github. Suggesting change via pull request. Coding Style Guide Contributions BAS","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":"feature-requests","dir":"","previous_headings":"Issues","what":"Feature Requests","title":"Contributing to BAS development","text":"wish easily extract additional information BAS objects ? like see new functionality available BAS? , feel free fill feature request! Please describe much detail like added. can anything just idea code advanced user!","code":""},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":"bug-reports","dir":"","previous_headings":"Issues","what":"Bug Reports","title":"Contributing to BAS development","text":"filing bug report issue, important thing include minimal reproducible example can quickly verify problem, figure fix . three things need include make example reproducible: required packages, data, code. Packages loaded top script, ’s easy see ones example needs. easiest way include data use dput() generate R code recreate . example, recreate mtcars dataset R, ’d perform following steps: Run dput(mtcars) R Copy output reproducible script, type mtcars <- paste. even better can create data.frame() just handful rows columns still illustrates problem. Spend little bit time ensuring code easy others read: make sure ’ve used spaces variable names concise, informative (OK using “.”, camel case “_” variable names improve readibility. details see Style Guide use comments indicate problem lies best remove everything related problem. shorter code , easier understand. can check actually made reproducible example starting fresh R session pasting script . (Unless ’ve specifically asked , please don’t include output sessionInfo().)","code":""},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":"other-issues","dir":"","previous_headings":"Issues","what":"Other issues","title":"Contributing to BAS development","text":"sure something bug undocumented feature, see possible errors help files documentation use clarification (issue) please file regular issue","code":""},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to BAS development","text":"contribute change BAS, follow steps: Create branch git make changes, ideally using commit -s sign-commits Developer Certificate Origin. Make sure branch passes R CMD check. Push branch github issue pull request (PR). Discuss pull request. Iterate either accept PR decide ’s good fit BAS. steps described detail . might feel overwhelming first time get set , gets easier practice. get stuck point, please reach help. ’re familiar git github, please start reading http://r-pkgs..co.nz/git.html Pull requests evaluated following checklist: Motivation. pull request clearly concisely motivates need change. Please describe problem show pull request solves concisely possible. Also include motivation NEWS new release BAS comes ’s easy users see ’s changed. Add item top file use markdown formatting. news item end (@yourGithubUsername, #the_issue_number). related changes. submit pull request, please check make sure haven’t accidentally included unrelated changes. make harder see exactly ’s changed, evaluate unexpected side effects. PR corresponds git branch, expect submit multiple changes make sure create multiple branches. multiple changes depend , start first one don’t submit others first one processed. Document ’re adding new parameters new function, ’ll also need document roxygen. Please add short example appropriate function optionally package vignettes. Make sure re-run devtools::document() code submitting. (sure include name authors function!) Testing fixing bug adding new feature, add testthat unit test. seems like lot work don’t worry pull request isn’t perfect. ’s learning process hand help . pull request process, unless ’ve submitted past ’s unlikely pull request accepted . Please don’t submit pull requests change existing behaviour. Instead, think can add new feature minimally invasive way.","code":""},{"path":"http://merliseclyde.github.io/BAS/CONTRIBUTING.html","id":"style-guide-for-contributing-to-bas","dir":"","previous_headings":"","what":"Style Guide for Contributing to BAS","title":"Contributing to BAS development","text":"consistent style improves readibility code. wed particular style generally draw Google Style Guide well Hadley Wickham’s Style Guide noted . Using package styler enforce styling based TidyVerse helpful, required. Function Variable names: Use informative names using “.”, camel case, “_” improve readibility, .e. variable.name, VariableName variable_name, rather foo xxx. tend avoid _ historical reasons going back S. Assignment: Use either <- = assignment consistent within contribution. many style guides prefer <- suggest using styler enforce use <-, OK = shorter type! Just consistent within contributed code. Spaces: Include spaces around operators =, +, -, <-,  == etc improve readibility. Put space comman, . : :: never spaces around . Additional spaces newlines fine improve readibilty code (e.g. aligmnent arguments). Comments: Comment code whenever can. Explain clear code. Use # start comment followed space capitalize first letter; short inline comments (comments line code) need two spaces # Curly Braces: opening curly brace never go line, closing curly brace go line. exception short conditional statement shuch else code may fit one line. Indentation: Use 2 spaces rather tabs per level indentation. Indent code inside curly braces. Semi-colons: use semi-colons put one statement line. Line Length: Use 80 characters per line code. RStudio setting display vertical line 80 characters visually assist . Turn going Tools -> Global Options… -> Code -> Display -> Show margin File names R code informative end .R. Use - improve readibility. include spaces file names! Contributing adopted ggplot2’s CONTRIBUTING.md","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/SECURITY.html","id":"supported-versions","dir":"","previous_headings":"","what":"Supported Versions","title":"Security Policy","text":"Supported security updates.","code":""},{"path":"http://merliseclyde.github.io/BAS/SECURITY.html","id":"reporting-a-vulnerability","dir":"","previous_headings":"","what":"Reporting a Vulnerability","title":"Security Policy","text":"Please submit vulnerability reports Github Issues maintainers address soon possibl","code":""},{"path":"http://merliseclyde.github.io/BAS/SECURITY.html","id":"expectations","dir":"","previous_headings":"","what":"Expectations","title":"Security Policy","text":"package utilizes C code efficiency allocates/frees memory. package checked memory leaks prior releases CRAN using ASAN/UBSBAN. package distributed via CRAN https://CRAN.R-project.org/package=bark reports additional checks. development version may installed GitHub https://github.com/merliseclyde/bark checked via github actions (users may check current version passing badge installing) Bugs reported via Issue tracker handled soon possible. (See link )","code":""},{"path":"http://merliseclyde.github.io/BAS/SECURITY.html","id":"assurance","dir":"","previous_headings":"","what":"Assurance","title":"Security Policy","text":"highly unlikely malicious code added package. submissions CRAN require verification via maintainer’s email, protected via two factor authentication. pull requests contributions github verified lead maintainer. Based Code Conduct Contributing Guidelines modifications include unit tests cover additional code blocks.","code":""},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"installing-bas","dir":"Articles","previous_headings":"","what":"Installing BAS","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"stable version can installed easily R console like package: hand, welcome everyone use recent version package quick-fixes, new features probably new bugs. get latest development version GitHub, use devtools package CRAN enter R: package depend BLAS LAPACK, installing GitHub require FORTRAN C compilers system.","code":"install.packages(\"BAS\") devtools::install_github(\"merliseclyde/BAS\")"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"demo","dir":"Articles","previous_headings":"","what":"Demo","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"use UScrime data illustrate commands functionality. Following analyses, go ahead log transform variables except column 2, indicator variable state southern state. get started, use BAS Zellner-Siow Cauchy prior coefficients. BAS uses model formula similar lm specify full model potential predictors. using shorthand . indicate remaining variables data frame provided data argument. Different prior distributions regression coefficients may specified using prior argument, include “BIC” “AIC “g-prior” “hyper-g” “hyper-g-laplace” “hyper-g-n” “JZS” “ZS-null” “ZS-full” “EB-local” “EB-global” default Zellner-Siow prior, ZS-null, Bayes factors compared null model. newest prior option, “JZS”, also corresponds Zellner-Siow prior coefficients, uses numerical integration rather Laplace approximation obtain marginal likelihood models. default, BAS try enumerate models \\(p < 19\\) using default method=\"BAS\". prior distribution models uniform() distribution assigns equal probabilities models. last optional argument initprobs = eplogp provides way initialize sampling algorithm order variables tree structure represents model space BAS. eplogp option uses Bayes factor calibration p-values \\(-e p \\log(p)\\) provide approximation marginal inclusion probability coefficient predictor zero, using p-values full model. options initprobs include “marg-eplogp”” “uniform” numeric vector length p option “marg-eplogp” uses p-values \\(p\\) simple linear regressions (useful large p highly correlated variables). Since enumerating possible models options important method=\"deterministic\" may faster factors interactions model.","code":"data(UScrime, package = \"MASS\") UScrime[, -2] <- log(UScrime[, -2]) library(BAS) crime.ZS <- bas.lm(y ~ .,   data = UScrime,   prior = \"ZS-null\",   modelprior = uniform(), initprobs = \"eplogp\",   force.heredity = FALSE, pivot = TRUE )"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"plots","dir":"Articles","previous_headings":"","what":"Plots","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"graphical summaries output may obtained plot function  produces panel four plots. first plot residuals fitted values Bayesian Model Averaging. Ideally, model assumptions hold, see outliers non-constant variance. second plot shows cumulative probability models order sampled. plot indicates cumulative probability leveling additional model adds small increment cumulative probability, earlier, larger jumps corresponding discovering new high probability model. third plot shows dimension model (number regression coefficients including intercept) versus log marginal likelihood model. last plot shows marginal posterior inclusion probabilities (pip) covariates, marginal pips greater 0.5 shown red. variables pip > 0.5 correspond known median probability model. Variables high inclusion probabilities generally important explaining data prediction, marginal inclusion probabilities may small predictors highly correlated, similar p-values may large presence multicollinearity. Individual plots may obtained using option.  BAS print summary methods defined objects class bas. Typing objects name returns summary marginal inclusion probabilities, summary function provides list top 5 models (terms posterior probability) zero-one indicators variable inclusion. columns summary Bayes factor model highest probability model (hence Bayes factor 1), posterior probabilities models, ordinary \\(R^2\\) models, dimension models (number coefficients including intercept) log marginal likelihood selected prior distribution.","code":"plot(crime.ZS, ask = F) plot(crime.ZS, which = 4, ask = FALSE, caption = \"\", sub.caption = \"\") crime.ZS ##  ## Call: ## bas.lm(formula = y ~ ., data = UScrime, prior = \"ZS-null\", modelprior = uniform(),  ##     initprobs = \"eplogp\", force.heredity = FALSE, pivot = TRUE) ##  ##  ##  Marginal Posterior Inclusion Probabilities:  ## Intercept          M         So         Ed        Po1        Po2         LF   ##    1.0000     0.8536     0.2737     0.9747     0.6652     0.4490     0.2022   ##       M.F        Pop         NW         U1         U2        GDP       Ineq   ##    0.2050     0.3696     0.6944     0.2526     0.6149     0.3601     0.9965   ##      Prob       Time   ##    0.8992     0.3718 options(width = 80) summary(crime.ZS) ##           P(B != 0 | Y)  model 1    model 2    model 3   model 4    model 5 ## Intercept     1.0000000  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## M             0.8535720  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## So            0.2737083  0.00000  0.0000000  0.0000000  0.000000  0.0000000 ## Ed            0.9746605  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## Po1           0.6651553  1.00000  1.0000000  0.0000000  1.000000  1.0000000 ## Po2           0.4490097  0.00000  0.0000000  1.0000000  0.000000  0.0000000 ## LF            0.2022374  0.00000  0.0000000  0.0000000  0.000000  0.0000000 ## M.F           0.2049659  0.00000  0.0000000  0.0000000  0.000000  0.0000000 ## Pop           0.3696150  0.00000  0.0000000  0.0000000  1.000000  0.0000000 ## NW            0.6944069  1.00000  1.0000000  1.0000000  1.000000  0.0000000 ## U1            0.2525834  0.00000  0.0000000  0.0000000  0.000000  0.0000000 ## U2            0.6149388  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## GDP           0.3601179  0.00000  0.0000000  0.0000000  0.000000  0.0000000 ## Ineq          0.9965359  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## Prob          0.8991841  1.00000  1.0000000  1.0000000  1.000000  1.0000000 ## Time          0.3717976  1.00000  0.0000000  0.0000000  0.000000  0.0000000 ## BF                   NA  1.00000  0.9416178  0.6369712  0.594453  0.5301269 ## PostProbs            NA  0.01820  0.0172000  0.0116000  0.010800  0.0097000 ## R2                   NA  0.84200  0.8265000  0.8229000  0.837500  0.8046000 ## dim                  NA  9.00000  8.0000000  8.0000000  9.000000  7.0000000 ## logmarg              NA 23.65111 23.5909572 23.2000822 23.130999 23.0164741"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"visualization-of-the-model-space","dir":"Articles","previous_headings":"","what":"Visualization of the Model Space","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"see beyond first five models, can represent collection models via image plot. default shows top 20 models.  image rows correspond variables intercept, labels variables y-axis. x-axis corresponds possible models. sorted posterior probability best left worst right rank top x-axis. column represents one 16 models. variables excluded model shown black column, variables included colored, color related log posterior probability. color column proportional log posterior probabilities (lower x-axis) model. log posterior probabilities actually scaled 0 corresponds lowest probability model top 20, values axis correspond log Bayes factors comparing model lowest probability model top 20 models. Models color similar log Bayes factors allows us view models clustered together Bayes Factors differences “worth bare mention”. plot indicates police expenditure two years enter model together, indication high correlation two variables.","code":"image(crime.ZS, rotate = F)"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"posterior-distributions-of-coefficients","dir":"Articles","previous_headings":"","what":"Posterior Distributions of Coefficients","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"examine marginal distributions two coefficients police expenditures, can extract coefficients estimates standard deviations BMA. optional argument, n.models coef use top n.models BMA may computationally efficient large problems. Plots posterior distributions averaging models obtained using plot method bas coefficient object.  vertical bar represents posterior probability coefficient 0 bell shaped curve represents density plausible values models coefficient non-zero. scaled height density non-zero values probability coefficient non-zero. Omitting subset argument provides marginal distributions. obtain credible intervals coefficients, BAS includes confint method create Highest Posterior Density intervals summaries coef. third column posterior mean. uses Monte Carlo sampling draw mixture model coefficient models sampled based posterior probabilities. can also plot via  using parm argument select coefficients plot (intercept parm=1). estimation selection, BAS supports additional arguments via estimator. default estimator=\"BMA\" uses models n.models. options include estimation highest probability model  median probability model variables excluded distributions point masses zero selection.","code":"coef.ZS <- coef(crime.ZS) plot(coef.ZS, subset = c(5:6), ask = F) confint(coef.ZS) ##                    2.5%      97.5%        beta ## Intercept  6.666930e+00 6.78164619  6.72493620 ## M          0.000000e+00 2.19641638  1.14359433 ## So        -4.707724e-02 0.31431450  0.03547522 ## Ed         6.496393e-01 3.17566810  1.85848834 ## Po1       -2.158795e-04 1.43681569  0.60067372 ## Po2       -2.108569e-01 1.42994718  0.31841766 ## LF        -5.437181e-01 1.03209467  0.05933737 ## M.F       -2.410463e+00 1.83011041 -0.02702786 ## Pop       -1.250611e-01 0.01212007 -0.02248283 ## NW        -1.528445e-05 0.16796356  0.06668437 ## U1        -5.363377e-01 0.36658398 -0.02456854 ## U2         0.000000e+00 0.66272189  0.20702927 ## GDP       -6.834740e-03 1.23207087  0.20625063 ## Ineq       6.704244e-01 2.15281005  1.39012647 ## Prob      -4.181555e-01 0.00000000 -0.21536203 ## Time      -5.480326e-01 0.04211726 -0.08433479 ## attr(,\"Probability\") ## [1] 0.95 ## attr(,\"class\") ## [1] \"confint.bas\" plot(confint(coef.ZS, parm = 2:16)) ## NULL plot(confint(coef(crime.ZS, estimator = \"HPM\"))) ## NULL plot(confint(coef(crime.ZS, estimator = \"MPM\")))"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"prediction","dir":"Articles","previous_headings":"","what":"Prediction","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS methods defined return fitted values, fitted, using observed design matrix predictions either observed data potentially new values, predict, lm. Plotting two sets fitted values,  see perfect agreement. always case posterior mean regression mean function point \\(x\\) expected posterior predictive value \\(Y\\) \\(x\\). true estimators BMA, expected values model selection.","code":"muhat.BMA <- fitted(crime.ZS, estimator = \"BMA\") BMA <- predict(crime.ZS, estimator = \"BMA\")  # predict has additional slots for fitted values under BMA, predictions under each model names(BMA) ##  [1] \"fit\"         \"Ybma\"        \"Ypred\"       \"postprobs\"   \"se.fit\"      ##  [6] \"se.pred\"     \"se.bma.fit\"  \"se.bma.pred\" \"df\"          \"best\"        ## [11] \"bestmodel\"   \"best.vars\"   \"estimator\" par(mar = c(9, 9, 3, 3)) plot(muhat.BMA, BMA$fit,   pch = 16,   xlab = expression(hat(mu[i])), ylab = expression(hat(Y[i])) ) abline(0, 1)"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"inference-with-model-selection","dir":"Articles","previous_headings":"Prediction","what":"Inference with model selection","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"addition using BMA, can use posterior means model selection. corresponds decision rule combines estimation selection. BAS currently implements following options highest probability model: little interpretable version names: median probability model: model predictors inclusion probability greater equal 0.5. coincides HPM predictors mutually orthogonal, case best predictive model squared error loss. Note can also extract best model attribute fitted values well. best predictive model: general, HPM MPM best predictive models, Bayesian decision theory perspective model closest BMA predictions squared error loss. Let’s see compare:  Using se.fit = TRUE option predict can also calculate standard deviations prediction mean use input confint function prediction object.   prediction new points, can supply new dataframe predict function lm.","code":"HPM <- predict(crime.ZS, estimator = \"HPM\")  # show the indices of variables in the best model where 0 is the intercept HPM$bestmodel ## [1]  0  1  3  4  9 11 13 14 15 variable.names(HPM) ## [1] \"Intercept\" \"M\"         \"Ed\"        \"Po1\"       \"NW\"        \"U2\"        ## [7] \"Ineq\"      \"Prob\"      \"Time\" MPM <- predict(crime.ZS, estimator = \"MPM\") variable.names(MPM) ## [1] \"Intercept\" \"M\"         \"Ed\"        \"Po1\"       \"NW\"        \"U2\"        ## [7] \"Ineq\"      \"Prob\" BPM <- predict(crime.ZS, estimator = \"BPM\") variable.names(BPM) ##  [1] \"Intercept\" \"M\"         \"So\"        \"Ed\"        \"Po1\"       \"Po2\"       ##  [7] \"M.F\"       \"NW\"        \"U2\"        \"Ineq\"      \"Prob\" GGally::ggpairs(data.frame(   HPM = as.vector(HPM$fit), # this used predict so we need to extract fitted values   MPM = as.vector(MPM$fit), # this used fitted   BPM = as.vector(BPM$fit), # this used fitted   BMA = as.vector(BMA$fit) )) # this used predict BPM <- predict(crime.ZS, estimator = \"BPM\", se.fit = TRUE) crime.conf.fit <- confint(BPM, parm = \"mean\") crime.conf.pred <- confint(BPM, parm = \"pred\") plot(crime.conf.fit) ## NULL plot(crime.conf.pred) ## NULL new.pred <- predict(crime.ZS, newdata = UScrime, estimator = \"MPM\")"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"alternative-algorithms","dir":"Articles","previous_headings":"","what":"Alternative algorithms","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS several options sampling model space without enumeration. (current) default method=\"BAS\" samples models without replacement using estimates marginal inclusion probabilities using algorithm described Clyde et al (2011). initial sampling probabilities provided initprobs updated based sampled models, every update iterations. can efficient cases large fraction model space sampled, however, cases high correlation large number predictors, can lead biased estimates Clyde Ghosh (2012), case MCMC preferred. method=\"MCMC\" described better large \\(p\\). deterministic sampling scheme also available enumeration; faster enumeration default method=“BAS”.","code":"system.time(   for (i in 1:10) {     crime.ZS <- bas.lm(y ~ .,       data = UScrime,       prior = \"ZS-null\", method = \"BAS\",       modelprior = uniform(), initprobs = \"eplogp\"     )   } ) ##    user  system elapsed  ##   1.391   0.000   1.391 system.time(   for (i in 1:10) {     crime.ZS <- bas.lm(y ~ .,       data = UScrime,       prior = \"ZS-null\", method = \"deterministic\",       modelprior = uniform(), initprobs = \"eplogp\"     )   } ) ##    user  system elapsed  ##   1.301   0.007   1.308"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"beyond-enumeration","dir":"Articles","previous_headings":"","what":"Beyond Enumeration","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"Many problems large enumerate possible models. cases may use method=\"BAS\" sample without replacement method=\"MCMC\" option sample models using Markov Chain Monte Carlo sampling sample models based posterior probabilities. spaces number models greatly exceeds number models sample, MCMC option recommended provides estimates low bias compared sampling without replacement BAS (Clyde Ghosh 2011). run MCMC sampler number unique sampled models exceeds n.models \\(2^p\\) (\\(p < 19\\)) default MCMC.iterations exceeded, MCMC.iterations = n.models*2 default.","code":"crime.ZS <- bas.lm(y ~ .,   data = UScrime,   prior = \"ZS-null\",   modelprior = uniform(),   method = \"MCMC\" )"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"estimates-of-marginal-posterior-inclusion-probabilities-pip","dir":"Articles","previous_headings":"Beyond Enumeration","what":"Estimates of Marginal Posterior Inclusion Probabilities (pip)","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"MCMC sampling two estimates marginal inclusion probabilities: object$probne0 obtained using re-normalized posterior odds sampled models estimate probabilities estimates based Monte Carlo frequencies object$probs.MCMC. close agreement MCMC sampler run enough iterations. BAS includes diagnostic function compare two sets estimates posterior inclusion probabilities posterior model probabilities   left hand plot pips, point represents one posterior inclusion probability 15 variables estimated two methods. two estimators pretty close agreement. plot model probabilities suggests use MCMC.iterations want accurate estimates posterior model probabilities.","code":"diagnostics(crime.ZS, type = \"pip\", pch = 16) diagnostics(crime.ZS, type = \"model\", pch = 16) crime.ZS <- bas.lm(y ~ .,   data = UScrime,   prior = \"ZS-null\",   modelprior = uniform(),   method = \"MCMC\", MCMC.iterations = 10^6 )  diagnostics(crime.ZS, type=\"model\", pch=16)"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"outliers","dir":"Articles","previous_headings":"","what":"Outliers","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS can also used exploring mean shift variance inflation outliers adding indicator variables case outlier (mean given regression) . similar MC3.REG function BMA, although using g-prior mixture g-priors coefficients outlier means. Using Stackloss data, can add identify matrix original dataframe, column indicator ith variable outlier. call introduces using truncated prior distributions model space; case distribution number variables included Poisson distribution, mean 4 (truncation), truncation point 10, models 10 (one half cases rounded ) probability zero. avoids exploration models full rank. Looking summaries","code":"data(\"stackloss\") stackloss <- cbind(stackloss, diag(nrow(stackloss))) stack.bas <- bas.lm(stack.loss ~ .,   data = stackloss,   method = \"MCMC\", initprobs = \"marg-eplogp\",   prior = \"ZS-null\",   modelprior = tr.poisson(4, 10),   MCMC.iterations = 200000 ) knitr::kable(as.data.frame(summary(stack.bas)))"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"factors-and-hierarchical-heredity","dir":"Articles","previous_headings":"","what":"Factors and Hierarchical Heredity","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS now includes constraints factors terms represent factor either included excluded together. illustrate, use data set ToothGrowth convert dose factor: fit model main effects two way interaction without constraints:  image model space, see levels factor enter drop model independently interactions may included without main effects. may lead parsimonious models, however, hypotheses tested coefficients represent factor depend choice reference group. force levels factor enter leave together can use force.heredity = TRUE. force.heredity option also forces interactions included main effects also included, models several factors higher order interactions, heredity constraint implies lower order interactions must included adding higher order interactions.  force.heredity set FALSE sampling methods MCMC+BAS deterministic. 20 predictors factors, recommend using MCMC enforce constraints. Alternatively, function, force.heredity.bas, post-process output drop models violate hierarchical heredity constraint: can used sampling methods.","code":"data(ToothGrowth) ToothGrowth$dose <- factor(ToothGrowth$dose) levels(ToothGrowth$dose) <- c(\"Low\", \"Medium\", \"High\") TG.bas <- bas.lm(len ~ supp*dose,   data = ToothGrowth,   modelprior = uniform(), method = \"BAS\" )  image(TG.bas) TG.bas <- bas.lm(len ~ supp * dose,   data = ToothGrowth,   modelprior = uniform(), method = \"BAS\", force.heredity = TRUE )  image(TG.bas) TG.bas <- bas.lm(len ~ supp * dose,   data = ToothGrowth,   modelprior = uniform(), method = \"BAS\", force.heredity = FALSE ) TG.herid.bas <- force.heredity.bas(TG.bas)"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"weighted-regression","dir":"Articles","previous_headings":"","what":"Weighted Regression","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS can perform weighted regression supplying optional weight vector length response assumption variance response proportional 1/weights. g-prior incorporates weights prior covariance, \\[ \\sigma^2 g (X_\\gamma^T W X_\\gamma)^{-1} \\] \\(X_\\gamma\\) design matrix model \\(\\gamma\\) \\(W\\) \\(n \\times n\\) diagonal matrix weights diagonal. illustrate, use climate data, available url includes measurements changes temperature (deltaT) various latitudes well measure accuracy measured values sdev 8 different types proxy obtaining measurements. use explore weighted regression option group terms factors poly. illustration purposes, eliminate proxy == 6 one level interactions estimable, convert proxy factor. can fit weighted regression weights = 1/sdev^2 following code Examining image top models,  see levels factor enter drop model together, well vectors design matrix represent term poly. Rerunning without constraint,  allows one see factors levels different reference group.","code":"data(climate, package=\"BAS\") str(climate) ## 'data.frame':    63 obs. of  5 variables: ##  $ deltaT  : num  -2.6 -2.6 -2.9 -2.4 -2.8 -1.2 -2.4 -2.6 -2.4 -2.5 ... ##  $ sdev    : num  0.7 0.8 0.9 0.7 0.7 0.3 1.3 1.3 1.3 0.5 ... ##  $ proxy   : int  1 1 1 1 1 1 1 1 1 1 ... ##  $ T.M     : int  1 1 1 1 1 1 1 1 1 1 ... ##  $ latitude: num  2.5 2.2 0.5 0.3 0.2 -1.1 5.2 11.4 14.6 6.3 ... summary(climate) ##      deltaT            sdev            proxy            T.M         ##  Min.   :-7.000   Min.   :0.1500   Min.   :1.000   Min.   :0.0000   ##  1st Qu.:-3.900   1st Qu.:0.5000   1st Qu.:2.000   1st Qu.:1.0000   ##  Median :-2.900   Median :0.7000   Median :3.000   Median :1.0000   ##  Mean   :-3.111   Mean   :0.8579   Mean   :3.333   Mean   :0.8254   ##  3rd Qu.:-2.000   3rd Qu.:1.3000   3rd Qu.:5.000   3rd Qu.:1.0000   ##  Max.   : 0.200   Max.   :2.5000   Max.   :8.000   Max.   :1.0000   ##     latitude       ##  Min.   :-22.500   ##  1st Qu.: -3.450   ##  Median :  0.200   ##  Mean   :  2.187   ##  3rd Qu.:  9.700   ##  Max.   : 29.000 library(dplyr) climate <- filter(climate, proxy != 6) %>%   mutate(proxy = factor(proxy)) climate.bas <- bas.lm(deltaT ~ proxy * poly(latitude, 2),   data = climate,   weights = 1 / sdev^2,   prior = \"hyper-g-n\", alpha = 3.0,   n.models = 2^20,    force.heredity=TRUE,   modelprior = uniform() ) image(climate.bas, rotate = F) # May take a while to enumerate all 2^20 models climate.bas <- bas.lm(deltaT ~ proxy * poly(latitude, 2),   data = climate,   weights = 1 / sdev^2,   prior = \"hyper-g-n\", alpha = 3.0,   n.models = 2^20,   modelprior = uniform(),   force.heredity = FALSE ) image(climate.bas)"},{"path":"http://merliseclyde.github.io/BAS/articles/BAS-vignette.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging and Variable Selection","text":"BAS includes prior distributions coefficients models, well bas.glm fitting Generalized Linear Models. syntax bas.glm bas.lm yet , particularly priors coefficients represented, please see documentation features details updated another vignette added! issues feature requests please submit via package’s github page merliseclyde/BAS","code":""},{"path":"http://merliseclyde.github.io/BAS/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Merlise Clyde. Author, maintainer, copyright holder.            ORCID=0000-0002-3595-1872 Michael Littman. Contributor. Joyee Ghosh. Contributor. Yingbo Li. Contributor. Betsy Bersson. Contributor. Don van de Bergh. Contributor. Quanli Wang. Contributor.","code":""},{"path":"http://merliseclyde.github.io/BAS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clyde, Merlise (2023) BAS: Bayesian Variable Selection Model Averaging using Bayesian Adaptive Sampling, R package version 1.6.5","code":"@Manual{,   title = {{BAS}: Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling},   author = {Merlise Clyde},   year = {2023},   note = {R package version 1.6.5}, }"},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"bas-bayesian-variable-selection-and-model-averaging-using-bayesian-adaptive-sampling","dir":"","previous_headings":"","what":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"BAS R package designed provide easy use package fast code implementing Bayesian Model Averaging Model Selection R using state art prior distributions linear generalized linear models. prior distributions BAS based Zellner’s g-prior mixtures g-priors linear generalized linear models. shown consistent asymptotically model selection inference number computational advantages. BAS implements three main algorithms sampling space potential models: deterministic algorithm efficient enumeration, adaptive sampling without replacement algorithm modest problems, MCMC algorithm utilizes swapping escape local modes standard Metropolis-Hastings proposals.","code":""},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"stable version  can installed easily R console like package: hand, welcome everyone use recent version package quick-fixes, new features probably new bugs. ’s currently hosted GitHub. get latest development version GitHub, use devtools package CRAN enter R: can check current build status  installing. Installing package source require compilation C FORTRAN code library makes use BLAS LAPACK efficient model fitting. See CRAN manuals installing packages source different operating systems.","code":"install.packages('BAS') devtools::install_github('merliseclyde/BAS')"},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"begin load package: two main function BAS bas.lm bas.glm implementing Bayesian Model Averaging Variable Selection using Zellner’s g-prior mixtures g priors. functions syntax similar lm glm functions respectively. illustrate using BAS simple example famous Hald data set using Zellner-Siow Cauchy prior via BAS summary, plot coef, predict fitted functions like lm/glm functions. Images model space highlighting variable important may obtained via  Run demo(\"BAS.hald\") demo(\"BAS.USCrime\") see package vignette examples options using MCMC model spaces enumerated.","code":"library(BAS) data(Hald) hald.ZS = bas.lm(Y ~ ., data=Hald, prior=\"ZS-null\", modelprior=uniform(), method=\"BAS\") image(hald.ZS)"},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"generalized-linear-models","dir":"","previous_headings":"Usage","what":"Generalized Linear Models","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"BAS now includes support binomial binary regression, Poisson regression, Gamma regression using Laplace approximations obtain Bayes Factors used calculating posterior probabilities models sampling models. example using Pima diabetes data set hyper-g/n prior: Note, syntax specifying priors coefficients bas.glm uses function arguments specify hyper-parameters, rather text string specify prior name separate argument hyper-parameters. bas.lm moving format sometime future.","code":"library(MASS) data(Pima.tr) Pima.hgn = bas.glm(type ~ ., data=Pima.tr, method=\"BAS\", family=binomial(),                   betaprior=hyper.g.n(), modelprior=uniform())"},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"feature-requests-and-issues","dir":"","previous_headings":"","what":"Feature Requests and Issues","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"Feel free report issues request features added via github issues page. current documentation vignettes see BAS website","code":""},{"path":"http://merliseclyde.github.io/BAS/index.html","id":"support","dir":"","previous_headings":"Feature Requests and Issues","what":"Support","title":"Bayesian Variable Selection and Model Averaging using Bayesian Adaptive Sampling","text":"material based upon work supported National Science Foundation Grant DMS-1106891. opinions, findings, conclusions recommendations expressed material author(s) necessarily reflect views National Science Foundation.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/BAS.html","id":null,"dir":"Reference","previous_headings":"","what":"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling — BAS","title":"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling — BAS","text":"Implementation  Bayesian Model Averaging linear models using stochastic deterministic sampling without replacement posterior distributions. Prior distributions coefficients form Zellner's g-prior mixtures g-priors. Options include Zellner-Siow Cauchy Priors, Liang et al hyper-g priors, Local Global Empirical Bayes estimates g, default model selection criteria AIC BIC. Sampling probabilities may updated based sampled models.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/BAS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling — BAS","text":"Clyde, M. Ghosh, J. Littman, M. (2010) Bayesian Adaptive Sampling Variable Selection Model Averaging. Journal Computational Graphics Statistics.  20:80-101 doi:10.1198/jcgs.2010.09049 Clyde, M. George, E. . (2004) Model uncertainty. Statist. Sci., 19, 81-94. doi:10.1214/088342304000000035 Clyde, M. (1999) Bayesian Model Averaging Model Search Strategies (discussion). Bayesian Statistics 6. J.M. Bernardo, .P. Dawid, J.O. Berger, .F.M. Smith eds. Oxford University Press, pages 157-185. Li, Y. Clyde, M. (2018) Mixtures g-priors Generalized Linear Models. Journal American Statistical Association, 113:524, 1828-1845 doi:10.1080/01621459.2018.1469992 Liang, F., Paulo, R., Molina, G., Clyde, M. Berger, J.O. (2008) Mixtures g-priors Bayesian Variable Selection. Journal American Statistical Association. 103:410-423. doi:10.1198/016214507000001337","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/BAS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling — BAS","text":"Merlise Clyde,  Maintainer: Merlise Clyde <clyde@stat.duke.edu>","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/BAS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BAS: Bayesian Model Averaging using Bayesian Adaptive Sampling — BAS","text":"","code":"data(\"Hald\") hald.gprior =  bas.lm(Y ~ ., data=Hald, alpha=13, prior=\"g-prior\")  # more complete demos  demo(BAS.hald) #>  #>  #> \tdemo(BAS.hald) #> \t---- ~~~~~~~~ #>  #> > data(Hald) #>  #> > hald.gprior =  bas.lm(Y~ ., data=Hald, prior=\"g-prior\", alpha=13, #> +                       modelprior=beta.binomial(1,1), #> +                       initprobs=\"eplogp\") #>  #> > hald.gprior #>  #> Call: #> bas.lm(formula = Y ~ ., data = Hald, prior = \"g-prior\", alpha = 13,  #>     modelprior = beta.binomial(1, 1), initprobs = \"eplogp\") #>  #>  #>  Marginal Posterior Inclusion Probabilities:  #> Intercept         X1         X2         X3         X4   #>    1.0000     0.9019     0.6896     0.4653     0.6329   #>  #> > plot(hald.gprior)     #>  #> > summary(hald.gprior) #>           P(B != 0 | Y)  model 1    model 2    model 3    model 4    model 5 #> Intercept     1.0000000  1.00000  1.0000000 1.00000000  1.0000000  1.0000000 #> X1            0.9019245  1.00000  1.0000000 1.00000000  1.0000000  1.0000000 #> X2            0.6895830  1.00000  0.0000000 1.00000000  1.0000000  1.0000000 #> X3            0.4652762  0.00000  0.0000000 1.00000000  0.0000000  1.0000000 #> X4            0.6329266  0.00000  1.0000000 1.00000000  1.0000000  0.0000000 #> BF                   NA  1.00000  0.6923944 0.08991408  0.3355714  0.3344926 #> PostProbs            NA  0.24320  0.1684000 0.13120000  0.1224000  0.1220000 #> R2                   NA  0.97870  0.9725000 0.98240000  0.9823000  0.9823000 #> dim                  NA  3.00000  3.0000000 5.00000000  4.0000000  4.0000000 #> logmarg              NA 11.72735 11.3597547 9.31845348 10.6354335 10.6322138 #>  #> > image(hald.gprior, subset=-1, vlas=0)  #>  #> > hald.coef = coefficients(hald.gprior) #>  #> > hald.coef #>  #>  Marginal Posterior Summaries of Coefficients:  #>  #>  Using  BMA  #>  #>  Based on the top  16 models  #>            post mean  post SD  post p(B != 0) #> Intercept  95.4231     0.7107   1.0000        #> X1          1.2150     0.5190   0.9019        #> X2          0.2756     0.4832   0.6896        #> X3         -0.1271     0.4976   0.4653        #> X4         -0.3269     0.4717   0.6329        #>  #> > plot(hald.coef)      #>  #> > predict(hald.gprior, top=5, se.fit=TRUE)   #> $fit #>  [1]  79.74246  74.50010 105.29268  89.88693  95.57177 104.56409 103.40145 #>  [8]  77.13668  91.99731 114.21325  82.78446 111.00723 110.40160 #>  #> $Ybma #>            [,1] #>  [1,]  79.74246 #>  [2,]  74.50010 #>  [3,] 105.29268 #>  [4,]  89.88693 #>  [5,]  95.57177 #>  [6,] 104.56409 #>  [7,] 103.40145 #>  [8,]  77.13668 #>  [9,]  91.99731 #> [10,] 114.21325 #> [11,]  82.78446 #> [12,] 111.00723 #> [13,] 110.40160 #>  #> $Ypred #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 81.17036 74.83464 105.0725 89.69881 97.15898 104.4575 103.3893 76.06454 #> [2,] 77.70296 74.24113 105.8554 90.46267 93.09565 104.7152 103.1399 78.80193 #> [3,] 79.70437 74.40553 105.2175 89.76253 95.63309 104.5709 103.5254 77.08557 #> [4,] 79.65151 74.47846 105.4218 89.83174 95.62799 104.5962 103.5068 77.00839 #> [5,] 79.84321 74.31409 104.9063 89.65651 95.70301 104.5285 103.5476 77.15919 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 91.57174 113.1722 81.59906 111.2219 111.0884 #> [2,] 92.68123 115.8058 84.50293 110.4162 109.0791 #> [3,] 91.98604 114.1759 82.78145 111.1196 110.5321 #> [4,] 92.07571 114.1088 82.68233 111.0429 110.4674 #> [5,] 91.83513 114.2353 82.88128 111.2384 110.6515 #>  #> $postprobs #> [1] 0.3089304 0.2139017 0.1666632 0.1555023 0.1550024 #>  #> $se.fit #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 2.220164 2.265862 1.546911 2.181188 1.310135 1.523300 2.655096 2.176560 #> [2,] 2.716798 2.389723 1.633637 2.179215 1.321062 1.581232 2.721957 2.078129 #> [3,] 3.203405 2.501485 3.279273 2.357164 2.589756 1.549136 2.623290 2.765255 #> [4,] 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817 #> [5,] 2.932580 2.353352 1.538009 2.141694 2.507848 1.498758 2.616407 2.680289 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 1.883610 3.264656 1.908238 1.970691 2.054234 #> [2,] 2.013244 3.298134 1.933819 1.964374 1.924460 #> [3,] 2.353516 3.609909 2.821295 2.227363 2.390135 #> [4,] 1.990817 3.485929 2.456636 1.951456 2.212238 #> [5,] 1.889302 3.569065 2.665166 1.934336 2.117189 #>  #> $se.pred #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 5.057182 5.077410 4.799885 5.040193 4.728892 4.792328 5.262651 5.038191 #> [2,] 5.415848 5.259391 4.961773 5.167146 4.867815 4.944766 5.418438 5.125333 #> [3,] 5.489152 5.111401 5.533771 5.042342 5.155175 4.718984 5.172102 5.245534 #> [4,] 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065 #> [5,] 5.337427 5.042456 4.717369 4.947217 5.116386 4.704719 5.170463 5.203081 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 4.918734 5.594992 4.928218 4.952735 4.986566 #> [2,] 5.099370 5.729582 5.068538 5.080274 5.064974 #> [3,] 5.040638 5.735890 5.275291 4.982985 5.057839 #> [4,] 4.882702 5.659428 5.090431 4.866787 4.977090 #> [5,] 4.843301 5.711946 5.195307 4.861045 4.936658 #>  #> $se.bma.fit #>  [1] 2.688224 2.095245 1.769625 1.970919 2.197285 1.363804 2.356457 2.302631 #>  [9] 1.822084 3.141443 2.237663 1.801849 1.991374 #>  #> $se.bma.pred #>  [1] 4.838655 4.536087 4.395180 4.480017 4.584113 4.248058 4.662502 4.635531 #>  [9] 4.416563 5.104380 4.603604 4.408253 4.489054 #>  #> $df #> [1] 12 12 12 12 12 #>  #> $best #> [1] 3 9 2 5 4 #>  #> $bestmodel #> $bestmodel[[1]] #> [1] 0 1 2 #>  #> $bestmodel[[2]] #> [1] 0 1 4 #>  #> $bestmodel[[3]] #> [1] 0 1 2 3 4 #>  #> $bestmodel[[4]] #> [1] 0 1 2 4 #>  #> $bestmodel[[5]] #> [1] 0 1 2 3 #>  #>  #> $best.vars #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X3\"        \"X4\"        #>  #> $estimator #> [1] \"BMA\" #>  #> attr(,\"class\") #> [1] \"pred.bas\" #>  #> > confint(predict(hald.gprior, Hald, estimator=\"BMA\", se.fit=TRUE, top=5), parm=\"mean\") #>            2.5%     97.5%      mean #>  [1,]  73.16373  85.92049  79.74246 #>  [2,]  69.29281  79.63944  74.50010 #>  [3,] 100.96553 109.86522 105.29268 #>  [4,]  84.93257  94.52517  89.88693 #>  [5,]  90.27461 100.26170  95.57177 #>  [6,] 101.35811 107.88850 104.56409 #>  [7,]  97.59924 109.07395 103.40145 #>  [8,]  71.89841  82.91549  77.13668 #>  [9,]  87.64842  96.54965  91.99731 #> [10,] 106.37793 121.49682 114.21325 #> [11,]  77.29568  87.96977  82.78446 #> [12,] 106.78705 115.60666 111.00723 #> [13,] 105.75957 115.25953 110.40160 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" #>  #> > predict(hald.gprior, estimator=\"MPM\", se.fit=TRUE)   #> $fit #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 #> attr(,\"model\") #> [1] 0 1 2 4 #> attr(,\"best\") #> [1] 1 #> attr(,\"estimator\") #> [1] \"MPM\" #>  #> $Ybma #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 #> attr(,\"model\") #> [1] 0 1 2 4 #> attr(,\"best\") #> [1] 1 #> attr(,\"estimator\") #> [1] \"MPM\" #>  #> $Ypred #> NULL #>  #> $postprobs #> NULL #>  #> $se.fit #>  [1] 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817 #>  [9] 1.990817 3.485929 2.456636 1.951456 2.212238 #>  #> $se.pred #>  [1] 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065 #>  [9] 4.882702 5.659428 5.090431 4.866787 4.977090 #>  #> $se.bma.fit #> NULL #>  #> $se.bma.pred #> NULL #>  #> $df #> [1] 12 #>  #> $best #> NULL #>  #> $bestmodel #> [1] 0 1 2 4 #>  #> $best.vars #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X4\"        #>  #> $estimator #> [1] \"MPM\" #>  #> attr(,\"class\") #> [1] \"pred.bas\" #>  #> > confint(predict(hald.gprior, Hald, estimator=\"MPM\", se.fit=TRUE), parm=\"mean\") #>            2.5%     97.5%      mean #>  [1,]  72.85939  86.44363  79.65151 #>  [2,]  69.50215  79.45478  74.47846 #>  [3,] 101.93102 108.91264 105.42183 #>  [4,]  85.14928  94.51420  89.83174 #>  [5,]  89.98634 101.26964  95.62799 #>  [6,] 101.30948 107.88283 104.59616 #>  [7,]  97.81813 109.19556 103.50684 #>  [8,]  71.46153  82.55525  77.00839 #>  [9,]  87.73810  96.41333  92.07571 #> [10,] 106.51357 121.70394 114.10876 #> [11,]  77.32978  88.03488  82.68233 #> [12,] 106.79101 115.29472 111.04286 #> [13,] 105.64736 115.28746 110.46741 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" #>  #> > fitted(hald.gprior, estimator=\"HPM\") #>  [1]  81.17036  74.83464 105.07248  89.69881  97.15898 104.45753 103.38927 #>  [8]  76.06454  91.57174 113.17222  81.59906 111.22195 111.08841 #>  #> > hald.gprior =  bas.lm(Y~ ., data=Hald, n.models=2^4, #> +                       prior=\"g-prior\", alpha=13, modelprior=uniform(), #> +                       initprobs=\"eplogp\") #>  #> > hald.EB = update(hald.gprior, newprior=\"EB-global\") #>  #> > hald.bic = update(hald.gprior,newprior=\"BIC\") #>  #> > hald.zs = update(hald.bic, newprior=\"ZS-null\") if (FALSE) { demo(BAS.USCrime) }"},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Outlier Detection — Bayes.outlier","title":"Bayesian Outlier Detection — Bayes.outlier","text":"Calculate posterior  probability absolute value error exceeds k standard deviations P(|epsilon_j| > k sigma | data) model Y = X B + epsilon, epsilon ~ N(0, sigma^2 ) based paper Chaloner & Brant Biometrika (1988). Either k prior probability outliers must provided. uses reference prior p(B, sigma) = 1; priors model averaging come.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Outlier Detection — Bayes.outlier","text":"","code":"Bayes.outlier(lmobj, k, prior.prob)"},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Outlier Detection — Bayes.outlier","text":"lmobj object class `lm` k number standard deviations used calculating probability individual case outlier, P(|error| > k sigma | data) prior.prob prior probability outliers sample size n","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Outlier Detection — Bayes.outlier","text":"Returns list three items: e residuals hat leverage values prob.outlier posterior probabilities point outlier prior.prob prior probability point outlier","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Outlier Detection — Bayes.outlier","text":"Chaloner & Brant (1988) Bayesian Approach Outlier Detection Residual Analysis Biometrika (1988) 75, 651-659","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bayes.outlier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Outlier Detection — Bayes.outlier","text":"","code":"data(\"stackloss\") stack.lm <- lm(stack.loss ~ ., data = stackloss) stack.outliers <- Bayes.outlier(stack.lm, k = 3) plot(stack.outliers$prob.outlier, type = \"h\", ylab = \"Posterior Probability\")  # adjust for sample size for calculating prior prob that a # a case is an outlier stack.outliers <- Bayes.outlier(stack.lm, prior.prob = 0.95) # cases where posterior probability exceeds prior probability which(stack.outliers$prob.outlier > stack.outliers$prior.prob) #> [1]  4 21"},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.heredity.html","id":null,"dir":"Reference","previous_headings":"","what":"Independent Bernoulli prior on models that with constraints for\nmodel hierarchy induced by interactions — Bernoulli.heredity","title":"Independent Bernoulli prior on models that with constraints for\nmodel hierarchy induced by interactions — Bernoulli.heredity","text":"Independent Bernoulli prior models constraints model hierarchy induced interactions","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.heredity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Independent Bernoulli prior on models that with constraints for\nmodel hierarchy induced by interactions — Bernoulli.heredity","text":"","code":"Bernoulli.heredity(pi = 0.5, parents)"},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.heredity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Independent Bernoulli prior on models that with constraints for\nmodel hierarchy induced by interactions — Bernoulli.heredity","text":"pi Bernoulli probability term included parents matrix terms parents indicators terms parents term","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.heredity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Independent Bernoulli prior on models that with constraints for\nmodel hierarchy induced by interactions — Bernoulli.heredity","text":"implemented yet use bas.lm bas.glm","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Independent Bernoulli Prior Distribution for Models — Bernoulli","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"Creates object representing prior distribution models BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"","code":"Bernoulli(probs = 0.5)"},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"probs scalar vector prior inclusion probabilities. scalar, values replicated variables ans 1 added intercept. BAS checks see length equal dimension parameter vector full model adds 1 include intercept.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"independent Bernoulli prior distribution commonly used prior BMA, Uniform distribution special case probs=.5.  indicator variables independent Bernoulli distributions common probability probs, distribution model size binomial(p, probs) distribution.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Independent Bernoulli Prior Distribution for Models — Bernoulli","text":"","code":"Bernoulli(.9) #> $family #> [1] \"Bernoulli\" #>  #> $hyper.parameters #> [1] 0.9 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"Creates object representing CCH mixture g-priors coefficients BAS .","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"","code":"CCH(alpha, beta, s = 0)"},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"alpha scalar > 0, recommended alpha=.5 (betaprime) 1 CCH. hyper.g(alpha) equivalent CCH(alpha -2, 2, 0). Liang et al recommended values range 2 < alpha_h <= 4 beta scalar > 0.  value updated data; beta function n consistency null model.  hyper-g corresponds b = 2 s scalar, recommended s=0","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/CCH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — CCH","text":"","code":"CCH(alpha = .5, beta = 100, s = 0) #> $family #> [1] \"CCH\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 0.5 #>  #> $hyper.parameters$beta #> [1] 100 #>  #> $hyper.parameters$s #> [1] 0 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the global Empirical Bayes estimates for BMA — EB.global","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"Finds global Empirical Bayes estimates g Zellner's g-prior model probabilities","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"","code":"EB.global(object, tol = 0.1, g.0 = NULL, max.iterations = 100)"},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"object 'bas' object created bas tol tolerance estimating g g.0 initial value g max.iterations Maximum number iterations EM algorithm","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"object class 'bas' using Zellner's g prior estimate g based models","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"Uses EM algorithm Liang et al estimate type II MLE g Zellner's g prior","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"Liang, F., Paulo, R., Molina, G., Clyde, M. Berger, J.O. (2008) Mixtures g-priors Bayesian Variable Selection. Journal American Statistical Association. 103:410-423.  doi:10.1198/016214507000001337","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.global.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the global Empirical Bayes estimates for BMA — EB.global","text":"","code":"library(MASS) data(UScrime) UScrime[,-2] = log(UScrime[,-2]) # EB local uses a different g within each model crime.EBL =  bas.lm(y ~ ., data=UScrime, n.models=2^15,                     prior=\"EB-local\", initprobs= \"eplogp\") # use a common (global) estimate of g crime.EBG = EB.global(crime.EBL)"},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"Creates object representing EB prior BAS GLM.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"","code":"EB.local()"},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/EB.local.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empirical Bayes Prior Distribution for Coefficients in BMA Model — EB.local","text":"","code":"EB.local() #> $family #> [1] \"EB-local\" #>  #> $class #> [1] \"EB\" #>  #> $hyper.parameters #> $hyper.parameters$local #> [1] TRUE #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/Hald.html","id":null,"dir":"Reference","previous_headings":"","what":"Hald Data — Hald","title":"Hald Data — Hald","text":"Hald data used many books papers illustrate variable selection. data relate engineering application concerned effect composition cement heat evolved hardening. response variable Y heat evolved cement mix. four explanatory variables ingredients mix, X1: tricalcium aluminate, X2: tricalcium silicate, X3: tetracalcium alumino ferrite, X4: dicalcium silicate. important feature data variables X1 X3 highly correlated, well variables X2 X4.  Thus expect subset (X1,X2,X3,X4) includes one variable highly correlated pair subset also includes member.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Hald.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hald Data — Hald","text":"hald dataframe 13 observations 5 variables (columns), Y: Heat evolved per gram cement (calories) X1: Amount tricalcium aluminate X2: Amount tricalcium silicate X3: Amount tetracalcium alumino ferrite X4: Amount dicalcium silicate","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Hald.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Hald Data — Hald","text":"Wood, H., Steinour, H.H., Starke, H.R. (1932). \"Effect Composition Portland cement Heat Evolved Hardening\", Industrial Engineering Chemistry, 24, 1207-1214.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"Creates object representing prior distribution coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"","code":"IC.prior(penalty)"},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"penalty scalar used penalized loglikelihood form penalty*dimension","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"log marginal likelihood approximated -2*(deviance + penalty*dimension).  Allows alternatives AIC (penalty = 2) BIC (penalty = log(n)).  BIC, argument may missing, case sample size determined call `bas.glm` used determine penalty.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/IC.prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information Criterion Families of Prior Distribution for Coefficients in BMA\nModels — IC.prior","text":"","code":"IC.prior(2) #> $family #> [1] \"IC\" #>  #> $class #> [1] \"IC\" #>  #> $hyper #> [1] 2 #>  #> $hyper.parameters #> $hyper.parameters$penalty #> [1] 2 #>  #>  #> attr(,\"class\") #> [1] \"prior\" aic.prior() #> $family #> [1] \"AIC\" #>  #> $class #> [1] \"IC\" #>  #> $hyper.parameters #> $hyper.parameters$penalty #> [1] 2 #>  #>  #> $hyper #> [1] 2 #>  #> attr(,\"class\") #> [1] \"prior\" bic.prior(100) #> $family #> [1] \"BIC\" #>  #> $class #> [1] \"IC\" #>  #> $hyper.parameters #> $hyper.parameters$penalty #> [1] 4.60517 #>  #> $hyper.parameters$n #> [1] 100 #>  #>  #> $hyper #> [1] 4.60517 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":null,"dir":"Reference","previous_headings":"","what":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"Creates object representing Jeffrey's Prior g mixture g-priors coefficients BAS. equivalent limiting version CCH(, 2, 0) = 0 hyper-g(= 2) improper prior.  $g$ appear Null Model, Bayes Factors model probabilities well-defined arbitrary normalizing constants, reason null model excluded constants used across models.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"","code":"Jeffreys()"},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/Jeffreys.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jeffreys Prior Distribution for $g$ for Mixtures of g-Priors for\nCoefficients in BMA Models — Jeffreys","text":"","code":"Jeffreys() #> $family #> [1] \"Jeffreys\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 0 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"Creates object representing Truncated Gamma (tCCH) mixture g-priors coefficients BAS, u = 1/(1+g) Gamma distribution supported (0, 1].","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"","code":"TG(alpha = 2)"},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"alpha scalar > 0, recommended alpha=.5 (betaprime) 1.  alpha=2 corresponds uniform prior shrinkage factor.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/TG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized g-Prior Distribution for Coefficients in BMA Models — TG","text":"","code":"TG(alpha = 2) #> $family #> [1] \"TG\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 2 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #>  #> attr(,\"class\") #> [1] \"prior\" CCH(alpha = 2, beta = 100, s = 0) #> $family #> [1] \"CCH\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 2 #>  #> $hyper.parameters$beta #> [1] 100 #>  #> $hyper.parameters$s #> [1] 0 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"Sample without replacement posterior distribution GLMs","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"","code":"bas.glm(   formula,   family = binomial(link = \"logit\"),   data,   weights,   subset,   contrasts = NULL,   offset,   na.action = \"na.omit\",   n.models = NULL,   betaprior = CCH(alpha = 0.5, beta = as.numeric(nrow(data)), s = 0),   modelprior = beta.binomial(1, 1),   initprobs = \"Uniform\",   include.always = ~1,   method = \"MCMC\",   update = NULL,   bestmodel = NULL,   prob.rw = 0.5,   MCMC.iterations = NULL,   thin = 1,   control = glm.control(),   laplace = FALSE,   renormalize = FALSE,   force.heredity = FALSE,   bigmem = FALSE )"},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"formula generalized linear model formula full model predictors, Y ~ X.  code assumes intercept included model. family description error distribution link function exponential family; currently `binomial()` logistic link `poisson()` `Gamma()`log link available. data data frame weights optional vector weights used fitting process. May missing case weights 1. subset subset data used fitting contrasts optional list. See contrasts.arg `model.matrix.default()`. offset priori known component included linear predictor; default 0. na.action function indicates happen data contain NAs. default \"na.omit\". n.models number unique models keep. NULL, BAS attempt enumerate unless p > 35 method=\"MCMC\". methods using MCMC algorithms sample replacement, sampling stop number iterations exceeds min 'n.models' 'MCMC.iterations' exit 'n.models' updated reflect unique number models sampled. betaprior Prior coefficients model coefficients (except intercept).  Options include  g.prior,  CCH, robust,  intrinsic,  beta.prime, EB.local,  AIC,  BIC. modelprior Family prior distribution models.  Choices include uniform, Bernoulli, beta.binomial, truncated Beta-Binomial, tr.beta.binomial, truncated power family tr.power.prior. initprobs vector length p initial inclusion probabilities used sampling without replacement (intercept included probability one need added ) character string giving method used construct sampling probabilities \"Uniform\" predictor variable equally likely sampled (equivalent random sampling without replacement). \"eplogp\", use eplogprob function approximate Bayes factor using p-values find initial marginal inclusion probabilities sample without replacement using inclusion probabilities, may updated using estimates marginal inclusion probabilities. \"eplogp\" assumes MLEs full model exist; problems case 'p' large, initial sampling probabilities may obtained using eplogprob.marg fits model predictor separately.  run Markov Chain provide initial estimates marginal inclusion probabilities, use method=\"MCMC+BAS\" . initprobs used sampling method=\"MCMC\", determines order variables lookup table affects memory allocation large problems enumeration feasible.  variables always included set corresponding initprobs 1, override `modelprior` use `include.always` force variables always included model. include.always formula terms always included model probability one.  default `~ 1` meaning intercept always included.   also override values `initprobs` setting 1. method character variable indicating sampling method use: method=\"BAS\" uses Bayesian Adaptive Sampling (without replacement) using sampling probabilities given initprobs updates using marginal inclusion probabilities direct search/sample; method=\"MCMC\" combines random walk Metropolis Hastings (MC3 Raftery et al 1997) random swap variable included variable currently excluded (see Clyde, Ghosh, Littman (2010) details); method=\"MCMC+BAS\" runs initial MCMC calculate marginal inclusion probabilities samples without replacement BAS; method = \"deterministic\" runs deterministic sampling using initial probabilities (updating); recommended fast enumeration model independence good approximation joint posterior distribution model indicators.  BAS, sampling probabilities can updated models sampled. (see 'update' ).  recommend \"MCMC+BAS\" \"MCMC\" high dimensional problems. update number iterations potential updates sampling probabilities \"BAS\" method. NULL update, otherwise algorithm update using marginal inclusion probabilities change sampling takes place.  large model spaces, updating recommended. model space enumerated, leave default. bestmodel optional binary vector representing model initialize sampling. NULL sampling starts null model prob.rw MCMC methods, probability using random-walk proposal; otherwise use random \"flip\" move propose new model. MCMC.iterations Number models sample using MCMC options; greater 'n.models'. default 10*n.models. thin oFr \"MCMC\", thin MCMC chain every \"thin\" iterations; default  thinning.  large p, thinning can used significantly reduce memory requirements models associated summaries saved every thin  iterations.  thin = p,  model associated output recorded  every p iterations,similar Gibbs sampler SSVS. control list parameters control convergence fitting process.  See documentation glm.control() laplace logical variable whether use Laplace approximate integration respect g obtain marginal likelihood.  FALSE Cephes library used may inaccurate large n large values Wald Chisquared statistic. renormalize logical variable whether posterior probabilities based renormalizing marginal likelihoods times prior probabilities use Monte Carlo frequencies. Applies MCMC sampling. force.heredity Logical variable force levels factor included together include higher order interactions lower order terms included.  Currently supported `method='MCMC'` `method='BAS'` (experimental) non-Solaris platforms. Default FALSE. bigmem Logical variable indicate access large amounts memory (physical virtual) enumeration large model spaces, e.g. > 2^25.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"bas.glm returns object class basglm object class basglm list containing least following components: postprobs posterior probabilities models selected priorprobs prior probabilities models selected logmarg values log marginal likelihood models n.vars total number independent variables full model, including intercept size number independent variables models, includes intercept list lists one list per model variables included model probne0 posterior probability variable non-zero mle list lists one list per model giving GLM estimate (nonzero) coefficient model. mle.se list lists one list per model giving GLM standard error coefficient model deviance GLM deviance model modelprior prior distribution models created BMA  object Q Q statistic model used marginal likelihood approximation Y response X matrix predictors family family object original call betaprior family object prior coefficients, including  hyperparameters modelprior family object prior models include.always indices variables forced model","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"BAS provides several search algorithms find high probability models use Bayesian Model Averaging Bayesian model selection. p less 20-25, BAS can enumerate models depending memory availability, larger p, BAS samples without replacement using random deterministic sampling. Bayesian Adaptive Sampling algorithm Clyde, Ghosh, Littman (2010) samples models without replacement using initial sampling probabilities, optionally update sampling probabilities every \"update\" models using estimated marginal inclusion probabilities. BAS uses different methods obtain initprobs, may impact results high-dimensional problems. deterministic sampler provides list top models order approximation independence using provided initprobs.  may effective running algorithms identify high probability models works well correlations variables small modest.  priors coefficients mixtures g-priors provide approximations power prior.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"Li, Y. Clyde, M. (2018) Mixtures g-priors Generalized Linear Models.  Journal American Statistical Association. 113:1828-1845 doi:10.1080/01621459.2018.1469992   Clyde, M. Ghosh, J. Littman, M. (2010) Bayesian Adaptive Sampling Variable Selection Model Averaging. Journal Computational Graphics Statistics.  20:80-101 doi:10.1198/jcgs.2010.09049   Raftery, .E, Madigan, D. Hoeting, J.. (1997) Bayesian Model Averaging Linear Regression Models. Journal American Statistical Association.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"Merlise Clyde (clyde@duke.edu), Quanli Wang Yingbo Li","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Adaptive Sampling Without Replacement for Variable Selection in\nGeneralized Linear Models — bas.glm","text":"","code":"library(MASS) data(Pima.tr)   # enumeration  with default method=\"BAS\" pima.cch = bas.glm(type ~ ., data=Pima.tr, n.models= 2^7,               method=\"BAS\",               betaprior=CCH(a=1, b=532/2, s=0), family=binomial(),               modelprior=beta.binomial(1,1))  summary(pima.cch) #>           P(B != 0 | Y)   model 1      model 2      model 3      model 4 #> Intercept     1.0000000    1.0000    1.0000000    1.0000000    1.0000000 #> npreg         0.5684414    0.0000    1.0000000    1.0000000    0.0000000 #> glu           0.9999949    1.0000    1.0000000    1.0000000    1.0000000 #> bp            0.2198720    0.0000    0.0000000    0.0000000    0.0000000 #> skin          0.2653924    0.0000    0.0000000    0.0000000    0.0000000 #> bmi           0.7425039    1.0000    1.0000000    1.0000000    0.0000000 #> ped           0.8860972    1.0000    1.0000000    1.0000000    1.0000000 #> age           0.7459954    1.0000    1.0000000    0.0000000    1.0000000 #> BF                   NA    1.0000    0.4406494    0.6209086    0.4628319 #> PostProbs            NA    0.1596    0.1172000    0.0991000    0.0739000 #> R2                   NA    0.2938    0.3040000    0.2901000    0.2703000 #> dim                  NA    5.0000    6.0000000    5.0000000    4.0000000 #> logmarg              NA -101.7878 -102.6072611 -102.2643268 -102.5581467 #>                 model 5 #> Intercept  1.000000e+00 #> npreg      1.000000e+00 #> glu        1.000000e+00 #> bp         1.000000e+00 #> skin       1.000000e+00 #> bmi        1.000000e+00 #> ped        1.000000e+00 #> age        1.000000e+00 #> BF         8.659168e-03 #> PostProbs  4.840000e-02 #> R2         3.043000e-01 #> dim        8.000000e+00 #> logmarg   -1.065369e+02 image(pima.cch)  # Note MCMC.iterations are set to 2500 for illustration purposes due to time # limitations for running examples on CRAN servers. # Please check convergence diagnostics and run longer in practice  pima.robust = bas.glm(type ~ ., data=Pima.tr, n.models= 2^7,               method=\"MCMC\", MCMC.iterations=2500,               betaprior=robust(), family=binomial(),               modelprior=beta.binomial(1,1))  pima.BIC = bas.glm(type ~ ., data=Pima.tr, n.models= 2^7,               method=\"BAS+MCMC\", MCMC.iterations=2500,               betaprior=bic.prior(), family=binomial(),               modelprior=uniform()) #> Warning: no non-missing arguments to min; returning Inf # Poisson example if(requireNamespace(\"glmbb\", quietly=TRUE)) {   data(crabs, package='glmbb')   #short run for illustration   crabs.bas = bas.glm(satell ~ color*spine*width + weight, data=crabs,                       family=poisson(),                       betaprior=EB.local(), modelprior=uniform(),                       method='MCMC', n.models=2^10, MCMC.iterations=2500,                       prob.rw=.95)     # Gamma example  if(requireNamespace(\"faraway\", quietly=TRUE)) {     data(wafer, package='faraway')                            wafer_bas = bas.glm(resist~ ., data=wafer,  include.always = ~ .,                         betaprior = bic.prior() ,                         family = Gamma(link = \"log\"))   } }"},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"Sample without replacement posterior distribution models","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"","code":"bas.lm(   formula,   data,   subset,   weights,   contrasts = NULL,   na.action = \"na.omit\",   n.models = NULL,   prior = \"ZS-null\",   alpha = NULL,   modelprior = beta.binomial(1, 1),   initprobs = \"Uniform\",   include.always = ~1,   method = \"BAS\",   update = NULL,   bestmodel = NULL,   prob.local = 0,   prob.rw = 0.5,   MCMC.iterations = NULL,   lambda = NULL,   delta = 0.025,   thin = 1,   renormalize = FALSE,   force.heredity = FALSE,   pivot = TRUE,   tol = 1e-07,   bigmem = FALSE )"},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"formula linear model formula full model predictors, Y ~ X.  code assumes intercept included model X's centered. data data frame.  Factors converted numerical vectors based using `model.matrix`. subset optional vector specifying subset observations used fitting process. weights optional vector weights used fitting process. NULL numeric vector. non-NULL, Bayes estimates obtained assuming \\(Y_i \\sim N(x^T_i\\beta, \\sigma^2/w_i)\\). contrasts optional list. See contrasts.arg `model.matrix.default()`. na.action function indicates happen data contain NAs. default \"na.omit\". n.models number models sample either without replacement (method=\"BAS\" \"MCMC+BAS\") replacement (method=\"MCMC\"). NULL, BAS method=\"BAS\" try enumerate 2^p models. enumeration possible (memory time) value supplied controls number sampled models using 'n.models'.  method=\"MCMC\", sampling stop min(n.models, MCMC.iterations) occurs MCMC.iterations significantly larger n.models order explore model space. exit method= \"MCMC\" number unique models sampled counts stored output \"freq\". prior prior distribution regression coefficients.  Choices include \"AIC\" \"BIC\" \"g-prior\", Zellner's g prior `g` specified using argument `alpha` \"JZS\"  Jeffreys-Zellner-Siow prior uses Jeffreys prior sigma Zellner-Siow Cauchy prior coefficients. optional parameter `alpha` can used control squared scale prior, default alpha=1. Setting `alpha` equal rscale^2 BayesFactor package Morey. uses QUADMATH numerical integration g. \"ZS-null\", Laplace approximation 'JZS' prior integration g.  alpha = 1 . recommend using 'JZS' accuracy compatibility BayesFactor package, although slower. \"ZS-full\" (deprecated) \"hyper-g\", mixture g-priors prior g/(1+g) Beta(1, alpha/2) Liang et al (2008).  uses Cephes library evaluation marginal likelihoods may numerically unstable large n R2 close 1.  Default choice alpha 3. \"hyper-g-laplace\", using Laplace approximation integrate prior g. \"hyper-g-n\", mixture g-priors u = g/n u ~ Beta(1, alpha/2)  provide consistency null model true. \"EB-local\", use MLE g marginal likelihood within model \"EB-global\" uses EM algorithm find common global estimate g, averaged models.  possible enumerate models, EM algorithm uses models sampled EB-local. alpha optional hyperparameter g-prior hyper g-prior.  Zellner's g-prior, alpha = g, Liang et al hyper-g hyper-g-n method, recommended choice alpha (2 < alpha < 4), alpha = 3 default.  Zellner-Siow prior alpha = 1 default, can used modify rate parameter gamma prior g,   $$1/g \\sim G(1/2, n*\\alpha/2)$$ $$\\beta \\sim C(0, \\sigma^2 \\alpha (X'X/n)^{-1})$$. modelprior function family prior distribution models.  Choices include uniform Bernoulli beta.binomial, tr.beta.binomial, (truncation) tr.poisson (truncated Poisson), tr.power.prior (truncated power family),  default beta.binomial(1,1).  Truncated versions useful p > n. initprobs Vector length p character string specifying method used create vector. used order variables sampling methods potentially efficient storage sampling provides initial inclusion probabilities used sampling without replacement method=\"BAS\".  Options character string giving method : \"Uniform\" \"uniform\" predictor variable equally likely sampled (equivalent random sampling without replacement); \"eplogp\" uses eplogprob function approximate Bayes factor p-values full model find initial marginal inclusion probabilities; \"marg-eplogp\" useseplogprob.marg function approximate Bayes factor p-values full model simple linear regression.  run Markov Chain provide initial estimates marginal inclusion probabilities \"BAS\", use method=\"MCMC+BAS\" . initprobs used sampling method=\"MCMC\", determines order variables lookup table affects memory allocation large problems enumeration feasible.  variables always included set corresponding initprobs 1, override `modelprior` use `include.always` force variables always included model. include.always formula terms always included model probability one.  default `~ 1` meaning intercept always included.  also override values `initprobs` setting 1. method character variable indicating sampling method use: \"deterministic\" uses \"top k\" algorithm described Ghosh Clyde (2011) sample models order approximate probability conditional independence using \"initprobs\".  efficient algorithm enumeration. \"BAS\" uses Bayesian Adaptive Sampling (without replacement) using sampling probabilities given initprobs model conditional independence. can updated based estimates marginal inclusion probabilities. \"MCMC\" samples replacement via MCMC algorithm combines birth/death random walk Hoeting et al (1997) MC3 random swap move interchange variable model one currently excluded described Clyde, Ghosh Littman (2010). \"MCMC+BAS\" runs initial MCMC calculate marginal inclusion probabilities samples without replacement BAS.  BAS, sampling probabilities can updated models sampled. (see update ). update number iterations potential updates sampling probabilities method \"BAS\" \"MCMC+BAS\". NULL update, otherwise algorithm update using marginal inclusion probabilities change sampling takes place.  large model spaces, updating recommended. model space enumerated, leave default. bestmodel optional binary vector representing model initialize sampling. NULL sampling starts null model prob.local future option allow sampling models \"near\" median probability model.  used time. prob.rw MCMC methods, probability using random-walk Metropolis proposal; otherwise use random \"flip\" move propose swap variable excluded variable model. MCMC.iterations Number iterations MCMC sampler; default n.models*10 set user. lambda Parameter AMCMC algorithm (deprecated). delta truncation parameter prevent sampling probabilities degenerate 0 1 prior enumeration sampling without replacement. thin \"MCMC\" \"MCMC+BAS\", thin MCMC chain every \"thin\" iterations; default thinning.  large p, thinning can used significantly reduce memory requirements models associated summaries saved every thin iterations.  thin = p,  model associated output recorded every p iterations, similar Gibbs sampler SSVS. renormalize MCMC sampling, posterior probabilities based renormalizing marginal likelihoods times prior probabilities (TRUE) frequencies MCMC.  latter unbiased long runs, former may less variability.  May compared via diagnostic plot function diagnostics. See details Clyde Ghosh (2012). force.heredity Logical variable force levels factor included together include higher order interactions lower order terms included.  Currently supported `method='MCMC'` experimentally `method='BAS'` non-Solaris platforms. Default FALSE. pivot Logical variable allow pivoting columns obtaining OLS estimates model models full rank can fit. Defaults TRUE. Currently coefficients estimable set zero.  Use caution interpreting BMA estimates parameters. tol 1e-7 bigmem Logical variable indicate access large amounts memory (physical virtual) enumeration large model spaces, e.g. > 2^25. default; used determining rank X^TX cholesky decomposition pivoting.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"bas returns object class bas object class BAS list containing least following components: postprob posterior probabilities models selected priorprobs prior probabilities models selected namesx names variables R2 R2 values models logmarg values log marginal likelihood models.  equivalent log Bayes Factor comparing model base model intercept . n.vars total number independent variables full model, including intercept size number independent variables models, includes intercept rank rank design matrix; `pivot = FALSE`, size  checking rank conducted. list lists one list per model variables included model probne0 posterior probability variable non-zero computed using renormalized marginal likelihoods sampled models.  may biased number sampled models much smaller total number models. Unbiased estimates may obtained using method \"MCMC\". mle list lists one list per model giving MLE (OLS) estimate (nonzero) coefficient model. NOTE: intercept mean Y column X centered subtracting mean. mle.se list lists one list per model giving MLE (OLS) standard error coefficient model prior name prior created BMA object alpha value hyperparameter coefficient prior used create BMA object. modelprior prior distribution models created BMA object Y response X matrix predictors mean.x vector means column X (used predict.bas) include.always indices variables forced model function summary.bas, used print summary results. function plot.bas used plot posterior distributions coefficients image.bas provides image distribution models.  Posterior summaries coefficients can extracted using coefficients.bas.  Fitted values predictions can obtained using S3 functions fitted.bas predict.bas.  BAS objects may updated use different prior (without rerunning sampler) using function update.bas. MCMC sampling diagnostics can used assess whether MCMC run long enough posterior probabilities stable. details see associated demos vignette.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"BAS provides several algorithms sample posterior distributions models use Bayesian Model Averaging Bayesian variable selection. p less 20-25, BAS can enumerate models depending memory availability.  BAS saves models, MLEs, standard errors, log marginal likelihoods, prior posterior  probabilities memory requirements grow linearly M*p M number models p number predictors.  example, enumeration p=21 2,097,152 takes just 2 Gigabytes 64 bit machine store summaries needed model averaging. (future version likely include option store summaries users plan using  model averaging model selection Best Predictive models.) larger p, BAS samples without replacement using random deterministic sampling. Bayesian Adaptive Sampling algorithm Clyde, Ghosh, Littman (2010) samples models without replacement using initial sampling probabilities, optionally update sampling probabilities every \"update\" models using estimated marginal inclusion probabilities. BAS uses different methods obtain initprobs, may impact results high-dimensional problems. deterministic sampler provides list top models order approximation independence using provided initprobs.  may effective running algorithms identify high probability models works well correlations variables small modest. recommend \"MCMC\" problems enumeration feasible (memory time constrained) even modest p number models sampled close number possible models /significant correlations among predictors bias estimates inclusion probabilities \"BAS\" \"MCMC+BAS\" may large relative reduced variability using normalized model probabilities shown Clyde Ghosh, 2012. Diagnostic plots MCMC can used assess convergence. large problems recommend thinning MCMC reduce memory requirements. priors coefficients include Zellner's g-prior, Hyper-g prior (Liang et al 2008, Zellner-Siow Cauchy prior, Empirical Bayes (local global) g-priors.  AIC BIC also included, range priors model space available.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"Clyde, M. Ghosh, J. Littman, M. (2010) Bayesian Adaptive Sampling Variable Selection Model Averaging. Journal Computational Graphics Statistics.  20:80-101 doi:10.1198/jcgs.2010.09049 Clyde, M. Ghosh. J. (2012) Finite population estimators stochastic search variable selection. Biometrika, 99 (4), 981-988. doi:10.1093/biomet/ass040 Clyde, M. George, E. . (2004) Model Uncertainty. Statist. Sci., 19, 81-94. doi:10.1214/088342304000000035 Clyde, M. (1999) Bayesian Model Averaging Model Search Strategies (discussion). Bayesian Statistics 6. J.M. Bernardo, .P. Dawid, J.O. Berger, .F.M. Smith eds. Oxford University Press, pages 157-185. Hoeting, J. ., Madigan, D., Raftery, . E. Volinsky, C. T. (1999) Bayesian model averaging: tutorial (discussion). Statist. Sci., 14, 382-401. doi:10.1214/ss/1009212519 Liang, F., Paulo, R., Molina, G., Clyde, M. Berger, J.O. (2008) Mixtures g-priors Bayesian Variable Selection. Journal American Statistical Association.  103:410-423.  doi:10.1198/016214507000001337 Zellner, . (1986) assessing prior distributions Bayesian regression analysis g-prior distributions. Bayesian Inference Decision Techniques: Essays Honor Bruno de Finetti, pp. 233-243. North-Holland/Elsevier. Zellner, . Siow, . (1980) Posterior odds ratios selected regression hypotheses. Bayesian Statistics: Proceedings First International Meeting held Valencia (Spain), pp. 585-603. Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., Iverson, G. (2009). Bayesian t-tests accepting rejecting null hypothesis. Psychonomic Bulletin & Review, 16, 225-237 Rouder, J. N., Morey, R. D., Speckman, P. L., Province, J. M., (2012) Default Bayes Factors ANOVA Designs. Journal Mathematical Psychology. 56.  p. 356-374.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"Merlise Clyde (clyde@duke.edu) Michael Littman","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bas.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Adaptive Sampling for Bayesian Model Averaging and Variable Selection in\nLinear Models — bas.lm","text":"","code":"library(MASS) data(UScrime)  # pivot=FALSE is faster, but should only be used in full rank case # default is pivot = TRUE crime.bic <- bas.lm(log(y) ~ log(M) + So + log(Ed) +   log(Po1) + log(Po2) +   log(LF) + log(M.F) + log(Pop) + log(NW) +   log(U1) + log(U2) + log(GDP) + log(Ineq) +   log(Prob) + log(Time),   data = UScrime, n.models = 2^15, prior = \"BIC\",   modelprior = beta.binomial(1, 1),   initprobs = \"eplogp\", pivot = FALSE )   # use MCMC rather than enumeration crime.mcmc <- bas.lm(log(y) ~ log(M) + So + log(Ed) +   log(Po1) + log(Po2) +   log(LF) + log(M.F) + log(Pop) + log(NW) +   log(U1) + log(U2) + log(GDP) + log(Ineq) +  log(Prob) + log(Time),   data = UScrime,   method = \"MCMC\",   MCMC.iterations = 20000, prior = \"BIC\",   modelprior = beta.binomial(1, 1),   initprobs = \"eplogp\", pivot = FALSE )  summary(crime.bic) #>           P(B != 0 | Y)   model 1       model 2     model 3     model 4 #> Intercept     1.0000000   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(M)        0.9335117   1.00000  1.000000e+00   1.0000000   1.0000000 #> So            0.3276563   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(Ed)       0.9910219   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(Po1)      0.7246635   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(Po2)      0.4602481   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(LF)       0.2935326   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(M.F)      0.3298168   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(Pop)      0.4962869   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(NW)       0.8346412   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(U1)       0.3481266   0.00000  1.000000e+00   0.0000000   0.0000000 #> log(U2)       0.7752102   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(GDP)      0.5253694   0.00000  1.000000e+00   0.0000000   1.0000000 #> log(Ineq)     0.9992058   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(Prob)     0.9541470   1.00000  1.000000e+00   1.0000000   1.0000000 #> log(Time)     0.5432686   1.00000  1.000000e+00   0.0000000   1.0000000 #> BF                   NA   1.00000  1.267935e-04   0.7609295   0.5431578 #> PostProbs            NA   0.01910  1.560000e-02   0.0145000   0.0133000 #> R2                   NA   0.84200  8.695000e-01   0.8265000   0.8506000 #> dim                  NA   9.00000  1.600000e+01   8.0000000  10.0000000 #> logmarg              NA -22.15855 -3.113150e+01 -22.4317627 -22.7689035 #>               model 5 #> Intercept   1.0000000 #> log(M)      1.0000000 #> So          0.0000000 #> log(Ed)     1.0000000 #> log(Po1)    1.0000000 #> log(Po2)    0.0000000 #> log(LF)     0.0000000 #> log(M.F)    0.0000000 #> log(Pop)    1.0000000 #> log(NW)     1.0000000 #> log(U1)     0.0000000 #> log(U2)     1.0000000 #> log(GDP)    0.0000000 #> log(Ineq)   1.0000000 #> log(Prob)   1.0000000 #> log(Time)   0.0000000 #> BF          0.5203179 #> PostProbs   0.0099000 #> R2          0.8375000 #> dim         9.0000000 #> logmarg   -22.8118635 plot(crime.bic)     image(crime.bic, subset = -1)   # example with two-way interactions and hierarchical constraints data(ToothGrowth) ToothGrowth$dose <- factor(ToothGrowth$dose) levels(ToothGrowth$dose) <- c(\"Low\", \"Medium\", \"High\") TG.bas <- bas.lm(len ~ supp * dose,   data = ToothGrowth,   modelprior = uniform(), method = \"BAS\",   force.heredity = TRUE ) summary(TG.bas) #>                   P(B != 0 | Y)  model 1    model 2     model 3      model 4 #> Intercept             1.0000000  1.00000  1.0000000  1.00000000 1.000000e+00 #> suppVC                0.9910702  1.00000  1.0000000  0.00000000 0.000000e+00 #> doseMedium            1.0000000  1.00000  1.0000000  1.00000000 0.000000e+00 #> doseHigh              1.0000000  1.00000  1.0000000  1.00000000 0.000000e+00 #> suppVC:doseMedium     0.4500943  0.00000  1.0000000  0.00000000 0.000000e+00 #> suppVC:doseHigh       0.4500943  0.00000  1.0000000  0.00000000 0.000000e+00 #> BF                           NA  1.00000  0.8320043  0.01650685 2.812754e-15 #> PostProbs                    NA  0.54100  0.4501000  0.00890000 0.000000e+00 #> R2                           NA  0.76230  0.7937000  0.70290000 0.000000e+00 #> dim                          NA  4.00000  6.0000000  3.00000000 1.000000e+00 #> logmarg                      NA 33.50461 33.3206946 29.40063248 0.000000e+00 #>                         model 5 #> Intercept          1.000000e+00 #> suppVC             1.000000e+00 #> doseMedium         0.000000e+00 #> doseHigh           0.000000e+00 #> suppVC:doseMedium  0.000000e+00 #> suppVC:doseHigh    0.000000e+00 #> BF                 7.895214e-16 #> PostProbs          0.000000e+00 #> R2                 5.950000e-02 #> dim                2.000000e+00 #> logmarg           -1.270492e+00 image(TG.bas)    # don't run the following due to time limits on CRAN   if (FALSE) {  # exmple with non-full rank case  loc <- system.file(\"testdata\", package = \"BAS\") d <- read.csv(paste(loc, \"JASP-testdata.csv\", sep = \"/\")) fullModelFormula <- as.formula(\"contNormal ~  contGamma * contExpon +                                 contGamma * contcor1 + contExpon * contcor1\")  # should trigger a warning (default is to use pivoting, so use pivot=FALSE  # only for full rank case)   out = bas.lm(fullModelFormula,               data = d,               alpha = 0.125316,               prior = \"JZS\",               weights = facFifty, force.heredity = FALSE, pivot = FALSE)   # use pivot = TRUE to fit non-full rank case  (default) # This is slower but safer  out =  bas.lm(fullModelFormula,               data = d,               alpha = 0.125316,               prior = \"JZS\",               weights = facFifty, force.heredity = FALSE, pivot = TRUE) } # more complete demo's demo(BAS.hald) #>  #>  #> \tdemo(BAS.hald) #> \t---- ~~~~~~~~ #>  #> > data(Hald) #>  #> > hald.gprior =  bas.lm(Y~ ., data=Hald, prior=\"g-prior\", alpha=13, #> +                       modelprior=beta.binomial(1,1), #> +                       initprobs=\"eplogp\") #>  #> > hald.gprior #>  #> Call: #> bas.lm(formula = Y ~ ., data = Hald, prior = \"g-prior\", alpha = 13,  #>     modelprior = beta.binomial(1, 1), initprobs = \"eplogp\") #>  #>  #>  Marginal Posterior Inclusion Probabilities:  #> Intercept         X1         X2         X3         X4   #>    1.0000     0.9019     0.6896     0.4653     0.6329   #>  #> > plot(hald.gprior)     #>  #> > summary(hald.gprior) #>           P(B != 0 | Y)  model 1    model 2    model 3    model 4    model 5 #> Intercept     1.0000000  1.00000  1.0000000 1.00000000  1.0000000  1.0000000 #> X1            0.9019245  1.00000  1.0000000 1.00000000  1.0000000  1.0000000 #> X2            0.6895830  1.00000  0.0000000 1.00000000  1.0000000  1.0000000 #> X3            0.4652762  0.00000  0.0000000 1.00000000  0.0000000  1.0000000 #> X4            0.6329266  0.00000  1.0000000 1.00000000  1.0000000  0.0000000 #> BF                   NA  1.00000  0.6923944 0.08991408  0.3355714  0.3344926 #> PostProbs            NA  0.24320  0.1684000 0.13120000  0.1224000  0.1220000 #> R2                   NA  0.97870  0.9725000 0.98240000  0.9823000  0.9823000 #> dim                  NA  3.00000  3.0000000 5.00000000  4.0000000  4.0000000 #> logmarg              NA 11.72735 11.3597547 9.31845348 10.6354335 10.6322138 #>  #> > image(hald.gprior, subset=-1, vlas=0)  #>  #> > hald.coef = coefficients(hald.gprior) #>  #> > hald.coef #>  #>  Marginal Posterior Summaries of Coefficients:  #>  #>  Using  BMA  #>  #>  Based on the top  16 models  #>            post mean  post SD  post p(B != 0) #> Intercept  95.4231     0.7107   1.0000        #> X1          1.2150     0.5190   0.9019        #> X2          0.2756     0.4832   0.6896        #> X3         -0.1271     0.4976   0.4653        #> X4         -0.3269     0.4717   0.6329        #>  #> > plot(hald.coef)      #>  #> > predict(hald.gprior, top=5, se.fit=TRUE)   #> $fit #>  [1]  79.74246  74.50010 105.29268  89.88693  95.57177 104.56409 103.40145 #>  [8]  77.13668  91.99731 114.21325  82.78446 111.00723 110.40160 #>  #> $Ybma #>            [,1] #>  [1,]  79.74246 #>  [2,]  74.50010 #>  [3,] 105.29268 #>  [4,]  89.88693 #>  [5,]  95.57177 #>  [6,] 104.56409 #>  [7,] 103.40145 #>  [8,]  77.13668 #>  [9,]  91.99731 #> [10,] 114.21325 #> [11,]  82.78446 #> [12,] 111.00723 #> [13,] 110.40160 #>  #> $Ypred #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 81.17036 74.83464 105.0725 89.69881 97.15898 104.4575 103.3893 76.06454 #> [2,] 77.70296 74.24113 105.8554 90.46267 93.09565 104.7152 103.1399 78.80193 #> [3,] 79.70437 74.40553 105.2175 89.76253 95.63309 104.5709 103.5254 77.08557 #> [4,] 79.65151 74.47846 105.4218 89.83174 95.62799 104.5962 103.5068 77.00839 #> [5,] 79.84321 74.31409 104.9063 89.65651 95.70301 104.5285 103.5476 77.15919 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 91.57174 113.1722 81.59906 111.2219 111.0884 #> [2,] 92.68123 115.8058 84.50293 110.4162 109.0791 #> [3,] 91.98604 114.1759 82.78145 111.1196 110.5321 #> [4,] 92.07571 114.1088 82.68233 111.0429 110.4674 #> [5,] 91.83513 114.2353 82.88128 111.2384 110.6515 #>  #> $postprobs #> [1] 0.3089304 0.2139017 0.1666632 0.1555023 0.1550024 #>  #> $se.fit #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 2.220164 2.265862 1.546911 2.181188 1.310135 1.523300 2.655096 2.176560 #> [2,] 2.716798 2.389723 1.633637 2.179215 1.321062 1.581232 2.721957 2.078129 #> [3,] 3.203405 2.501485 3.279273 2.357164 2.589756 1.549136 2.623290 2.765255 #> [4,] 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817 #> [5,] 2.932580 2.353352 1.538009 2.141694 2.507848 1.498758 2.616407 2.680289 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 1.883610 3.264656 1.908238 1.970691 2.054234 #> [2,] 2.013244 3.298134 1.933819 1.964374 1.924460 #> [3,] 2.353516 3.609909 2.821295 2.227363 2.390135 #> [4,] 1.990817 3.485929 2.456636 1.951456 2.212238 #> [5,] 1.889302 3.569065 2.665166 1.934336 2.117189 #>  #> $se.pred #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 5.057182 5.077410 4.799885 5.040193 4.728892 4.792328 5.262651 5.038191 #> [2,] 5.415848 5.259391 4.961773 5.167146 4.867815 4.944766 5.418438 5.125333 #> [3,] 5.489152 5.111401 5.533771 5.042342 5.155175 4.718984 5.172102 5.245534 #> [4,] 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065 #> [5,] 5.337427 5.042456 4.717369 4.947217 5.116386 4.704719 5.170463 5.203081 #>          [,9]    [,10]    [,11]    [,12]    [,13] #> [1,] 4.918734 5.594992 4.928218 4.952735 4.986566 #> [2,] 5.099370 5.729582 5.068538 5.080274 5.064974 #> [3,] 5.040638 5.735890 5.275291 4.982985 5.057839 #> [4,] 4.882702 5.659428 5.090431 4.866787 4.977090 #> [5,] 4.843301 5.711946 5.195307 4.861045 4.936658 #>  #> $se.bma.fit #>  [1] 2.688224 2.095245 1.769625 1.970919 2.197285 1.363804 2.356457 2.302631 #>  [9] 1.822084 3.141443 2.237663 1.801849 1.991374 #>  #> $se.bma.pred #>  [1] 4.838655 4.536087 4.395180 4.480017 4.584113 4.248058 4.662502 4.635531 #>  [9] 4.416563 5.104380 4.603604 4.408253 4.489054 #>  #> $df #> [1] 12 12 12 12 12 #>  #> $best #> [1]  7  4 14 16  2 #>  #> $bestmodel #> $bestmodel[[1]] #> [1] 0 1 2 #>  #> $bestmodel[[2]] #> [1] 0 1 4 #>  #> $bestmodel[[3]] #> [1] 0 1 2 3 4 #>  #> $bestmodel[[4]] #> [1] 0 1 2 4 #>  #> $bestmodel[[5]] #> [1] 0 1 2 3 #>  #>  #> $best.vars #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X3\"        \"X4\"        #>  #> $estimator #> [1] \"BMA\" #>  #> attr(,\"class\") #> [1] \"pred.bas\" #>  #> > confint(predict(hald.gprior, Hald, estimator=\"BMA\", se.fit=TRUE, top=5), parm=\"mean\") #>            2.5%     97.5%      mean #>  [1,]  73.12098  85.72244  79.74246 #>  [2,]  69.29372  79.48791  74.50010 #>  [3,] 101.13915 109.79719 105.29268 #>  [4,]  84.94208  94.39819  89.88693 #>  [5,]  90.51869 100.37157  95.57177 #>  [6,] 101.26810 107.88915 104.56409 #>  [7,]  97.78924 109.02951 103.40145 #>  [8,]  71.64513  82.72126  77.13668 #>  [9,]  87.56827  96.41263  91.99731 #> [10,] 106.43002 121.77740 114.21325 #> [11,]  77.67284  88.40456  82.78446 #> [12,] 106.72305 115.38382 111.00723 #> [13,] 105.55495 115.18690 110.40160 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" #>  #> > predict(hald.gprior, estimator=\"MPM\", se.fit=TRUE)   #> $fit #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 #> attr(,\"model\") #> [1] 0 1 2 4 #> attr(,\"best\") #> [1] 1 #> attr(,\"estimator\") #> [1] \"MPM\" #>  #> $Ybma #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 #> attr(,\"model\") #> [1] 0 1 2 4 #> attr(,\"best\") #> [1] 1 #> attr(,\"estimator\") #> [1] \"MPM\" #>  #> $Ypred #> NULL #>  #> $postprobs #> NULL #>  #> $se.fit #>  [1] 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817 #>  [9] 1.990817 3.485929 2.456636 1.951456 2.212238 #>  #> $se.pred #>  [1] 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065 #>  [9] 4.882702 5.659428 5.090431 4.866787 4.977090 #>  #> $se.bma.fit #> NULL #>  #> $se.bma.pred #> NULL #>  #> $df #> [1] 12 #>  #> $best #> NULL #>  #> $bestmodel #> [1] 0 1 2 4 #>  #> $best.vars #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X4\"        #>  #> $estimator #> [1] \"MPM\" #>  #> attr(,\"class\") #> [1] \"pred.bas\" #>  #> > confint(predict(hald.gprior, Hald, estimator=\"MPM\", se.fit=TRUE), parm=\"mean\") #>            2.5%     97.5%      mean #>  [1,]  72.85939  86.44363  79.65151 #>  [2,]  69.50215  79.45478  74.47846 #>  [3,] 101.93102 108.91264 105.42183 #>  [4,]  85.14928  94.51420  89.83174 #>  [5,]  89.98634 101.26964  95.62799 #>  [6,] 101.30948 107.88283 104.59616 #>  [7,]  97.81813 109.19556 103.50684 #>  [8,]  71.46153  82.55525  77.00839 #>  [9,]  87.73810  96.41333  92.07571 #> [10,] 106.51357 121.70394 114.10876 #> [11,]  77.32978  88.03488  82.68233 #> [12,] 106.79101 115.29472 111.04286 #> [13,] 105.64736 115.28746 110.46741 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" #>  #> > fitted(hald.gprior, estimator=\"HPM\") #>  [1]  81.17036  74.83464 105.07248  89.69881  97.15898 104.45753 103.38927 #>  [8]  76.06454  91.57174 113.17222  81.59906 111.22195 111.08841 #>  #> > hald.gprior =  bas.lm(Y~ ., data=Hald, n.models=2^4, #> +                       prior=\"g-prior\", alpha=13, modelprior=uniform(), #> +                       initprobs=\"eplogp\") #>  #> > hald.EB = update(hald.gprior, newprior=\"EB-global\") #>  #> > hald.bic = update(hald.gprior,newprior=\"BIC\") #>  #> > hald.zs = update(hald.bic, newprior=\"ZS-null\") if (FALSE) { demo(BAS.USCrime) }"},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"version glm.fit rewritten C; also returns marginal likelihoods Bayesian model comparison","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"","code":"bayesglm.fit(   x,   y,   weights = rep(1, nobs),   start = NULL,   etastart = NULL,   mustart = NULL,   offset = rep(0, nobs),   family = binomial(),   coefprior = bic.prior(nobs),   control = glm.control(),   intercept = TRUE )"},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"x design matrix y response weights optional vector weights used fitting process. NULL numeric vector. start starting value coefficients linear predictor etastart starting values linear predictor mustart starting values vectors means offset priori known component included linear predictor family description error distribution link function exponential family; currently binomial(), poisson(), Gamma() canonical links implemented. coefprior function specifying prior distribution coefficients optional hyperparameters leading marginal likelihood calculations; options include bic.prior(), aic.prior(), ic.prior() control list parameters control convergence fitting process.  See documentation glm.control() intercept intercept included null model?","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"coefficients MLEs se Standard errors coefficients based sqrt diagonal inverse information matrix mu fitted mean rank numeric rank fitted linear model deviance minus twice log likelihood evaluated MLEs g value g g-priors shrinkage shrinkage factor coefficients linear predictor RegSS quadratic form beta'(beta)beta used shrinkage logmarglik log marginal integrated log likelihood (constant)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"C version glm-fit.  different prior choices returns, marginal likelihood model using Laplace approximation.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"glm","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"Merlise Clyde translated glm.fit R base C using .Call interface","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bayesglm.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting Generalized Linear Models and Bayesian marginal likelihood\nevaluation — bayesglm.fit","text":"","code":"data(Pima.tr, package=\"MASS\") Y <- as.numeric(Pima.tr$type) - 1 X <- cbind(1, as.matrix(Pima.tr[,1:7])) out <- bayesglm.fit(X, Y, family=binomial(),coefprior=bic.prior(n=length(Y))) out$coef #> [1] -9.773061533  0.103183427  0.032116823 -0.004767542 -0.001916632 #> [6]  0.083623912  1.820410367  0.041183529 out$se #> [1] 1.770386016 0.064694153 0.006787299 0.018540741 0.022499541 0.042826888 #> [7] 0.665513776 0.022090978 # using built in function glm(type ~ ., family=binomial(), data=Pima.tr) #>  #> Call:  glm(formula = type ~ ., family = binomial(), data = Pima.tr) #>  #> Coefficients: #> (Intercept)        npreg          glu           bp         skin          bmi   #>   -9.773062     0.103183     0.032117    -0.004768    -0.001917     0.083624   #>         ped          age   #>    1.820410     0.041184   #>  #> Degrees of Freedom: 199 Total (i.e. Null);  192 Residual #> Null Deviance:\t    256.4  #> Residual Deviance: 178.4 \tAIC: 194.4"},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta-Binomial Prior Distribution for Models — beta.binomial","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"Creates object representing prior distribution models BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"","code":"beta.binomial(alpha = 1, beta = 1)"},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"alpha parameter beta prior distribution beta parameter beta prior distribution","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"beta-binomial distribution model size obtained assigning variable inclusion indicator independent Bernoulli distributions probability w, giving w beta(alpha,beta) distribution. Marginalizing w leads distribution model size beta-binomial distribution. default hyperparameters lead uniform distribution model size.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.binomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Beta-Binomial Prior Distribution for Models — beta.binomial","text":"","code":"beta.binomial(1, 10) #' @family priors modelpriors #> $family #> [1] \"Beta-Binomial\" #>  #> $hyper.parameters #> [1]  1 10 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":null,"dir":"Reference","previous_headings":"","what":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"Creates object representing Beta-Prime prior mixture g-priors coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"","code":"beta.prime(n = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"n sample size; NULL, value derived data call `bas.glm` used.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/beta.prime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Beta-Prime Prior Distribution for Coefficients in BMA Model — beta.prime","text":"","code":"beta.prime(n = 100) #> $family #> [1] \"betaprime\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$n #> [1] 100 #>  #> $hyper.parameters$alpha #> [1] 0.5 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":null,"dir":"Reference","previous_headings":"","what":"Bodyfat Data — bodyfat","title":"Bodyfat Data — bodyfat","text":"Lists estimates percentage body fat determined underwater weighing various body circumference measurements 252 men.  Accurate measurement body fat inconvenient/costly desirable easy methods estimating body fat inconvenient/costly.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Bodyfat Data — bodyfat","text":"data frame 252 observations following 15 variables. Density numeric vector density determined underwater weighing Bodyfat percent body fat Siri's (1956) equation Age age individual years Weight weight individual pounds Height height individual inches Neck neck circumference centimeters (cm) Chest chest circumference (cm) Abdomen abdomen circumference (cm) Hip hip circumference (cm) \"Thigh\" thigh circumference (cm) \"Knee\" knee circumference (cm) Ankle ankle circumference (cm) Biceps bicep (extended) circumference (cm) Forearm forearm circumference (cm) Wrist wrist circumference (cm)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Bodyfat Data — bodyfat","text":"data used produce predictive equations lean body weight given abstract \"Generalized body composition prediction equation men using simple measurement techniques\", K.W. Penrose, .G. Nelson, .G. Fisher, FACSM, Human Performance Research Center, Brigham Young University, Provo, Utah 84602 listed _Medicine Science Sports Exercise_, vol. 17, . 2, April 1985, p. 189. (predictive equations obtained first 143 252 cases listed ). data generously supplied Dr. . Garth Fisher gave permission freely distribute data use non-commercial purposes.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bodyfat Data — bodyfat","text":"variety popular health books suggest readers assess health, least part, estimating percentage body fat. Bailey (1994), instance, reader can estimate body fat tables using age various skin-fold measurements obtained using caliper. texts give predictive equations body fat using body circumference measurements (e.g. abdominal circumference) /skin-fold measurements. See, instance, Behnke Wilmore (1974), pp. 66-67; Wilmore (1976), p. 247; Katch McArdle (1977), pp. 120-132).# Percentage body fat individual can estimated body density determined. Folks (e.g. Siri (1956)) assume body consists two components - lean body tissue fat tissue. Letting D = Body Density (gm/cm^3) = proportion lean body tissue B = proportion fat tissue (+B=1) = density lean body tissue (gm/cm^3) b = density fat tissue (gm/cm^3) D = 1/[(/) + (B/b)] solving B find B = (1/D)*[ab/(-b)] - [b/(-b)]. Using estimates =1.10 gm/cm^3 b=0.90 gm/cm^3 (see Katch McArdle (1977), p. 111 Wilmore (1976), p. 123) come \"Siri's equation\": Percentage Body Fat (.e. 100*B) = 495/D - 450.# Volume, hence body density, can accurately measured variety ways. technique underwater weighing \"computes body volume difference body weight measured air weight measured water submersion. words, body volume equal loss weight water appropriate temperature correction water's density\" (Katch McArdle (1977), p. 113). Using technique, Body Density = WA/[(WA-WW)/c.f. - LV] WA = Weight air (kg) WW = Weight water (kg) c.f. = Water correction factor (=1 39.2 deg F one-gram water occupies exactly one cm^3 temperature, =.997 76-78 deg F) LV = Residual Lung Volume (liters) (Katch McArdle (1977), p. 115). methods determining body volume given Behnke Wilmore (1974), p. 22 ff. Measurement standards apparently listed Behnke Wilmore (1974), pp. 45-48 , instance, abdomen circumference measured \"laterally, level iliac crests, anteriorly, umbilicus\".)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bodyfat Data — bodyfat","text":"Bailey, Covert (1994). Smart Exercise: Burning Fat, Getting Fit, Houghton-Mifflin Co., Boston, pp. 179-186. Behnke, .R. Wilmore, J.H. (1974). Evaluation Regulation Body Build Composition, Prentice-Hall, Englewood Cliffs, N.J. Siri, W.E. (1956), \"Gross composition body\", Advances Biological Medical Physics, vol. IV, edited J.H. Lawrence C.. Tobias, Academic Press, Inc., New York. Katch, Frank McArdle, William (1977). Nutrition, Weight Control, Exercise, Houghton Mifflin Co., Boston. Wilmore, Jack (1976). Athletic Training Physical Fitness: Physiological Principles Conditioning Process, Allyn Bacon, Inc., Boston.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/bodyfat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bodyfat Data — bodyfat","text":"","code":"data(bodyfat) bodyfat.bas = bas.lm(Bodyfat ~ Abdomen, data=bodyfat, prior=\"ZS-null\") summary(bodyfat.bas) #>           P(B != 0 | Y)  model 1      model 2 #> Intercept             1   1.0000 1.000000e+00 #> Abdomen               1   1.0000 0.000000e+00 #> BF                   NA   1.0000 1.039211e-57 #> PostProbs            NA   1.0000 0.000000e+00 #> R2                   NA   0.6617 0.000000e+00 #> dim                  NA   2.0000 1.000000e+00 #> logmarg              NA 131.2089 0.000000e+00 plot(Bodyfat ~ Abdomen, data=bodyfat, xlab=\"abdomen circumference (cm)\") betas = coef(bodyfat.bas)$postmean   # current version has that intercept is ybar betas[1] = betas[1] - betas[2]*bodyfat.bas$mean.x abline(betas) abline(coef(lm(Bodyfat ~ Abdomen, data=bodyfat)), col=2, lty=2)"},{"path":"http://merliseclyde.github.io/BAS/reference/climate.html","id":null,"dir":"Reference","previous_headings":"","what":"Climate Data — climate","title":"Climate Data — climate","text":"Climate Data","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/climate.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Climate Data — climate","text":"Scientists interested Earth's temperature change since last glacial maximum, 20,000 years ago. first study estimate temperature change published 1980, estimated change -1.5 degrees  C, +/- 1.2 degrees C tropical sea surface temperatures.  negative value means Earth colder now.  Since 1980 many studies. climate dataset 63 measurements 5 variables: sdev standard deviation calculated deltaT; proxy number 1-8 reflecting type measurement system used derive deltaT. proxies can used land, others water. proxies coded 1 \"Mg/Ca\"          2 \"alkenone\"       3 \"Faunal\"         4 \"Sr/Ca\"          5 \"del 180\"        6 \"Ice Core\"       7 \"Pollen\"         8 \"Noble Gas\" T/M , indicator whether terrestrial marine study (T/M),  coded 0 Terrestrial, 1 Marine; latitude latitude data collected.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/climate.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Climate Data — climate","text":"Data provided originally Michael Lavine","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients of a Bayesian Model Average object — coef.bas","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"Extract conditional posterior means standard deviations, marginal posterior means standard deviations, posterior probabilities, marginal inclusions probabilities Bayesian Model Averaging object class 'bas'","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"","code":"# S3 method for bas coef(object, n.models, estimator = \"BMA\", ...)  # S3 method for coef.bas print(x, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"object object class 'bas' created BAS n.models Number top models report printed summary, coef default use models.  extract summaries Highest Probability Model, use n.models=1 estimator=\"HPM\". estimator return summaries selected model, rather using BMA.  Options 'HPM' (highest posterior probability model) ,'MPM' (median probability model), 'BMA' ... optional arguments x object class 'coef.bas' print digits number significant digits print","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"coefficients returns object class coef.bas following: conditionalmeans matrix conditional posterior means model conditionalsd standard deviations model postmean marginal posterior means regression coefficient using BMA postsd marginal posterior standard deviations using BMA postne0 vector posterior inclusion probabilities, marginal probability coefficient non-zero","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"Calculates posterior means (approximate) standard deviations regression coefficients Bayesian Model averaging using g-priors mixtures g-priors.  Print returns overall summaries. fully Bayesian methods place prior g, posterior standard deviations take account full uncertainty regarding g. updated future releases.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"highly correlated variables, marginal summaries may representative joint distribution. Use plot.coef.bas view distributions.  value reported intercept centered parameterization.   Gaussian error model centered sample mean Y.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"Liang, F., Paulo, R., Molina, G., Clyde, M. Berger, J.O. (2005) Mixtures g-priors Bayesian Variable Selection.  Journal American Statistical Association.  103:410-423.  doi:10.1198/016214507000001337","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients of a Bayesian Model Average object — coef.bas","text":"","code":"data(\"Hald\") hald.gprior =  bas.lm(Y~ ., data=Hald, n.models=2^4, alpha=13,                       prior=\"ZS-null\", initprobs=\"Uniform\", update=10) coef.hald.gprior = coefficients(hald.gprior) coef.hald.gprior #>  #>  Marginal Posterior Summaries of Coefficients:  #>  #>  Using  BMA  #>  #>  Based on the top  16 models  #>            post mean  post SD   post p(B != 0) #> Intercept  95.42308    0.67885   1.00000       #> X1          1.40116    0.35351   0.97454       #> X2          0.42326    0.38407   0.76017       #> X3         -0.03997    0.33398   0.30660       #> X4         -0.22077    0.36931   0.44354       plot(coef.hald.gprior)      confint(coef.hald.gprior) #>                  2.5%      97.5%        beta #> Intercept 93.98929153 96.8992566 95.42307692 #> X1         0.61104473  2.1680535  1.40116123 #> X2        -0.04265929  1.0361251  0.42325794 #> X3        -0.79230007  0.7202382 -0.03997087 #> X4        -0.80838902  0.2556555 -0.22076600 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\"  #Estimation under Median Probability Model coef.hald.gprior = coefficients(hald.gprior, estimator=\"MPM\") coef.hald.gprior #>  #>  Marginal Posterior Summaries of Coefficients:  #>  #>  Using  MPM  #>  #>  Based on the top  1 models  #>            post mean  post SD   post p(B != 0) #> Intercept  95.42308    0.66740   1.00000       #> X1          1.45542    0.12077   1.00000       #> X2          0.65644    0.04565   1.00000       #> X3          0.00000    0.00000   0.00000       #> X4          0.00000    0.00000   0.00000       plot(coef.hald.gprior)      plot(confint(coef.hald.gprior))  #> NULL   coef.hald.gprior = coefficients(hald.gprior, estimator=\"HPM\") coef.hald.gprior #>  #>  Marginal Posterior Summaries of Coefficients:  #>  #>  Using  HPM  #>  #>  Based on the top  1 models  #>            post mean  post SD   post p(B != 0) #> Intercept  95.42308    0.66740   1.00000       #> X1          1.45542    0.12077   0.97454       #> X2          0.65644    0.04565   0.76017       #> X3          0.00000    0.00000   0.30660       #> X4          0.00000    0.00000   0.44354       plot(coef.hald.gprior)      confint(coef.hald.gprior) #>                 2.5%     97.5%       beta #> Intercept 93.9689432 96.877211 95.4230769 #> X1         1.1922938  1.718554  1.4554239 #> X2         0.5569707  0.755910  0.6564404 #> X3         0.0000000  0.000000  0.0000000 #> X4         0.0000000  0.000000  0.0000000 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\"  # To add estimation under Best Predictive Model"},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"Uses Monte Carlo simulations using posterior means standard deviations coefficients generate draws posterior distributions returns highest posterior density (HPD) credible intervals.  number models equals one, use t distribution find intervals.  currently condition estimate $g$.  description ~~","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"","code":"# S3 method for coef.bas confint(object, parm, level = 0.95, nsim = 10000, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"object coef.bas object parm specification parameters given credible intervals, either vector numbers vector names. missing, parameters considered. level probability coverage required nsim number Monte Carlo draws posterior distribution. Used number models greater 1. ... arguments passed; none currently","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"matrix (vector) columns giving lower upper HPD credible limits parameter. labeled 1-level)/2 1 - (1-level)/2 percent (default 2.5 97.5).","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"mixture g-priors approximate.  uses Monte Carlo sampling results may subject Monte Carlo variation larger values nsim may needed reduce variability.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Credible Intervals for BAS regression coefficients from BAS objects — confint.coef.bas","text":"","code":"data(\"Hald\") hald_gprior <-  bas.lm(Y~ ., data=Hald, alpha=13,                             prior=\"g-prior\") coef_hald <- coef(hald_gprior) confint(coef_hald) #>                2.5%      97.5%       beta #> Intercept 93.755762 96.9040431 95.4230769 #> X1         0.000000  1.8881172  1.2150202 #> X2        -1.107504  0.9329637  0.2756235 #> X3        -1.534797  0.5727478 -0.1270575 #> X4        -1.694228  0.2931558 -0.3268710 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" confint(coef_hald, approx=FALSE, nsim=5000) #>                   2.5%      97.5%       beta #> Intercept 93.925744324 97.0345800 95.4230769 #> X1        -0.002202755  1.8832172  1.2150202 #> X2        -1.155873753  0.8113817  0.2756235 #> X3        -1.513979790  0.5588345 -0.1270575 #> X4        -1.720671394  0.1894892 -0.3268710 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" # extract just the coefficient of X4 confint(coef_hald, parm=\"X4\") #>       2.5%     97.5%      beta #> X4 -1.6651 0.2751071 -0.326871 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"Compute credible intervals -sample sample prediction regression function","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"","code":"# S3 method for pred.bas confint(object, parm, level = 0.95, nsim = 10000, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"object object created predict.bas parm character variable, \"mean\" \"pred\".  missing parm='pred'. level nominal level (point-wise) credible interval nsim number Monte Carlo simulations sampling methods BMA ... optional arguments pass next function call; none time.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"matrix lower upper level * 100 percent credible intervals either mean regression function predicted values.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"constructs approximate 95 percent Highest Posterior Density intervals 'pred.bas' objects.  estimator based model selection, intervals use Student t distribution using estimate g.  estimator based BMA, nsim draws mixture Student t distributions obtained HPD interval obtained Monte Carlo draws.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/confint.pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Credible (Bayesian Confidence) Intervals for a BAS predict object — confint.pred.bas","text":"","code":"data(\"Hald\") hald.gprior =  bas.lm(Y~ ., data=Hald, alpha=13, prior=\"g-prior\") hald.pred = predict(hald.gprior, estimator=\"BPM\", predict=FALSE, se.fit=TRUE) confint(hald.pred, parm=\"mean\") #>            2.5%     97.5%      mean #>  [1,]  72.85939  86.44363  79.65151 #>  [2,]  69.50215  79.45478  74.47846 #>  [3,] 101.93102 108.91264 105.42183 #>  [4,]  85.14928  94.51420  89.83174 #>  [5,]  89.98634 101.26964  95.62799 #>  [6,] 101.30948 107.88283 104.59616 #>  [7,]  97.81813 109.19556 103.50684 #>  [8,]  71.46153  82.55525  77.00839 #>  [9,]  87.73810  96.41333  92.07571 #> [10,] 106.51357 121.70394 114.10876 #> [11,]  77.32978  88.03488  82.68233 #> [12,] 106.79101 115.29472 111.04286 #> [13,] 105.64736 115.28746 110.46741 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" confint(hald.pred)  #default #>            2.5%     97.5%      pred #>  [1,]  67.79843  91.50459  79.65151 #>  [2,]  63.56396  85.39296  74.47846 #>  [3,]  95.09960 115.74406 105.42183 #>  [4,]  79.04805 100.61543  89.83174 #>  [5,]  84.39452 106.86146  95.62799 #>  [6,]  94.34116 114.85115 104.59616 #>  [7,]  92.24966 114.76402 103.50684 #>  [8,]  65.82223  88.19456  77.00839 #>  [9,]  81.43722 102.71421  92.07571 #> [10,] 101.77792 126.43959 114.10876 #> [11,]  71.59123  93.77342  82.68233 #> [12,] 100.43905 121.64668 111.04286 #> [13,]  99.62326 121.31156 110.46741 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" hald.pred = predict(hald.gprior, estimator=\"BMA\", predict=FALSE, se.fit=TRUE) confint(hald.pred) #>            2.5%     97.5%      pred #>  [1,]  68.17384  91.76730  79.68307 #>  [2,]  63.51660  85.46930  74.69127 #>  [3,]  94.85399 116.46995 105.63258 #>  [4,]  78.49045 100.86273  89.91648 #>  [5,]  84.50867 107.36036  95.67480 #>  [6,]  94.42085 115.55796 104.57616 #>  [7,]  91.67135 114.33886 103.47945 #>  [8,]  65.49777  88.04153  76.96808 #>  [9,]  81.69203 103.52448  92.22184 #> [10,] 101.06366 126.70204 113.84918 #> [11,]  70.54793  93.37291  82.59035 #> [12,] 100.16145 121.92075 110.87673 #> [13,]  98.89635 121.06867 110.34001 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\""},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Summaries for Out of Sample Prediction — cv.summary.bas","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"Compute average prediction error sample predictions","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"","code":"cv.summary.bas(pred, ytrue, score = \"squared-error\")"},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"pred fitted predicted value output predict.bas ytrue vector left response values score function used summarize error rate.  Either \"squared-error\", \"miss-class\"","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"squared error, average prediction error Bayesian estimator error = sqrt(sum(ytrue - yhat)^2/npred) binary data misclassification rate appropriate.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/cv.summary.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summaries for Out of Sample Prediction — cv.summary.bas","text":"","code":"if (FALSE) { library(foreign) cognitive <- read.dta(\"https://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta\") cognitive$mom_work <- as.numeric(cognitive$mom_work > 1) cognitive$mom_hs <- as.numeric(cognitive$mom_hs > 0) colnames(cognitive) <- c(\"kid_score\", \"hs\", \"iq\", \"work\", \"age\")  set.seed(42) n <- nrow(cognitive) test <- sample(1:n, size = round(.20 * n), replace = FALSE) testdata <- cognitive[test, ] traindata <- cognitive[-test, ] cog_train <- bas.lm(kid_score ~ ., prior = \"BIC\", modelprior = uniform(), data = traindata) yhat <- predict(cog_train, newdata = testdata, estimator = \"BMA\", se = F) cv.summary.bas(yhat$fit, testdata$kid_score) }"},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"BAS MCMC diagnostic plot — diagnostics","title":"BAS MCMC diagnostic plot — diagnostics","text":"Function help assess convergence MCMC sampling bas objects.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BAS MCMC diagnostic plot — diagnostics","text":"","code":"diagnostics(obj, type = c(\"pip\", \"model\"), ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BAS MCMC diagnostic plot — diagnostics","text":"obj object created bas.lm bas.glm type type diagnostic plot.  \"pip\" marginal inclusion probabilities used, \"model\", plot posterior model probabilities ... additional graphics parameters passed plot","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BAS MCMC diagnostic plot — diagnostics","text":"plot marginal inclusion probabilities (pip) estimated MCMC renormalized marginal likelihoods times prior probabilities model probabilities.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BAS MCMC diagnostic plot — diagnostics","text":"BAS calculates posterior model probabilities two ways method=\"MCMC\". first using relative Monte Carlo frequencies sampled models. second renormalize marginal likelihood times prior probabilities sampled models.  Markov chain converged, two quantities fall 1-1 line.  , running longer may required.  chain converged, Monte Carlo frequencies may less bias, although may exhibit variability repeated runs.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"BAS MCMC diagnostic plot — diagnostics","text":"Merlise Clyde (clyde@duke.edu)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BAS MCMC diagnostic plot — diagnostics","text":"","code":"library(MASS) data(UScrime) UScrime[, -2] <- log(UScrime[, -2]) crime.ZS <- bas.lm(y ~ .,   data = UScrime,   prior = \"ZS-null\",   modelprior = uniform(),   method = \"MCMC\",   MCMC.iter = 1000 ) # short run for the example diagnostics(crime.ZS)"},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":null,"dir":"Reference","previous_headings":"","what":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"eplogprob calculates approximate marginal posterior inclusion probabilities p-values computed linear model using lower bound approximation Bayes factors.  Used obtain initial inclusion probabilities sampling using Bayesian Adaptive Sampling bas.lm","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"","code":"eplogprob(lm.obj, thresh = 0.5, max = 0.99, int = TRUE)"},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"lm.obj linear model object thresh value inclusion probability p-value > 1/exp(1), lower bound approximation valid. max maximum value inclusion probability; used bas.lm function keep initial inclusion probabilities away 1. int Intercept included linear model, set marginal inclusion probability corresponding intercept 1","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"eplogprob returns vector marginal posterior inclusion probabilities variables linear model. int = TRUE, inclusion probability intercept set 1.  model full rank, variables linearly dependent base QR factorization NA p-values.  bas.lm, probabilities used sampling, inclusion probability set 0.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"Sellke, Bayarri Berger (2001) provide simple calibration p-values BF(p) = -e p log(p) provide lower bound Bayes factor comparing H0: beta = 0 versus H1: beta equal 0, p-value p less 1/e.  Using equal prior odds hypotheses H0 H1, approximate marginal posterior inclusion probability p(beta != 0 | data ) = 1/(1 + BF(p)) p > 1/e, set marginal inclusion probability 0.5 value given thresh.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"Sellke, Thomas, Bayarri, M. J., Berger, James O.  (2001), ``Calibration p-values testing precise null hypotheses'', American Statistician, 55, 62-71.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"eplogprob - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob","text":"","code":"library(MASS) data(UScrime) UScrime[,-2] = log(UScrime[,-2]) eplogprob(lm(y ~ ., data=UScrime)) #> (Intercept)           M          So          Ed         Po1         Po2  #>   1.0000000   0.9480823   0.5000000   0.9883193   0.5045770   0.5000000  #>          LF         M.F         Pop          NW          U1          U2  #>   0.5000000   0.5304659   0.5807429   0.8046414   0.5000000   0.6858642  #>         GDP        Ineq        Prob        Time  #>   0.6069289   0.9900000   0.9412475   0.5782754"},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":null,"dir":"Reference","previous_headings":"","what":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"eplogprob.marg calculates approximate marginal posterior inclusion probabilities p-values computed series simple linear regression models using lower bound approximation Bayes factors.  Used order variables appropriate obtain initial inclusion probabilities sampling using Bayesian Adaptive Sampling bas.lm","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"","code":"eplogprob.marg(Y, X, thresh = 0.5, max = 0.99, int = TRUE)"},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"Y response variable X design matrix column ones intercept thresh value inclusion probability p-value > 1/exp(1), lower bound approximation valid. max maximum value inclusion probability; used bas.lm function keep initial inclusion probabilities away 1. int Intercept included linear model, set marginal inclusion probability corresponding intercept 1","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"eplogprob.prob returns vector marginal posterior inclusion probabilities variables linear model. int = TRUE, inclusion probability intercept set 1.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"Sellke, Bayarri Berger (2001) provide simple calibration p-values BF(p) = -e p log(p) provide lower bound Bayes factor comparing H0: beta = 0 versus H1: beta equal 0, p-value p less 1/e.  Using equal prior odds hypotheses H0 H1, approximate marginal posterior inclusion probability p(beta != 0 | data ) = 1/(1 + BF(p)) p > 1/e, set marginal inclusion probability 0.5 value given thresh. eplogprob.marg marginal p-values obtained using statistics p simple linear regressions P(F > (n-2) R2/(1 - R2)) F ~ F(1, n-2) R2 square correlation coefficient y X_j.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"Sellke, Thomas, Bayarri, M. J., Berger, James O.  (2001), ``Calibration p-values testing precise null hypotheses'', American Statistician, 55, 62-71.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/eplogprob.marg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"eplogprob.marg - Compute approximate marginal inclusion probabilities from\npvalues — eplogprob.marg","text":"","code":"library(MASS) data(UScrime) UScrime[,-2] = log(UScrime[,-2]) eplogprob(lm(y ~ ., data=UScrime)) #> (Intercept)           M          So          Ed         Po1         Po2  #>   1.0000000   0.9480823   0.5000000   0.9883193   0.5045770   0.5000000  #>          LF         M.F         Pop          NW          U1          U2  #>   0.5000000   0.5304659   0.5807429   0.8046414   0.5000000   0.6858642  #>         GDP        Ineq        Prob        Time  #>   0.6069289   0.9900000   0.9412475   0.5782754"},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted values for a BAS BMA objects — fitted.bas","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"Calculate fitted values BAS BMA object","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"","code":"# S3 method for bas fitted(   object,   type = \"link\",   estimator = \"BMA\",   top = NULL,   na.action = na.pass,   ... )"},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"object object class 'bas' created bas type type equals \"response\" \"link\" case GLMs (default 'link') estimator estimator type fitted value return. Default use BMA models. Options include  'HPM' highest probability model  'BMA' Bayesian model averaging, using optionally 'top' models  'MPM' median probability model Barbieri Berger.  'BPM' model closest BMA predictions squared error loss top optional argument specifying 'top' models used constructing BMA prediction, NULL models used.  top=1, equivalent 'HPM' na.action function determining done missing values newdata. default predict NA. ... optional arguments, used currently","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"vector length n fitted values.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"Calculates fitted values observed design matrix using either highest probability model, 'HPM', posterior mean (BMA) 'BMA', median probability model 'MPM' best predictive model 'BPM\".  median probability model defined including variable marginal inclusion probability greater equal 1/2. type=\"BMA\", weighted average may based using subset highest probability models optional argument given top.  default BMA uses sampled models, may take compute number variables number models large.  \"BPM\" found computing squared distance vector fitted values model fitted values BMA returns model smallest distance.  presence multicollinearity may quite different MPM, extreme collinearity may drop relevant predictors.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"Barbieri, M.  Berger, J.O. (2004) Optimal predictive model selection. Annals Statistics. 32, 870-897. https://projecteuclid.org/euclid.aos/1085408489&url=/UI/1.0/Summarize/euclid.aos/1085408489 Clyde, M. Ghosh, J. Littman, M. (2010) Bayesian Adaptive Sampling Variable Selection Model Averaging. Journal Computational Graphics Statistics.  20:80-101 doi:10.1198/jcgs.2010.09049","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/fitted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitted values for a BAS BMA objects — fitted.bas","text":"","code":"data(Hald) hald.gprior =  bas.lm(Y~ ., data=Hald, prior=\"ZS-null\", initprobs=\"Uniform\") plot(Hald$Y, fitted(hald.gprior, estimator=\"HPM\"))  plot(Hald$Y, fitted(hald.gprior, estimator=\"BMA\", top=3))  plot(Hald$Y, fitted(hald.gprior, estimator=\"MPM\"))  plot(Hald$Y, fitted(hald.gprior, estimator=\"BPM\"))"},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"function takes output bas object allows higher order interactions included parent lower order interactions terms model, assigning zero prior probability, hence posterior probability, models include respective parents.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"","code":"force.heredity.bas(object, prior.prob = 0.5)"},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"object bas linear model generalized linear model object prior.prob prior probability term included conditional parents included","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"bas object updated models, coefficients summaries obtained removing models   zero prior posterior probabilities.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"Currently prior probabilities computed using conditional Bernoulli distributions, .e.  P(gamma_j = 1 | Parents(gamma_j) = 1) = prior.prob.  efficient models large number levels.  Future updates force time sampling.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/force.heredity.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Post processing function to force constraints on interaction inclusion bas BMA objects — force.heredity.bas","text":"","code":"data(\"chickwts\") bas.chk <- bas.lm(weight ~ feed, data = chickwts) #  summary(bas.chk)  # 2^5 = 32 models bas.chk.int <- force.heredity.bas(bas.chk) #  summary(bas.chk.int)  # two models now   data(Hald) bas.hald <- bas.lm(Y ~ .^2, data = Hald) bas.hald.int <- force.heredity.bas(bas.hald) image(bas.hald.int)  image(bas.hald.int)   # two-way interactions data(ToothGrowth) ToothGrowth$dose <- factor(ToothGrowth$dose) levels(ToothGrowth$dose) <- c(\"Low\", \"Medium\", \"High\") TG.bas <- bas.lm(len ~ supp * dose, data = ToothGrowth, modelprior = uniform()) TG.bas.int <- force.heredity.bas(TG.bas) image(TG.bas.int)"},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"Creates object representing g-prior distribution coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"","code":"g.prior(g)"},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"g scalar used covariance Zellner's g-prior, Cov(beta) = sigma^2 g (X'X)^-1","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"Creates structure used BAS.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/g.prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Families of G-Prior Distribution for Coefficients in BMA Models — g.prior","text":"","code":"g.prior(100) #> $family #> [1] \"g.prior\" #>  #> $g #> [1] 100 #>  #> $class #> [1] \"g-prior\" #>  #> $hyper #> [1] 100 #>  #> $hyper.parameters #> $hyper.parameters$g #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"Creates object representing hyper-g mixture g-priors coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"","code":"hyper.g(alpha = 3)"},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"alpha scalar > 0. hyper.g(alpha) equivalent CCH(alpha -2, 2, 0). Liang et al recommended values range 2 < alpha_h <= 3","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hyper-g-Prior Distribution for Coefficients in BMA Models — hyper.g","text":"","code":"hyper.g(alpha = 3) #> $family #> [1] \"CCH\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 1 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"Creates object representing hyper-g/n mixture g-priors coefficients BAS. special case tCCH prior","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"","code":"hyper.g.n(alpha = 3, n = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"alpha scalar > 0, recommended 2 < alpha <= 3 n sample size; NULL, value derived data call `bas.glm` used.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"Creates structure used bas.glm.  special case tCCH, hyper.g.n(alpha=3, n) equivalent  tCCH(alpha=1, beta=2, s=0, r=1.5, v = 1, theta=1/n)","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hyper.g.n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized hyper-g/n Prior Distribution for g for mixtures of g-priors on\nCoefficients in BMA Models — hyper.g.n","text":"","code":"n <- 500 hyper.g.n(alpha = 3, n = n) #> $family #> [1] \"hyper-g/n\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 1 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #> $hyper.parameters$r #> [1] 1.5 #>  #> $hyper.parameters$v #> [1] 1 #>  #> $hyper.parameters$theta #> [1] 0.002 #>  #>  #> $n #> [1] 500 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":null,"dir":"Reference","previous_headings":"","what":"Confluent hypergeometric1F1 function — hypergeometric1F1","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"Compute Confluent Hypergeometric function: 1F1(,b,c,t) = Gamma(b)/(Gamma(b-)Gamma()) Int_0^1 t^(-1) (1 - t)^(b--1) exp(c t) dt","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"","code":"hypergeometric1F1(a, b, c, laplace = FALSE, log = TRUE)"},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"arbitrary b Must greater 0 c arbitrary laplace default use Cephes library; large s may return NA, Inf negative values,, case use Laplace approximation. log TRUE, return log(1F1)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"Cephes library hyp1f1.c","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"Merlise Clyde (clyde@stat.duke.edu)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric1F1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confluent hypergeometric1F1 function — hypergeometric1F1","text":"","code":"hypergeometric1F1(11.14756, 0.5, 0.00175097) #> [1] 0.03856253"},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian hypergeometric2F1 function — hypergeometric2F1","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"Compute Gaussian Hypergeometric2F1 function: 2F1(,b,c,z) = Gamma(b-c) Int_0^1 t^(b-1) (1 - t)^(c -b -1) (1 - t z)^(-) dt","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"","code":"hypergeometric2F1(a, b, c, z, method = \"Cephes\", log = TRUE)"},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"arbitrary b Must greater 0 c Must greater b |z| < 1, c > b + z = 1 z |z| <= 1 method default use Cephes library routine.  sometimes unstable large z near one returning Inf negative values.  case, try method=\"Laplace\", use Laplace approximation tau = exp(t/(1-t)). log TRUE, return log(2F1)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"log=T returns log 2F1 function; otherwise 2F1 function.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"default use routine hyp2f1.c Cephes library.  return negative value Inf, one try method=\"Laplace\" based Laplace approximation described Liang et al JASA 2008. used hyper-g prior calculate marginal likelihoods.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"Cephes library hyp2f1.c Liang, F., Paulo, R., Molina, G., Clyde, M. Berger, J.O. (2005) Mixtures g-priors Bayesian Variable Selection.  Journal American Statistical Association.  103:410-423.  doi:10.1198/016214507000001337","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"Merlise Clyde (clyde@duke.edu)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/hypergeometric2F1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian hypergeometric2F1 function — hypergeometric2F1","text":"","code":"hypergeometric2F1(12, 1, 2, .65) #> [1] 9.580921"},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Images of models used in Bayesian model averaging — image.bas","title":"Images of models used in Bayesian model averaging — image.bas","text":"Creates image models selected using bas.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Images of models used in Bayesian model averaging — image.bas","text":"","code":"# S3 method for bas image(   x,   top.models = 20,   intensity = TRUE,   prob = TRUE,   log = TRUE,   rotate = TRUE,   color = \"rainbow\",   subset = NULL,   drop.always.included = FALSE,   offset = 0.75,   digits = 3,   vlas = 2,   plas = 0,   rlas = 0,   ... )"},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Images of models used in Bayesian model averaging — image.bas","text":"x BMA object type 'bas' created BAS top.models Number top ranked models plot intensity Logical variable, TRUE image intensity proportional probability log(probability) model, FALSE, intensity binary indicating just presence (light) absence (dark) variable. prob Logical variable whether area image model proportional posterior probability (log probability) model (TRUE) equal area (FALSE). log Logical variable indicating whether intensities based log posterior odds (TRUE) posterior probabilities (FALSE).  log posterior odds comparing model worst model top.models. rotate image models rotated models y-axis variables x-axis (TRUE) color color scheme image intensities. value \"rainbow\" uses rainbow palette. value \"blackandwhite\" produces black white image (greyscale image) subset indices variables include/exclude plot drop.always.included logical variable drop variables always forced model.  FALSE default. offset numeric value add intensity digits number digits posterior probabilities keep vlas las parameter placing variable names; see par plas las parameter posterior probability axis rlas las parameter model ranks ... parameters passed image axis functions.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Images of models used in Bayesian model averaging — image.bas","text":"Creates image model space sampled using bas.  subset top models plotted, probabilities renormalized subset.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Images of models used in Bayesian model averaging — image.bas","text":"Suggestion allow area models proportional posterior probability due Thomas Lumley","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Images of models used in Bayesian model averaging — image.bas","text":"Clyde, M. (1999) Bayesian Model Averaging Model Search Strategies (discussion). Bayesian Statistics 6. J.M. Bernardo, .P. Dawid, J.O. Berger, .F.M. Smith eds. Oxford University Press, pages 157-185.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Images of models used in Bayesian model averaging — image.bas","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/image.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Images of models used in Bayesian model averaging — image.bas","text":"","code":"require(graphics) data(\"Hald\") hald.ZSprior <- bas.lm(Y ~ ., data = Hald, prior = \"ZS-null\") image(hald.ZSprior, drop.always.included = TRUE) # drop the intercept"},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":null,"dir":"Reference","previous_headings":"","what":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"Creates object representing intrinsic prior g, special case tCCH mixture g-priors coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"","code":"intrinsic(n = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"n sample size; NULL, value derived data call `bas.glm` used.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"returns object class \"prior\", family \"intrinsic\" class \"TCCH\" hyperparameters alpha = 1, beta = 1, s = 0, r = 1, n = n tCCH prior theta tCCH prior determined model size sample size.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"Creates structure used bas.glm.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"Womack, ., Novelo,L.L., Casella, G. (2014). \"Inference Intrinsic Bayes' Procedures Model Selection Uncertainty\". Journal American Statistical Association.  109:1040-1053. doi:10.1080/01621459.2014.880348","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/intrinsic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intrinsic Prior Distribution for Coefficients in BMA Models — intrinsic","text":"","code":"n <- 500 tCCH(alpha = 1, beta = 2, s = 0, r = 1.5, v = 1, theta = 1 / n) #> $family #> [1] \"tCCH\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 1 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #> $hyper.parameters$r #> [1] 1.5 #>  #> $hyper.parameters$v #> [1] 1 #>  #> $hyper.parameters$theta #> [1] 0.002 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce a BAS list object into a matrix. — list2matrix.bas","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"Models, coefficients, standard errors objects class 'bas' represented list lists reduce storage omitting zero entries.  functions coerce list object matrix fill zeros facilitate computations.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"","code":"list2matrix.bas(x, what, which.models = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"x 'bas' object name bas list coerce .models vector indices use extract subset","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"matrix representation x$, number rows equal length .models total number models number columns x$n.vars","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"list2matrix.bas(x, ) equivalent list2matrix.(x), however, latter uses sapply rather loop. list2matrix..matrix coerce x$matrix.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce a BAS list object into a matrix. — list2matrix.bas","text":"","code":"data(Hald) hald.bic <-  bas.lm(Y ~ ., data=Hald, prior=\"BIC\",                     initprobs= \"eplogp\") coef <- list2matrix.bas(hald.bic, \"mle\")  # extract all coefficients se <- list2matrix.bas(hald.bic, \"mle.se\") models <- list2matrix.which(hald.bic)     #matrix of model indicators models <- which.matrix(hald.bic$which, hald.bic$n.vars)     #matrix of model indicators"},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce a BAS list object into a matrix. — list2matrix.which","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"Models, coefficients, standard errors objects class 'bas' represented list lists reduce storage omitting zero entries.  functions coerce list object matrix fill zeros facilitate computations.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"","code":"list2matrix.which(x, which.models = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"x 'bas' object .models vector indices use extract subset","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"matrix representation x$, number rows equal length .models total number models number columns x$n.vars","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"list2matrix.bas(x, ) equivalent list2matrix.(x), however, latter uses sapply rather loop. list2matrix..matrix coerce x$matrix.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/list2matrix.which.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce a BAS list object into a matrix. — list2matrix.which","text":"","code":"data(Hald) Hald.bic <-  bas.lm(Y ~ ., data=Hald, prior=\"BIC\", initprobs=\"eplogp\") coef <- list2matrix.bas(Hald.bic, \"mle\")  # extract all ols coefficients se <- list2matrix.bas(Hald.bic, \"mle.se\") models <- list2matrix.which(Hald.bic)     #matrix of model indicators models <- which.matrix(Hald.bic$which, Hald.bic$n.vars)     #matrix of model indicators"},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":null,"dir":"Reference","previous_headings":"","what":"Compound Confluent hypergeometric function of two variables — phi1","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"Compute Confluent Hypergeometric function two variables, also know Horn hypergeometric function Humbert's hypergeometric used Gordy (1998) integral representation:","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"","code":"phi1(a, b, c, x, y, log = FALSE)"},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"> 0 b arbitrary c c > 0 x x > 0 y y > 0 log logical indicating whether return phi1 log scale","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"phi_1(,b,c,x,y) =  [(Gamma(c)/Gamma() Gamma(-c))] Int_0^1 t^(-1) (1 - t)^(c--1) (1 - yt)^(-b) exp(x t) dt https://en.wikipedia.org/wiki/Humbert_series Note Gordy's arguments x y reversed reference . original `phi1` function `BAS` based `C` code provided  Gordy.  function returns NA's  x greater `log(.Machine$double.xmax)/2`.    stable method calculating `phi1` function using R's `integrate`  suggested Daniel Heemann now option whenever $x$  large.  calculating Bayes factors use `phi1` function  recommend using `log=TRUE` option compute log Bayes factors.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"Gordy 1998","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"Merlise Clyde (clyde@duke.edu) Daniel Heemann (df.heemann@gmail.com)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/phi1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compound Confluent hypergeometric function of two variables — phi1","text":"","code":"# special cases # phi1(a, b, c, x=0, y) is the same as 2F1(b, a; c, y) phi1(1, 2, 1.5, 0, 1 / 100, log=FALSE) #> [1] 1.013495 hypergeometric2F1(2, 1, 1.5, 1 / 100, log = FALSE) #> [1] 1.013495  # phi1(a,0,c,x,y) is the same as 1F1(a,c,x) phi1(1, 0, 1.5, 3, 1 / 100) #> [1] 10.13001 hypergeometric1F1(1, 1.5, 3, log = FALSE) #> [1] 10.13001  # use direct integration phi1(1, 2, 1.5, 1000, 0, log=TRUE) #> [1] 996.4253"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"Displays plots posterior distributions coefficients generated Bayesian model averaging linear regression.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"","code":"# S3 method for coef.bas plot(x, e = 1e-04, subset = 1:x$n.vars, ask = TRUE, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"x object class coef.bas e optional numeric value specifying range distributions graphed. subset optional numerical vector specifying variables graph (including intercept) ask Prompt next plot ... parameters passed plot lines","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"Produces plots posterior distributions coefficients model averaging.  posterior probability coefficient zero represented solid line zero, height equal probability. nonzero part distribution scaled maximum height equal probability coefficient nonzero. parameter e specifies range distributions graphed specifying tail probabilities dictate range plot .","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"mixtures g-priors, uncertainty g incorporated time, thus results approximate","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"Hoeting, J.., Raftery, .E. Madigan, D. (1996). method simultaneous variable selection outlier identification linear regression. Computational Statistics Data Analysis, 22, 251-270.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"based function plot.bic Ian Painter package BMA; adapted 'bas' class Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots the posterior distributions of coefficients derived from Bayesian\nmodel averaging — plot.coef.bas","text":"","code":"if (FALSE) library(MASS) data(UScrime) UScrime[,-2] <- log(UScrime[,-2]) crime_bic <- bas.lm(y ~ ., data=UScrime, n.models=2^15, prior=\"BIC\") plot(coefficients(crime_bic), ask=TRUE)"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Bayesian Confidence Intervals — plot.confint.bas","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"Function takes output functions return credible intervals BAS objects, creates plot posterior mean segments representing credible interval.   function . ~~","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"","code":"# S3 method for confint.bas plot(x, horizontal = FALSE, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"x output confint.coef.bas confint.pred.bas containing credible intervals estimates. horizontal orientation plot ... optional graphical arguments pass plot","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"plot credible intervals.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"function takes HPD intervals credible intervals created confint.coef.bas confint.pred.bas BAS objects, creates plot posterior mean segments representing credible interval.  BAS tries return HPD intervals, model averaging may symmetric.   description ~~","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.confint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Bayesian Confidence Intervals — plot.confint.bas","text":"","code":"data(Hald) hald.ZS = bas.lm(Y ~ ., data=Hald, prior=\"ZS-null\", modelprior=uniform()) hald.coef = confint(coef(hald.ZS), parm=2:5) plot(hald.coef)  #> NULL plot(hald.coef, horizontal=TRUE)  #> NULL plot(confint(predict(hald.ZS, se.fit=TRUE), parm=\"mean\"))  #> NULL"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Diagnostics for an BAS Object — plot.bas","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"Four plots (selectable '') currently available: plot residuals fitted values, Cumulative Model Probabilities, log marginal likelihoods versus model dimension, marginal inclusion probabilities.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"","code":"# S3 method for bas plot(   x,   which = c(1:4),   caption = c(\"Residuals vs Fitted\", \"Model Probabilities\", \"Model Complexity\",     \"Inclusion Probabilities\"),   panel = if (add.smooth) panel.smooth else points,   sub.caption = NULL,   main = \"\",   ask = prod(par(\"mfcol\")) < length(which) && dev.interactive(),   col.in = 2,   col.ex = 1,   col.pch = 1,   cex.lab = 1,   ...,   id.n = 3,   labels.id = NULL,   cex.id = 0.75,   add.smooth = getOption(\"add.smooth\"),   label.pos = c(4, 2),   subset = NULL,   drop.always.included = FALSE )"},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"x bas BMA object result 'bas' subset plots required, specify subset numbers '1:4' caption captions appear plots panel panel function.  useful alternative 'points', 'panel.smooth' can chosen 'add.smooth = TRUE' sub.caption common title-figures multiple; used 'sub' (s.'title') otherwise.  'NULL', default, possible shortened version deparse(x$call) used main title plot-addition 'caption' ask logical; 'TRUE', user asked plot, see 'par(ask=.)' col.color included variables col.ex color excluded variables col.pch color points panels 1-3 cex.lab graphics parameter control size variable names ... parameters passed plotting functions id.n number points labeled plot, starting extreme labels.id vector labels, labels extreme points chosen.  'NULL' uses observation numbers cex.id magnification point labels. add.smooth logical indicating smoother added plots; see also 'panel' label.pos positioning labels, left half right half graph respectively, plots 1-4 subset indices variables include/exclude plot marginal posterior inclusion probabilities (NULL). drop.always.included logical variable drop marginal posterior inclusion probabilities variables always forced model.  FALSE default.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"provides panel 4 plots: first plot residuals versus fitted values BMA. second plot cumulative marginal likelihoods models; model space enumerated provides indication whether probabilities leveling . third plot log marginal likelihood versus model dimension fourth plot show posterior marginal inclusion probabilities.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"Merlise Clyde, based plot.lm John Maindonald Martin Maechler","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Diagnostics for an BAS Object — plot.bas","text":"","code":"data(Hald) hald.gprior =  bas.lm(Y~ ., data=Hald, prior=\"g-prior\", alpha=13,                       modelprior=beta.binomial(1,1),                       initprobs=\"eplogp\")  plot(hald.gprior)"},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction Method for an object of class BAS — predict.bas","title":"Prediction Method for an object of class BAS — predict.bas","text":"Predictions model averaging estimators BMA object class inheriting 'bas'.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction Method for an object of class BAS — predict.bas","text":"","code":"# S3 method for bas predict(   object,   newdata,   se.fit = FALSE,   type = \"link\",   top = NULL,   estimator = \"BMA\",   na.action = na.pass,   ... )"},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction Method for an object of class BAS — predict.bas","text":"object object class BAS, created bas newdata dataframe predictions. missing, use dataframe used fitting obtaining fitted predicted values. se.fit indicator whether compute se fitted predicted values type Type predictions required. \"link\" scale linear predictor option currently linear models, normal model equivalent type='response'. top scalar integer M.  supplied, subset top M models, based posterior probabilities model predictions BMA. estimator estimator used predictions.  Currently supported options include:  'HPM' highest probability model  'BMA' Bayesian model averaging, using optionally 'top' models  'MPM' median probability model Barbieri Berger.  'BPM' model closest BMA predictions squared error loss. BMA may computed using 'top' models supplied na.action function determining done missing values newdata. default predict NA. ... optional extra arguments","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction Method for an object of class BAS — predict.bas","text":"list fit fitted values based selected estimator Ybma predictions using BMA, fit non-BMA methods compatibility; deprecated Ypred matrix predictions model BMA se.fit se fitted values; case BMA matrix se.pred se predicted values; case BMA matrix se.bma.fit vector posterior sd BMA posterior mean regression function. NULL estimator 'BMA' se.bma.pred vector posterior sd BMA posterior predictive values.  NULL estimator 'BMA' best index top models included bestmodels subset bestmodels used fitting prediction best.vars names variables top model; NULL estimator='BMA' df scalar vector degrees freedom models estimator estimator upon 'fit' based.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction Method for an object of class BAS — predict.bas","text":"Use BMA /model selection form predictions using top highest probability models.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction Method for an object of class BAS — predict.bas","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction Method for an object of class BAS — predict.bas","text":"","code":"data(\"Hald\") hald.gprior =  bas.lm(Y ~ ., data=Hald, alpha=13, prior=\"g-prior\")  predict(hald.gprior, newdata=Hald, estimator=\"BPM\", se.fit=TRUE) #> $fit #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 #> attr(,\"model\") #> [1] 0 1 2 4 #> attr(,\"best\") #> [1] 12 #> attr(,\"estimator\") #> [1] \"BPM\" #>  #> $Ybma #>            [,1] #>  [1,]  79.68307 #>  [2,]  74.69127 #>  [3,] 105.63258 #>  [4,]  89.91648 #>  [5,]  95.67480 #>  [6,] 104.57616 #>  [7,] 103.47945 #>  [8,]  76.96808 #>  [9,]  92.22184 #> [10,] 113.84918 #> [11,]  82.59035 #> [12,] 110.87673 #> [13,] 110.34001 #>  #> $Ypred #>            [,1]     [,2]      [,3]      [,4]      [,5]      [,6]      [,7] #>  [1,]  81.17036 74.83464 105.07248  89.69881  97.15898 104.45753 103.38927 #>  [2,]  77.70296 74.24113 105.85537  90.46267  93.09565 104.71517 103.13993 #>  [3,]  79.70437 74.40553 105.21752  89.76253  95.63309 104.57088 103.52541 #>  [4,]  79.65151 74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [5,]  79.84321 74.31409 104.90632  89.65651  95.70301 104.52849 103.54760 #>  [6,]  79.26248 74.75042 106.28314  90.16732  95.37830 104.70862 103.39893 #>  [7,]  78.80123 75.69457 108.22151  90.62061  95.54467 104.84276 103.50032 #>  [8,]  81.66556 77.02098 106.35099  88.18423  99.83232 103.89115 105.74346 #>  [9,]  85.78065 79.39070 104.28069  87.30339 103.43704 102.66524 106.03984 #> [10,]  74.86000 80.34349 102.27744  83.77067  93.36677 100.90656 111.87354 #> [11,]  79.18965 81.38793 101.17241  82.85345  98.24138 100.43966 112.16380 #> [12,]  76.29823 80.55874 101.93127  83.25765  95.26054 100.79397 112.20198 #> [13,]  94.62219 84.21059 101.56325 101.56325  94.62219 101.56325  87.68112 #> [14,]  95.42308 95.42308  95.42308  95.42308  95.42308  95.42308  95.42308 #> [15,]  91.78308 83.03167 101.29055 101.29055  91.78308 101.74970  88.24455 #> [16,] 102.15048 91.65573  99.81831  99.81831 102.15048  98.65223  89.32357 #>           [,8]      [,9]     [,10]    [,11]     [,12]     [,13] #>  [1,] 76.06454  91.57174 113.17222 81.59906 111.22195 111.08841 #>  [2,] 78.80193  92.68123 115.80581 84.50293 110.41616 109.07906 #>  [3,] 77.08557  91.98604 114.17593 82.78145 111.11959 110.53210 #>  [4,] 77.00839  92.07571 114.10876 82.68233 111.04286 110.46741 #>  [5,] 77.15919  91.83513 114.23530 82.88128 111.23840 110.65147 #>  [6,] 76.86019  92.49134 113.99208 82.44826 110.67744 110.08148 #>  [7,] 76.13446  93.59932 112.64184 81.53107 109.86900 109.49863 #>  [8,] 74.60469  93.86382 106.77052 80.21897 110.61958 111.73373 #>  [9,] 74.19437  93.55892 101.91430 79.36984 110.13525 112.42979 #> [10,] 85.82697 100.90656  98.16482 92.68133 107.76092 107.76092 #> [11,] 82.85345  99.70690  94.57759 89.44827 108.50000 109.96552 #> [12,] 84.53056 100.50527  96.78718 91.37187 108.21267 108.79006 #> [13,] 84.21059  85.94586 118.91590 84.21059 101.56325  99.82798 #> [14,] 95.42308  95.42308  95.42308 95.42308  95.42308  95.42308 #> [15,] 86.24572  86.55641 120.92687 86.70486 101.74970  99.14326 #> [16,] 83.49316  88.15749 104.48264 82.32707  98.65223  99.81831 #>  #> $postprobs #>  [1] 2.432256e-01 1.684081e-01 1.312165e-01 1.224293e-01 1.220358e-01 #>  [6] 1.145513e-01 6.888252e-02 2.709377e-02 1.481347e-03 2.891971e-04 #> [11] 2.559516e-04 5.597869e-05 4.790052e-05 1.177702e-05 1.000762e-05 #> [16] 5.009504e-06 #>  #> $se.fit #>        1        2        3        4        5        6        7        8  #> 3.117350 2.283957 1.602160 2.149087 2.589321 1.508471 2.610923 2.545817  #>        9       10       11       12       13  #> 1.990817 3.485929 2.456636 1.951456 2.212238  #>  #> $se.pred #>        1        2        3        4        5        6        7        8  #> 5.440156 5.009380 4.737547 4.949344 5.155775 4.706689 5.166658 5.134065  #>        9       10       11       12       13  #> 4.882702 5.659428 5.090431 4.866787 4.977090  #>  #> $se.bma.fit #> NULL #>  #> $se.bma.pred #> NULL #>  #> $df #> [1] 12 #>  #> $best #> [1] 12 #>  #> $bestmodel #> [1] 0 1 2 4 #>  #> $best.vars #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X4\"        #>  #> $estimator #> [1] \"BPM\" #>  #> attr(,\"class\") #> [1] \"pred.bas\" # same as fitted fitted(hald.gprior,estimator=\"BPM\") #>  [1]  79.65151  74.47846 105.42183  89.83174  95.62799 104.59616 103.50684 #>  [8]  77.00839  92.07571 114.10876  82.68233 111.04286 110.46741 # default is BMA and estimation of mean vector hald.bma = predict(hald.gprior, top=5, se.fit=TRUE) confint(hald.bma) #>            2.5%     97.5%      pred #>  [1,]  68.13615  91.73475  79.74246 #>  [2,]  63.73489  85.58516  74.50010 #>  [3,]  94.54573 115.93312 105.29268 #>  [4,]  78.92815 100.57213  89.88693 #>  [5,]  84.77522 107.25599  95.57177 #>  [6,]  93.88975 114.52813 104.56409 #>  [7,]  92.31617 115.15504 103.40145 #>  [8,]  66.05824  88.46812  77.13668 #>  [9,]  81.35131 102.67814  91.99731 #> [10,] 101.48303 126.38518 114.21325 #> [11,]  71.37699  93.73436  82.78446 #> [12,] 100.19762 121.77267 111.00723 #> [13,]  99.67680 121.52927 110.40160 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\"  hald.bpm = predict(hald.gprior, newdata=Hald[1,],                     se.fit=TRUE,                     estimator=\"BPM\") confint(hald.bpm) #>          2.5%    97.5%     pred #> [1,] 67.74454 91.66421 79.70437 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" # extract variables variable.names(hald.bpm) #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X3\"        \"X4\"         hald.hpm = predict(hald.gprior, newdata=Hald[1,],                     se.fit=TRUE,                     estimator=\"HPM\") confint(hald.hpm) #>          2.5%    97.5%     pred #> [1,] 70.15171 92.18902 81.17036 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" variable.names(hald.hpm) #> [1] \"Intercept\" \"X1\"        \"X2\"         hald.mpm = predict(hald.gprior, newdata=Hald[1,],                     se.fit=TRUE,                     estimator=\"MPM\") confint(hald.mpm) #>          2.5%    97.5%     pred #> [1,] 67.79843 91.50459 79.65151 #> attr(,\"Probability\") #> [1] 0.95 #> attr(,\"class\") #> [1] \"confint.bas\" variable.names(hald.mpm) #> [1] \"Intercept\" \"X1\"        \"X2\"        \"X4\""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction Method for an Object of Class basglm — predict.basglm","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"Predictions model averaging BMA (BAS) object GLMs different loss functions.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"","code":"# S3 method for basglm predict(   object,   newdata,   se.fit = FALSE,   type = c(\"response\", \"link\"),   top = NULL,   estimator = \"BMA\",   na.action = na.pass,   ... )"},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"object object class \"basglm\", created bas.glm newdata dataframe, new matrix vector data predictions. May include column intercept just predictor variables.  dataframe, variables extracted using model.matrix using call created 'object'.  May missing case data used fitting used prediction. se.fit indicator whether compute se fitted predicted values type Type predictions required. default  \"response\" scale response variable, alternative linear predictor scale, `type ='link'`. Thus default binomial model `type = 'response'` gives predicted probabilities, `'link'`, estimates log-odds (probabilities logit scale). top scalar integer M.  supplied, calculate results using subset top M models based posterior probabilities. estimator estimator used predictions.  Currently supported options include:  'HPM' highest probability model  'BMA' Bayesian model averaging, using optionally 'top' models  'MPM' median probability model Barbieri Berger.  'BPM' model closest BMA predictions squared error loss. BMA may computed using 'top' models supplied na.action function determining done missing values newdata. default predict NA. ... optional extra arguments","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"list fit predictions using BMA estimators Ypred matrix predictions model(s) postprobs renormalized probabilities top models best index top models included","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"function first calls predict method class bas (linear models) form predictions linear predictor scale `BMA`, `HPM`, `MPM` etc. estimator `BMA` `type='response'` inverse link applied fitted values type equal `'link'` model averaging takes place `response` scale. Thus applying inverse link BMA estimate `type = 'link'` equal fitted values `type = 'response'` BMA due  nonlinear transformation inverse link.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/predict.basglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction Method for an Object of Class basglm — predict.basglm","text":"","code":"data(Pima.tr, package=\"MASS\") data(Pima.te, package=\"MASS\") Pima.bas = bas.glm(type ~ ., data=Pima.tr, n.models= 2^7, method=\"BAS\",            betaprior=CCH(a=1, b=nrow(Pima.tr)/2, s=0), family=binomial(),            modelprior=uniform()) pred = predict(Pima.bas, newdata=Pima.te, top=1)  # Highest Probability model cv.summary.bas(pred$fit, Pima.te$type, score=\"miss-class\") #> [1] 0.2108434"},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"summary print methods Bayesian model averaging objects created bas Bayesian Adaptive Sampling","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"","code":"# S3 method for bas print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"x object class 'bas' digits optional number specifying number digits display ... parameters passed print.default","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"print methods display view similar print.lm .  summary methods display view specific Bayesian model averaging giving top 5 highest probability models represented inclusion indicators. Summaries models include Bayes Factor (BF) model model largest marginal likelihood, posterior probability models, R2, dim (includes intercept) log marginal likelihood.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/print.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a Summary of Bayesian Model Averaging objects from BAS — print.bas","text":"","code":"library(MASS) data(UScrime) UScrime[, -2] <- log(UScrime[, -2]) crime.bic <- bas.lm(y ~ ., data = UScrime, n.models = 2^15, prior = \"BIC\", initprobs = \"eplogp\") print(crime.bic) #>  #> Call: #> bas.lm(formula = y ~ ., data = UScrime, n.models = 2^15, prior = \"BIC\",  #>     initprobs = \"eplogp\") #>  #>  #>  Marginal Posterior Inclusion Probabilities:  #> Intercept          M         So         Ed        Po1        Po2         LF   #>    1.0000     0.9335     0.3277     0.9910     0.7247     0.4602     0.2935   #>       M.F        Pop         NW         U1         U2        GDP       Ineq   #>    0.3298     0.4963     0.8346     0.3481     0.7752     0.5254     0.9992   #>      Prob       Time   #>    0.9541     0.5433   summary(crime.bic) #>           P(B != 0 | Y)   model 1       model 2     model 3     model 4 #> Intercept     1.0000000   1.00000  1.000000e+00   1.0000000   1.0000000 #> M             0.9335117   1.00000  1.000000e+00   1.0000000   1.0000000 #> So            0.3276563   0.00000  1.000000e+00   0.0000000   0.0000000 #> Ed            0.9910219   1.00000  1.000000e+00   1.0000000   1.0000000 #> Po1           0.7246635   1.00000  1.000000e+00   1.0000000   1.0000000 #> Po2           0.4602481   0.00000  1.000000e+00   0.0000000   0.0000000 #> LF            0.2935326   0.00000  1.000000e+00   0.0000000   0.0000000 #> M.F           0.3298168   0.00000  1.000000e+00   0.0000000   0.0000000 #> Pop           0.4962869   0.00000  1.000000e+00   0.0000000   0.0000000 #> NW            0.8346412   1.00000  1.000000e+00   1.0000000   1.0000000 #> U1            0.3481266   0.00000  1.000000e+00   0.0000000   0.0000000 #> U2            0.7752102   1.00000  1.000000e+00   1.0000000   1.0000000 #> GDP           0.5253694   0.00000  1.000000e+00   0.0000000   1.0000000 #> Ineq          0.9992058   1.00000  1.000000e+00   1.0000000   1.0000000 #> Prob          0.9541470   1.00000  1.000000e+00   1.0000000   1.0000000 #> Time          0.5432686   1.00000  1.000000e+00   0.0000000   1.0000000 #> BF                   NA   1.00000  1.267935e-04   0.7609295   0.5431578 #> PostProbs            NA   0.01910  1.560000e-02   0.0145000   0.0133000 #> R2                   NA   0.84200  8.695000e-01   0.8265000   0.8506000 #> dim                  NA   9.00000  1.600000e+01   8.0000000  10.0000000 #> logmarg              NA -22.15855 -3.113150e+01 -22.4317627 -22.7689035 #>               model 5 #> Intercept   1.0000000 #> M           1.0000000 #> So          0.0000000 #> Ed          1.0000000 #> Po1         1.0000000 #> Po2         0.0000000 #> LF          0.0000000 #> M.F         0.0000000 #> Pop         1.0000000 #> NW          1.0000000 #> U1          0.0000000 #> U2          1.0000000 #> GDP         0.0000000 #> Ineq        1.0000000 #> Prob        1.0000000 #> Time        0.0000000 #> BF          0.5203179 #> PostProbs   0.0099000 #> R2          0.8375000 #> dim         9.0000000 #> logmarg   -22.8118635"},{"path":"http://merliseclyde.github.io/BAS/reference/protein.html","id":null,"dir":"Reference","previous_headings":"","what":"Protein Activity Data — protein","title":"Protein Activity Data — protein","text":"data sets includes several predictors protein activity experiment run Glaxo.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/protein.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Protein Activity Data — protein","text":"protein dataframe 96 observations 8 predictor variables protein activity:","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/protein.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Protein Activity Data — protein","text":"Clyde, M. . Parmigiani, G. (1998), Protein Construct Storage: Bayesian Variable Selection Prediction Mixtures, Journal Biopharmaceutical Statistics, 8, 431-443","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust-Prior Distribution for Coefficients in BMA Model — robust","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"Creates object representing robust prior Bayarri et al (2012) mixture g-priors coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"","code":"robust(n = NULL)"},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"n sample size.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"Creates prior structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust-Prior Distribution for Coefficients in BMA Model — robust","text":"","code":"robust(100) #> $family #> [1] \"robust\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$n #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"summary print methods Bayesian model averaging objects created bas Bayesian Adaptive Sampling","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"","code":"# S3 method for bas summary(object, n.models = 5, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"object object class 'bas' n.models optional number specifying number best models display summary ... parameters passed summary.default","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"print methods display view similar print.lm .  summary methods display view specific Bayesian model averaging giving top 5 highest probability models represented inclusion indicators. Summaries models include Bayes Factor (BF) model model largest marginal likelihood, posterior probability models, R2, dim (includes intercept) log marginal likelihood.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summaries of Bayesian Model Averaging objects from BAS — summary.bas","text":"","code":"data(UScrime, package = \"MASS\") UScrime[, -2] <- log(UScrime[, -2]) crime.bic <- bas.lm(y ~ ., data = UScrime, n.models = 2^15, prior = \"BIC\", initprobs = \"eplogp\") print(crime.bic) #>  #> Call: #> bas.lm(formula = y ~ ., data = UScrime, n.models = 2^15, prior = \"BIC\",  #>     initprobs = \"eplogp\") #>  #>  #>  Marginal Posterior Inclusion Probabilities:  #> Intercept          M         So         Ed        Po1        Po2         LF   #>    1.0000     0.9335     0.3277     0.9910     0.7247     0.4602     0.2935   #>       M.F        Pop         NW         U1         U2        GDP       Ineq   #>    0.3298     0.4963     0.8346     0.3481     0.7752     0.5254     0.9992   #>      Prob       Time   #>    0.9541     0.5433   summary(crime.bic) #>           P(B != 0 | Y)   model 1       model 2     model 3     model 4 #> Intercept     1.0000000   1.00000  1.000000e+00   1.0000000   1.0000000 #> M             0.9335117   1.00000  1.000000e+00   1.0000000   1.0000000 #> So            0.3276563   0.00000  1.000000e+00   0.0000000   0.0000000 #> Ed            0.9910219   1.00000  1.000000e+00   1.0000000   1.0000000 #> Po1           0.7246635   1.00000  1.000000e+00   1.0000000   1.0000000 #> Po2           0.4602481   0.00000  1.000000e+00   0.0000000   0.0000000 #> LF            0.2935326   0.00000  1.000000e+00   0.0000000   0.0000000 #> M.F           0.3298168   0.00000  1.000000e+00   0.0000000   0.0000000 #> Pop           0.4962869   0.00000  1.000000e+00   0.0000000   0.0000000 #> NW            0.8346412   1.00000  1.000000e+00   1.0000000   1.0000000 #> U1            0.3481266   0.00000  1.000000e+00   0.0000000   0.0000000 #> U2            0.7752102   1.00000  1.000000e+00   1.0000000   1.0000000 #> GDP           0.5253694   0.00000  1.000000e+00   0.0000000   1.0000000 #> Ineq          0.9992058   1.00000  1.000000e+00   1.0000000   1.0000000 #> Prob          0.9541470   1.00000  1.000000e+00   1.0000000   1.0000000 #> Time          0.5432686   1.00000  1.000000e+00   0.0000000   1.0000000 #> BF                   NA   1.00000  1.267935e-04   0.7609295   0.5431578 #> PostProbs            NA   0.01910  1.560000e-02   0.0145000   0.0133000 #> R2                   NA   0.84200  8.695000e-01   0.8265000   0.8506000 #> dim                  NA   9.00000  1.600000e+01   8.0000000  10.0000000 #> logmarg              NA -22.15855 -3.113150e+01 -22.4317627 -22.7689035 #>               model 5 #> Intercept   1.0000000 #> M           1.0000000 #> So          0.0000000 #> Ed          1.0000000 #> Po1         1.0000000 #> Po2         0.0000000 #> LF          0.0000000 #> M.F         0.0000000 #> Pop         1.0000000 #> NW          1.0000000 #> U1          0.0000000 #> U2          1.0000000 #> GDP         0.0000000 #> Ineq        1.0000000 #> Prob        1.0000000 #> Time        0.0000000 #> BF          0.5203179 #> PostProbs   0.0099000 #> R2          0.8375000 #> dim         9.0000000 #> logmarg   -22.8118635"},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"Creates object representing tCCH mixture g-priors coefficients BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"","code":"tCCH(alpha = 1, beta = 2, s = 0, r = 3/2, v = 1, theta = 1)"},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"alpha scalar > 0, recommended alpha=.5 (betaprime) 1. beta scalar > 0.  value updated data; beta function n consistency null model. s scalar, recommended s=0 priori r r arbitrary; hyper-g-n prior sets r = (alpha + 2) v 0 < v theta theta > 1","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"Creates structure used bas.glm.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tCCH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized tCCH g-Prior Distribution for Coefficients in BMA Models — tCCH","text":"","code":"n <- 500 tCCH(alpha = 1, beta = 2, s = 0, r = 1.5, v = 1, theta = 1 / n) #> $family #> [1] \"tCCH\" #>  #> $class #> [1] \"TCCH\" #>  #> $hyper.parameters #> $hyper.parameters$alpha #> [1] 1 #>  #> $hyper.parameters$beta #> [1] 2 #>  #> $hyper.parameters$s #> [1] 0 #>  #> $hyper.parameters$r #> [1] 1.5 #>  #> $hyper.parameters$v #> [1] 1 #>  #> $hyper.parameters$theta #> [1] 0.002 #>  #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Test based Bayes Factors for BMA Models — testBF.prior","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"Creates object representing prior distribution coefficients BAS corresponds test-based Bayes Factors.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"","code":"testBF.prior(g)"},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"g scalar used covariance Zellner's g-prior, Cov(beta) = sigma^2 g (X'X)^-","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"returns object class \"prior\", family hyerparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"Creates prior object structure used BAS `bas.glm`.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/testBF.prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test based Bayes Factors for BMA Models — testBF.prior","text":"","code":"testBF.prior(100) #> $family #> [1] \"testBF.prior\" #>  #> $g #> [1] 100 #>  #> $class #> [1] \"g-prior\" #>  #> $hyper #> [1] 100 #>  #> $hyper.parameters #> $hyper.parameters$g #> [1] 100 #>  #> $hyper.parameters$loglik_null #> NULL #>  #>  #> attr(,\"class\") #> [1] \"prior\" library(MASS) data(Pima.tr)  # use g = n bas.glm(type ~ .,   data = Pima.tr, family = binomial(),   betaprior = testBF.prior(nrow(Pima.tr)),   modelprior = uniform(), method = \"BAS\" ) #>  #> Call: #> bas.glm(formula = type ~ ., family = binomial(), data = Pima.tr,  #>     betaprior = testBF.prior(nrow(Pima.tr)), modelprior = uniform(),  #>     method = \"BAS\") #>  #>  #>  Marginal Posterior Inclusion Probabilities:  #> Intercept      npreg        glu         bp       skin        bmi        ped   #>    1.0000     0.4252     1.0000     0.0706     0.1264     0.6139     0.8075   #>       age   #>    0.6705"},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"Creates object representing prior distribution models BAS using truncated Beta-Binomial Distribution Model Size","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"","code":"tr.beta.binomial(alpha = 1, beta = 1, trunc)"},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"alpha parameter beta prior distribution beta parameter beta prior distribution trunc parameter determines truncation distribution .e. P(M; alpha, beta, trunc) = 0 M > trunc.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"beta-binomial distribution model size obtained assigning variable inclusion indicator independent Bernoulli distributions probability w, giving w beta(alpha,beta) distribution. Marginalizing w leads number included predictors beta-binomial distribution. default hyperparameters lead uniform distribution model size.  Truncated version assigns zero probability models size > trunc.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.beta.binomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated Beta-Binomial Prior Distribution for Models — tr.beta.binomial","text":"","code":"tr.beta.binomial(1, 10, 5) #> $family #> [1] \"Trunc-Beta-Binomial\" #>  #> $hyper.parameters #> [1]  1 10  5 #>  #> attr(,\"class\") #> [1] \"prior\" library(MASS) data(UScrime) UScrime[, -2] <- log(UScrime[, -2]) crime.bic <- bas.lm(y ~ .,   data = UScrime, n.models = 2^15, prior = \"BIC\",   modelprior = tr.beta.binomial(1, 1, 8),   initprobs = \"eplogp\" )"},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated Poisson Prior Distribution for Models — tr.poisson","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"Creates object representing prior distribution models BAS using truncated Poisson Distribution Model Size","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"","code":"tr.poisson(lambda, trunc)"},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"lambda parameter Poisson distribution representing expected model size infinite predictors trunc parameter determines truncation distribution .e. P(M; lambda, trunc) = 0 M > trunc","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"Poisson prior distribution model size obtained assigning variable inclusion indicator independent Bernoulli distributions probability w, taking limit p goes infinity w goes zero, p*w converges lambda.  Truncated version assigns zero probability models size M > trunc.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated Poisson Prior Distribution for Models — tr.poisson","text":"","code":"tr.poisson(10, 50) #> $family #> [1] \"Trunc-Poisson\" #>  #> $hyper.parameters #> [1] 10 50 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated Power Prior Distribution for Models — tr.power.prior","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"Creates object representing prior distribution models BAS using truncated Distribution Model Size probability gamma = p^-kappa |gamma| gamma vector model indicators","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"","code":"tr.power.prior(kappa = 2, trunc)"},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"kappa parameter prior distribution controls sparsity trunc parameter determines truncation distribution .e. P(gamma; alpha, beta, trunc) = 0 |gamma| > trunc.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"returns object class \"prior\", family hyperparameters.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"beta-binomial distribution model size obtained assigning variable inclusion indicator independent Bernoulli distributions probability w, giving w beta(alpha,beta) distribution. Marginalizing w leads number included predictors beta-binomial distribution. default hyperparameters lead uniform distribution model size.  Truncated version assigns zero probability models size > trunc.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/tr.power.prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated Power Prior Distribution for Models — tr.power.prior","text":"","code":"tr.power.prior(2, 8) #> $family #> [1] \"Trunc-Power-Prior\" #>  #> $hyper.parameters #> [1] 2 8 #>  #> attr(,\"class\") #> [1] \"prior\" library(MASS) data(UScrime) UScrime[, -2] <- log(UScrime[, -2]) crime.bic <- bas.lm(y ~ .,   data = UScrime, n.models = 2^15, prior = \"BIC\",   modelprior = tr.power.prior(2, 8),   initprobs = \"eplogp\" )"},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated Compound Confluent Hypergeometric function — trCCH","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"Compute Truncated Confluent Hypergeometric function Li Clyde  (2018) normalizing constant tcch density Gordy (1998) integral representation:","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"","code":"trCCH(a, b, r, s, v, k, log = FALSE)"},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"> 0 b b > 0 r r  >= 0 s arbitrary v 0 < v k arbitrary log logical indicating whether return values log scale;  useful Bayes Factor calculations","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"tr.cch(,b,r,s,v,k) =  Int_0^1/v                     u^(-1) (1 - vu)^(b -1) (k + (1 - k)vu)^(-r) exp(-s u) du uses  stable method calculating normalizing constant using R's `integrate`  function rather version Gordy 1998. calculating Bayes factors  use `trCCH` function  recommend using `log=TRUE` option compute log Bayes factors.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"Gordy 1998 Li & Clyde 2018","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"Merlise Clyde (clyde@duke.edu)","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/trCCH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated Compound Confluent Hypergeometric function — trCCH","text":"","code":"# special cases # trCCH(a, b, r, s=0, v = 1, k) is the same as # 2F1(a, r, a + b, 1 - 1/k)*beta(a, b)/k^r  k = 10; a = 1.5; b = 2; r = 2;   trCCH(a, b, r, s=0, v = 1, k=k) *k^r/beta(a,b) #> [1] 4.74679 hypergeometric2F1(a, r, a + b, 1 - 1/k, log = FALSE) #> [1] 4.746772  # trCCH(a,b,0,s,1,1) is the same as  # beta(a, b) 1F1(a, a + b, -s, log=FALSE) s = 3; r = 0; v = 1; k = 1 beta(a, b)*hypergeometric1F1(a, a+b, -s, log = FALSE) #> [1] 0.0923551 trCCH(a, b, r, s, v, k) #> [1] 0.09235518  # Equivalence with the Phi1 function  a = 1.5; b = 3; k = 1.25; s = 400;  r = 2;  v = 1;   phi1(a, r,  a + b, -s, 1 - 1/k,  log=FALSE)*(k^-r)*gamma(a)*gamma(b)/gamma(a+b) #> [1] 7.04733e-05 trCCH(a,b,r,s,v,k) #> [1] 7.052186e-05"},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Uniform Prior Distribution for Models — uniform","title":"Uniform Prior Distribution for Models — uniform","text":"Creates object representing prior distribution models BAS.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uniform Prior Distribution for Models — uniform","text":"","code":"uniform()"},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uniform Prior Distribution for Models — uniform","text":"returns object class \"prior\", family name Uniform.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Uniform Prior Distribution for Models — uniform","text":"Uniform prior distribution commonly used prior BMA, special case independent Bernoulli prior probs=.5. implied prior distribution model size binomial(p, .5).","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Uniform Prior Distribution for Models — uniform","text":"Merlise Clyde","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/uniform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uniform Prior Distribution for Models — uniform","text":"","code":"uniform() #> $family #> [1] \"Uniform\" #>  #> $hyper.parameters #> [1] 0.5 #>  #> attr(,\"class\") #> [1] \"prior\""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update BAS object using a new prior — update.bas","title":"Update BAS object using a new prior — update.bas","text":"Update BMA object using new prior distribution coefficients.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update BAS object using a new prior — update.bas","text":"","code":"# S3 method for bas update(object, newprior, alpha = NULL, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update BAS object using a new prior — update.bas","text":"object BMA object update newprior Update posterior model probabilities, probne0, shrinkage, logmarg, etc, using prior based newprior.  See bas available methods alpha optional new value hyperparameter prior method ... optional arguments","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update BAS object using a new prior — update.bas","text":"new object class BMA","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update BAS object using a new prior — update.bas","text":"Recomputes marginal likelihoods new methods models already sampled current object.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Update BAS object using a new prior — update.bas","text":"Clyde, M. Ghosh, J. Littman, M. (2010) Bayesian Adaptive Sampling Variable Selection Model Averaging. Journal Computational Graphics Statistics.  20:80-101 doi:10.1198/jcgs.2010.09049","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Update BAS object using a new prior — update.bas","text":"Merlise Clyde clyde@stat.duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update BAS object using a new prior — update.bas","text":"","code":"# \\donttest{ library(MASS) data(UScrime) UScrime[,-2] <- log(UScrime[,-2]) crime.bic <-  bas.lm(y ~ ., data=UScrime, n.models=2^10, prior=\"BIC\",initprobs= \"eplogp\") crime.ebg <- update(crime.bic, newprior=\"EB-global\") crime.zs <- update(crime.bic, newprior=\"ZS-null\") # }"},{"path":"http://merliseclyde.github.io/BAS/reference/variable.names.pred.bas.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","title":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","text":"S3 method class 'pred.bas'.  Simple utility function extract variable names.  Used print names selected models using estimators 'HPM', 'MPM' 'BPM\". selected model created predict BAS objects.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/variable.names.pred.bas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","text":"","code":"# S3 method for pred.bas variable.names(object, ...)"},{"path":"http://merliseclyde.github.io/BAS/reference/variable.names.pred.bas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","text":"object BAS object created predict BAS `bas.lm` `bas.glm` object ... arguments pass ","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/variable.names.pred.bas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","text":"character vector names variables included selected model; case 'BMA' variables","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/variable.names.pred.bas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the variable names for a model from a BAS prediction object — variable.names.pred.bas","text":"","code":"data(Hald) hald.gprior =  bas.lm(Y~ ., data=Hald, prior=\"ZS-null\", modelprior=uniform()) hald.bpm = predict(hald.gprior, newdata=Hald[1,],                    se.fit=TRUE,                    estimator=\"BPM\") variable.names(hald.bpm) #> [1] \"Intercept\" \"X2\""},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce a BAS list object of models into a matrix. — which.matrix","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"function coerces list object models matrix fill zeros facilitate computations.","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"","code":"which.matrix(which, n.vars)"},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"'bas' model object  x$n.vars total number predictors, x$n.vars","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"matrix representation x$, number rows equal length .models total number models number columns x$n.vars","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":".matrix  coerces x$matrix.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"Merlise Clyde clyde@duke.edu","code":""},{"path":"http://merliseclyde.github.io/BAS/reference/which.matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce a BAS list object of models into a matrix. — which.matrix","text":"","code":"data(Hald) Hald.bic <-  bas.lm(Y ~ ., data=Hald, prior=\"BIC\", initprobs=\"eplogp\") # matrix of model indicators models <- which.matrix(Hald.bic$which, Hald.bic$n.vars)"},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-6-5","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.6.5","text":"Added support Gamma regression bas.glm, unit tests example (Code contributed @betsyberrson) added error initial model bas.lm sampling methods “MCMC” “MCMC+BAS” prior probability zero.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-6-5","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.6.5","text":"fixed printing problems identified via checks fixed indexing error bas.lm method = \"MCMC+BAS\" bas.lm using method = \"MCMC+BAS\" crashed segmentation fault bestmodel NULL null model. GitHub issue #69 fixed error predict.bas se.fit=TRUE one predictor. GitHub issue #68 reported @AleCarminati added unit test test-predict.R Fixed error coef bas.glm objects using betaprior class IC, including AIC BIC Github issue #65 Fixed error using Jeffreys prior bas.glm include.always option added unit test test-bas-glm.R. Github issue #61 Fixed error extracting coefficients median probability model formula passed object rather literal, added unit test test-coefficients.R Github issues #39 #56","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-164","dir":"Changelog","previous_headings":"","what":"BAS 1.6.4","title":"BAS 1.6.4","text":"CRAN release: 2022-11-02","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-6-4","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.6.4","text":"skipped test CRAN fails show warning non full rank case pivot=FALSE bas.lm default uses pivoting documentation indicates pivot=FALSE used full rank case users encounter issue practice. Users continue see warning NA’s returned, aware platforms may produce warning (M1mac). Github issue #62","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-163","dir":"Changelog","previous_headings":"","what":"BAS 1.6.3","title":"BAS 1.6.3","text":"CRAN release: 2022-10-19","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-6-3","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.6.3","text":"Added checks unit-tests see modelprior class ‘prior’ resolving Github Issue #57 Removed polevl.c, psi.c gamma.c Cephes longer used switching R’s internal functions","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-162","dir":"Changelog","previous_headings":"","what":"BAS 1.6.2","title":"BAS 1.6.2","text":"CRAN release: 2022-04-26 replaced deprecated DOUBLE_EPS DBL_EPSILON R 4.2.0 release (two places) restore CRAN","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-6-1","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.6.1","text":"replaced deprecated DOUBLE_EPS DBL_EPSILON R 4.2.0 release fixed warnings CRAN checkcs R devel (use | class) added function trCCH uses integration compute normalizing constant Truncated Compund Confluent Hypergeometric distribution provides correct normalizing constant Gordy (1998) stable large values compared current phi1 function. now used TCCH prior bas.glm. Rewrote phi1 function use direct numerical integration (phi1_int) Wald statistic large marginal likelihoods NA suggested Daniel Heeman Alexander Ly (see ). improve stability estimates Bayes Factors model probabilities bas.glm used HyperTwo function, including coefficient priors hyper.g.n(), robust(), intrinsic(). Added additional unit tests. Added thin option bas.glm added unit tests examples show connections special functions trCCH, phi1, 1F1 2F1","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-6-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.6.1","text":"added internal function phi1_int original HyperTwo function returns NA Issue #55 See details . corrected shrinkage estimate CCH prior include terms involving beta function.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-160","dir":"Changelog","previous_headings":"","what":"BAS 1.6.0","title":"BAS 1.6.0","text":"CRAN release: 2021-11-12","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-6-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.6.0","text":"update Fortran code compliant USE_FC_LEN_T character strings","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-6-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.6.0","text":"fixed warning src code log_laplace_F21 uninitialized variable leading NaN returned R function hypergeometric2F1","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-155","dir":"Changelog","previous_headings":"","what":"BAS 1.5.5","title":"BAS 1.5.5","text":"CRAN release: 2020-01-24","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"changes-1-5-5","dir":"Changelog","previous_headings":"","what":"Changes","title":"BAS 1.5.5","text":"Fixed WARNING fedora-clang-devel. Added climate.dat file package building vignette package violate CRAN’s policy accessing internet resources permament file location/url changes locally. Fixed testthat errors Solaris. Default settings force.heredity set back FALSE bas.lm bas.glm methods work platforms. Solaris, users wish impose force.heredity constraint may use post-processing function.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-154","dir":"Changelog","previous_headings":"","what":"BAS 1.5.4","title":"BAS 1.5.4","text":"CRAN release: 2020-01-19","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-5-4","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.5.4","text":"Modified prior probabilities adjust number variables always included using include.always. Pull request #41 Don van de Bergh. Issue #40","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-5-4","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.5.4","text":"Fixed valgrind error src/ZS_approx_null_np.c invalid write noted CRAN checks fixed function declaration type-mismatch argument errors identified LTO noted CRAN checks Added contrast=NULL argument bas.lm bas.glm non-NULL contrasts trigger warning model.matrix R 3.6.0. Bug #44 Added check sample size equal zero due subsetting missing data Bug #37","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"other-1-5-4","dir":"Changelog","previous_headings":"","what":"Other","title":"BAS 1.5.4","text":"Put ORCID quotes author list (per R-dev changes)","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-153","dir":"Changelog","previous_headings":"","what":"BAS 1.5.3","title":"BAS 1.5.3","text":"CRAN release: 2018-10-30","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-5-3","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.5.3","text":"Fixed errors identified cran checks https://cran.r-project.org/web/checks/check_results_BAS.html initialize R2_m = 0.0 lm_mcmcbas.c (lead NA’s clang debian fedora ) switch default pivot = TRUE bas.lm, adding tol argument control tolerance cholregpovot improved stability across platforms singular nearly singular designs. valgrind messages: Conditional jump move depends uninitialised value(s). Initialize vectors allocated via R_alloc lm_deterministic.c glm_deterministic.c.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-152","dir":"Changelog","previous_headings":"","what":"BAS 1.5.2","title":"BAS 1.5.2","text":"CRAN release: 2018-10-25","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-5-2","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.5.2","text":"Included option pivot=TRUE bas.lm fit models using pivoted Cholesky decomposition allow models rank-deficient. Enhancement #24 Bug #21. Currently coefficients -estimable set zero predict methods work . vector rank added output (see documentation bas.lm) degrees freedom methods assume uniform prior obtaining estimates (AIC BIC) adjusted use rank rather size. Added option force.heredity=TRUEto force lower order terms included higher order terms present (hierarchical constraint) method='MCMC' method='BAS' bas.lm bas.glm. Updated Vignette illustrate. enhancement #19. Checks see parents included using include.always pass issue #26. Added option drop.always.included image.bas variables always included may excluded image. default shown enhancement #23 Added option drop.always.included subset plot.bas variables always included may excluded plot showing marginal posterior inclusion probabilities (=4). default shown enhancement #23 update fitted.bas use predict code covers GLM LM cases type='link' type='response' Updates package CII Best Practices Badge certification Added Code Coverage support extensive tests using test_that.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-5-2","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.5.2","text":"fixed issue #36 Errors prior = “ZS-null” R2 finite range due model full rank. Change gexpectations function file bayesreg.c fixed issue #35 method=\"MCMC+BAS\" bas.glm glm_mcmcbas.c values provided MCMC.iterations n.models defaults used. Added unit test test-bas-glm.R fixed issue #34 bas.glm variables include.always marginal inclusion probabilities incorrect. Added unit test test-bas-glm.R fixed issue #33 Jeffreys prior marginal inclusion probabilities renormalized dropping intercept model fixed issue #32 allow vectorization phi1 function R/cch.R added unit test “tests/testthat/test-special-functions.R” fixed issue #31 coerce g REAL g.prior prior IC.prior bas.glm; added unit-test “tests/testthat/test-bas-glm.R” fixed issue #30 added n hyperparameter NULL coerced REAL intrinsic prior bas.glm; added unit-test fixed issue #29 added n hyperparameter NULL coerced REAL beta.prime prior bas.glm; added unit-test fixed issue #28 fixed length MCMC estimates marginal inclusion probabilities; added unit-test fixed issue #27 expected shrinkage JZS prior greater 1. Added unit test. fixed output include.always include intercept issue #26 always drop.always.included = TRUE drops intercept variables forced . include.always force.heredity=TRUE can now used together method=\"BAS\". added warning marginal likelihoods/posterior probabilities NA default model fitting method suggestion models rerun pivot = TRUE. uses modified Cholesky decomposition pivoting model rank deficient nearly singular dimensionality reduced. Bug #21. corrected count first model method='MCMC' lead potential model 0 probability errors image. coerced predicted values vector BMA (matrix) fixed size using method=deterministic bas.glm (updated) fixed problem confint horizontal=TRUE intervals point mass zero.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"other-1-5-2","dir":"Changelog","previous_headings":"","what":"Other","title":"BAS 1.5.2","text":"suppress warning sampling probabilities 1 0 number models decrementedIssue #25 changed force.heredity.bas renormalize prior probabilities rather use new prior probability based heredity constraints. future, add new priors models based heredity. See comment issue #26. Changed License GPL 3.0","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-151-june-6-2018","dir":"Changelog","previous_headings":"","what":"BAS 1.5.1 June 6, 2018","title":"BAS 1.5.1 June 6, 2018","text":"CRAN release: 2018-06-07","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-5-1","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.5.1 June 6, 2018","text":"added S3 method variable.names extract variable names highest probability model, median probability model, best probability model objects created predict.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-5-1","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.5.1 June 6, 2018","text":"Fixed incorrect documentation predict.basglm type = \"link\" default prediction issue #18","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-150-may-2-2018","dir":"Changelog","previous_headings":"","what":"BAS 1.5.0 May 2, 2018","title":"BAS 1.5.0 May 2, 2018","text":"CRAN release: 2018-05-03","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-5-0","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.5.0 May 2, 2018","text":"add na.action handling NA’s predict methods issue #10 added include.always new argument bas.lm. allows formula specify terms always included models. default intercept always included. added section vignette illustrate weighted regression force.heredity.bas function group levels factor enter leave model together.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-5-0","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.5.0 May 2, 2018","text":"fixed problem one model image function; github issue #11 fixed error bas.lm non-equal weights R2 incorrect. issue #17 ## Deprecated deprecate predict argument predict.bas, predict.basglm internal functions utilized","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-149-march-24-2018","dir":"Changelog","previous_headings":"","what":"BAS 1.4.9 March 24, 2018","title":"BAS 1.4.9 March 24, 2018","text":"CRAN release: 2018-03-25","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-4-9","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.4.9 March 24, 2018","text":"fixed bug confint.coef.bas parm character string added parentheses betafamily.c line 382 indicated CRAN check R devel","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-4-9","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.4.9 March 24, 2018","text":"added option determine k Bayes.outlier prior probability outliers provided","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-148-march-10-2018","dir":"Changelog","previous_headings":"","what":"BAS 1.4.8 March 10, 2018","title":"BAS 1.4.8 March 10, 2018","text":"CRAN release: 2018-03-12","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-4-8","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.4.8 March 10, 2018","text":"fixed issue scoping eval data predict.bas dataname defined local env. fixed issue 10 github (predict estimator=‘BPM’ failed NA’s X data. Delete NA’s finding closest model. fixed bug ‘JZS’ prior - merged pull request #12 vandenman/master fixed bug bas.glm default betaprior (CCH) used inputs INTEGER instead REAL removed warning use ‘ZS-null’ backwards compatibility","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-added-1-4-8","dir":"Changelog","previous_headings":"","what":"Features added","title":"BAS 1.4.8 March 10, 2018","text":"updated print.bas reflect changes print.lm Added Bayes.outlier function calculate posterior probabilities outliers using method Chaloner & Brant linear models.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-147-october-22-2017","dir":"Changelog","previous_headings":"","what":"BAS 1.4.7 October 22, 2017","title":"BAS 1.4.7 October 22, 2017","text":"CRAN release: 2017-10-22","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"updates-1-4-7","dir":"Changelog","previous_headings":"","what":"Updates","title":"BAS 1.4.7 October 22, 2017","text":"Added new method bas.lm obtain marginal likelihoods Zellner-Siow Priors “prior= ‘JZS’ using QUADPATH routines numerical integration. optional hyperparameter alpha may now used adjust scaling ZS prior g ~ G(1/2, alpha*n/2) BayesFactor package Morey, default alpha=1 corresponding ZS prior used Liang et al (2008). also uses stable evaluations log(1 + x) prevent underflow/overflow. Priors ZS-full bas.lm planned deprecated. replaced math functions use portable C code Rmath consolidated header files","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-146-may-24-2017","dir":"Changelog","previous_headings":"","what":"BAS 1.4.6 May 24, 2017","title":"BAS 1.4.6 May 24, 2017","text":"CRAN release: 2017-05-26","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"updates-1-4-6","dir":"Changelog","previous_headings":"","what":"Updates","title":"BAS 1.4.6 May 24, 2017","text":"Added force.heredity.interaction function allow higher order interactions included “parents” lower order interactions main effects included. Currently tested two way interactions. implemented post-sampling; future updates add sampling stage reduce memory usage sampling times reducing number models consideration.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-4-6","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.4.6 May 24, 2017","text":"Fixed unprotected ANS C code glm_sampleworep.c sampleworep.c call PutRNGstate possible stack imbalance glm_mcmc. Fixed problem predict estimator=BPM newdata one row","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-145-march-28-2017","dir":"Changelog","previous_headings":"","what":"BAS 1.4.5 March 28, 2017","title":"BAS 1.4.5 March 28, 2017","text":"CRAN release: 2017-03-31","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-4-5","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.4.5 March 28, 2017","text":"Fixed non-conformable error predict new data dataframe one row. Fixed problem missing weights prediction using median probability model new data.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-144-march-14-2017","dir":"Changelog","previous_headings":"","what":"BAS 1.4.4 March 14, 2017","title":"BAS 1.4.4 March 14, 2017","text":"CRAN release: 2017-03-14","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"updates-1-4-4","dir":"Changelog","previous_headings":"","what":"Updates","title":"BAS 1.4.4 March 14, 2017","text":"Extract coefficient summaries, credible intervals plots HPM MPM addition default BMA adding new estimator argument coef function. new n.models argument coef provides summaries based top n.models highest probability models reduce computation time. ‘n.models = 1’ equivalent highest probability model. use newdata vector now deprecated predict.bas; newdata must dataframe missing, case fitted values based dataframe used fitting used factor levels handled lm glm prediction may level factor newdata","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bugs-1-4-4","dir":"Changelog","previous_headings":"","what":"Bugs","title":"BAS 1.4.4 March 14, 2017","text":"fixed issue prediction newdata just one row fixed missing id plot.bas =3","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-143-february-18-2017","dir":"Changelog","previous_headings":"","what":"BAS 1.4.3 February 18, 2017","title":"BAS 1.4.3 February 18, 2017","text":"CRAN release: 2017-02-21","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"updates-1-4-3","dir":"Changelog","previous_headings":"","what":"Updates","title":"BAS 1.4.3 February 18, 2017","text":"Register symbols foreign function calls bin2int now deprecated fixed default MCMC.iteration bas.lm agree documentation updated vignette include examples, outlier detection, finding best predictive probability model set flag MCMC sampling renormalize selects whether Monte Carlo frequencies used estimate posterior model marginal inclusion probabilities (default renormalize = FALSE) marginal likelihoods time prior probabilities renormalized sum 1 used. (latter option methods); new slots probne0.MCMC, probne0.RN, postprobs.RN postprobs.MCMC.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-4-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"BAS 1.4.3 February 18, 2017","text":"fixed problem prior.bic, robust, hyper.g.n default missing n set hyperparameters fixed error predict plot GLMs family provided function","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-142-october-12-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.4.2 October 12, 2016","title":"BAS 1.4.2 October 12, 2016","text":"CRAN release: 2016-10-13","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"updates-1-4-2","dir":"Changelog","previous_headings":"","what":"Updates","title":"BAS 1.4.2 October 12, 2016","text":"added df object returned bas.glm simplify coefficients function.","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-4-2","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.4.2 October 12, 2016","text":"corrected expected value shrinkage intrinsic, hyper-g/n TCCH priors glms","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-141-september-17-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.4.1 September 17, 2016","title":"BAS 1.4.1 September 17, 2016","text":"CRAN release: 2016-09-20","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bug-fixes-1-4-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"BAS 1.4.1 September 17, 2016","text":"modification 1.4.0 automatically handle NA’s led errors response transformed part formula; fixed","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"features-1-4-1","dir":"Changelog","previous_headings":"","what":"Features","title":"BAS 1.4.1 September 17, 2016","text":"added subset argument bas.lm bas.glm","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-140-august-25-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.4.0 August 25, 2016","title":"BAS 1.4.0 August 25, 2016","text":"CRAN release: 2016-08-27","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"new-features-1-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"BAS 1.4.0 August 25, 2016","text":"added na.action bas.lm bas.glm omit missing data. new function plot credible intervals created confint.pred.bas confint.coef.bas. See help files example vignette. added se.fit option predict.basglm. Added testBF betaprior option bas.glm implement Bayes Factors based likelihood ratio statistic’s distribution GLMs. DOI version http://dx.doi.org/10.5281/zenodo.60948","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-130-july-15-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.3.0 July 15, 2016","title":"BAS 1.3.0 July 15, 2016","text":"CRAN release: 2016-07-16","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"new-features-1-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"BAS 1.3.0 July 15, 2016","text":"vignette added long last! illustrates several new features BAS new functions computing credible intervals fitted predicted values confint.pred.bas() new function adding credible intervals coefficients confint.coef.bas() added posterior standard deviations fitted values predicted values predict.bas()","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"deprecation-1-3-0","dir":"Changelog","previous_headings":"","what":"Deprecation","title":"BAS 1.3.0 July 15, 2016","text":"deprecated use type specify estimator fitted.bas replaced estimator predict() fitted() compatible S3 methods. updated functions class bas avoid NAMESPACE conflicts libraries","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-122-june-29-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.2.2 June 29, 2016","title":"BAS 1.2.2 June 29, 2016","text":"CRAN release: 2016-07-01","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"new-features-1-2-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"BAS 1.2.2 June 29, 2016","text":"added option find “Best Predictive Model” “BPM” fitted.bas predict.bas added local Empirical Bayes prior fixed g-prior bas.glm added diagnostic() function checking convergence bas objects created method = \"MCMC\"” added truncated power prior Yang, Wainwright & Jordan (2016)","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"minor-changes-1-2-2","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"BAS 1.2.2 June 29, 2016","text":"bug fix plot.bas appears Sweave bug fix coef.bma just one predictor","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-121-april-16-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.2.1 April 16, 2016","title":"BAS 1.2.1 April 16, 2016","text":"CRAN release: 2016-04-16 bug fix method=“MCMC” truncated prior distributions MH ratio incorrect allowing models 0 probability sampled. fixed error Zellner-Siow prior (ZS-null) n=p+1 saturated model log marginal likelihood 0","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-120-april-11-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.2.0 April 11, 2016","title":"BAS 1.2.0 April 11, 2016","text":"CRAN release: 2016-04-12 removed unsafe code Rbestmarg (input) overwritten .Call end corruption constant pool byte-code (Thanks Tomas Kalibera catching !) fixed issue dimensions use Simple Linear Regression","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-110-march-31-2016","dir":"Changelog","previous_headings":"","what":"BAS 1.1.0 March 31, 2016","title":"BAS 1.1.0 March 31, 2016","text":"CRAN release: 2016-03-31","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"BAS 1.1.0 March 31, 2016","text":"added truncated Beta-Binomial prior truncated Poisson (works MCMC currently) improved code finding fitted values Median deprecated method = “AMCMC” issue warning message","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"minor-changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Minor Changes","title":"BAS 1.1.0 March 31, 2016","text":"Changed S3 method plot image use class bas rather bma avoid name conflicts packages","code":""},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-109","dir":"Changelog","previous_headings":"","what":"BAS 1.09","title":"BAS 1.09","text":"","code":"- added weights for linear models - switched LINPACK calls in bayesreg to LAPACK finally should be faster - fixed bug in intercept calculation for glms - fixed inclusion probabilities to be a vector in the global EB methods for linear models"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-108","dir":"Changelog","previous_headings":"","what":"BAS 1.08","title":"BAS 1.08","text":"","code":"- added intrinsic prior for GLMs - fixed problems for linear models for p > n and R2 not correct"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-107","dir":"Changelog","previous_headings":"","what":"BAS 1.07","title":"BAS 1.07","text":"","code":"- added phi1 function from Gordy (1998)  confluent hypergeometric function of two variables  also known as one of the Horn hypergeometric functions or Humbert's phi1 - added Jeffrey's prior on g - added the general tCCH prior and special cases of the hyper-g/n. - TODO check shrinkage functions for all"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-106","dir":"Changelog","previous_headings":"","what":"BAS 1.06","title":"BAS 1.06","text":"","code":"- new improved Laplace approximation for hypergeometric1F1 - added class basglm for predict - predict function now handles glm output - added dataframe option for newdata in predict.bas and predict.basglm - renamed coefficients in output to be 'mle' in bas.lm to be consistent across lm and glm versions so that predict methods can handle both cases.  (This may lead to errors in other external code that expects object$ols or object$coefficients) - fixed bug with initprobs that did not include an intercept for bas.lm"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-105","dir":"Changelog","previous_headings":"","what":"BAS 1.05","title":"BAS 1.05","text":"","code":"- added thinning option for MCMC method for bas.lm - returned posterior expected shrinkage for bas.glm - added option for initprobs = \"marg-eplogp\" for using marginal SLR models to create starting probabilities or order variables especially for p > n case - added standalone function for hypergeometric1F1 using Cephes library and a Laplace approximation -Added class \"BAS\" so that predict and fitted functions (S3 methods) are not masked by functions in the BVS package: to do modify the rest of the S3 methods."},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-104","dir":"Changelog","previous_headings":"","what":"BAS 1.04","title":"BAS 1.04","text":"","code":"- added bas.glm for model averaging/section using mixture of g-priors for GLMs.  Currently limited to Logistic Regression - added Poisson family for glm.fit"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-10","dir":"Changelog","previous_headings":"","what":"BAS 1.0","title":"BAS 1.0","text":"CRAN release: 2012-06-01","code":"- cleaned up  MCMC method code"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-093","dir":"Changelog","previous_headings":"","what":"BAS 0.93","title":"BAS 0.93","text":"","code":"- removed internal print statements in bayesglm.c - Bug fixes in AMCMC algorithm"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-092","dir":"Changelog","previous_headings":"","what":"BAS 0.92","title":"BAS 0.92","text":"CRAN release: 2010-10-01","code":"- fixed glm-fit.R  so that hyperparameter for BIC is numeric"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-091","dir":"Changelog","previous_headings":"","what":"BAS 0.91","title":"BAS 0.91","text":"CRAN release: 2010-09-09","code":"- added new AMCMC algorithm"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-091-1","dir":"Changelog","previous_headings":"","what":"BAS 0.91","title":"BAS 0.91","text":"CRAN release: 2010-09-09","code":"- bug fix in bayes.glm"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-090","dir":"Changelog","previous_headings":"","what":"BAS 0.90","title":"BAS 0.90","text":"CRAN release: 2010-07-24","code":"- added C routines for fitting glms"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-085","dir":"Changelog","previous_headings":"","what":"BAS 0.85","title":"BAS 0.85","text":"CRAN release: 2010-04-29 restricting n.models correct fitted values (broken version 0.80)","code":"- fixed problem with duplicate models if n.models was > 2^(p-1) by - save original X as part of object so that fitted.bma gives the"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-080","dir":"Changelog","previous_headings":"","what":"BAS 0.80","title":"BAS 0.80","text":"CRAN release: 2010-04-06 shrinkage - changed predict.bma center newdata using mean(X) - Added new Adaptive MCMC option (method = “AMCMC”) (stable point)","code":"- Added `hypergeometric2F1` function that is callable by R - centered X's in bas.lm so that the intercept has the correct"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-07","dir":"Changelog","previous_headings":"","what":"BAS 0.7","title":"BAS 0.7","text":"","code":"-Allowed pruning of model tree to eliminate rejected models"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-06","dir":"Changelog","previous_headings":"","what":"BAS 0.6","title":"BAS 0.6","text":"","code":"- Added MCMC option to create starting values for BAS (`method = \"MCMC+BAS\"`)"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-05","dir":"Changelog","previous_headings":"","what":"BAS 0.5","title":"BAS 0.5","text":"allocated within code","code":"-Cleaned up all .Call routines so that all objects are duplicated or"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-045","dir":"Changelog","previous_headings":"","what":"BAS 0.45","title":"BAS 0.45","text":"CRAN release: 2009-12-30","code":"- fixed ch2inv that prevented building on Windows in bayes glm_fit"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-04","dir":"Changelog","previous_headings":"","what":"BAS 0.4","title":"BAS 0.4","text":"CRAN release: 2009-12-28","code":"- fixed FORTRAN calls to use F77_NAME macro  - changed  allocation of objects for .Call to prevent some objects from being overwritten."},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-03","dir":"Changelog","previous_headings":"","what":"BAS 0.3","title":"BAS 0.3","text":"CRAN release: 2009-05-29","code":"- fixed EB.global function to include prior probabilities on models - fixed update function"},{"path":"http://merliseclyde.github.io/BAS/news/index.html","id":"bas-02","dir":"Changelog","previous_headings":"","what":"BAS 0.2","title":"BAS 0.2","text":"column ones intercept optionally included. - fixed help file predict - added modelprior argument bas.lm users may now use beta-binomial prior distribution model size addition default uniform distribution - added functions uniform(), beta-binomial() Bernoulli() create model prior objects - added vector user specified initial probabilities option argument initprobs bas.lm removed separate argument user.prob","code":"- fixed predict.bma to allow newdata to be a matrix or vector with the"}]
